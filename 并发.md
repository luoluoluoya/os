#### 并发

* 为单个运行进程提供的新抽象：线程。经典观点是一个程序只有一个执行点(一个程序计数器，用来存放要执行的指令)，但多线程程序会有多个执行点(多个程序计数器，每个都用于取指令和执行)。换一个角度来看，每个线程类似于独立的进程，只有一点区别：它们共享地址空间，从而能够访问相同的数据。

* 因此，单个线程的状态与进程状态非常类似。线程有一个程序计数器(PC)，记录程序从哪里获取指令。每个线程有自己的一组用于计算的寄存器。所以，如果有两个线程运行在一个处理器上，从运行一个线程(T1)切换到另一个线程(T2)时，必定发生上下文切换(context switch)。

* 线程之间的上下文切换类似于进程间的上下文切换。对于进程，我们将状态保存到进程控制块(Process Control Block，PCB)。现在，我们需要一个或多个线程控制块(Thread Control Block，TCB)，保存每个线程的状态。但是，与进程相比，线程之间的上下文切换有一点主要区别：地址空间保持不变(即不需要切换当前使用的页表)。

* 线程和进程之间的另一个主要区别在于栈。在简单的传统进程地址空间模型中，只有一个栈，通常位于地址空间的底部(高地址空间)。

* 然而，在多线程的进程中，每个线程独立运行，当然可以调用各种例程来完成正在执行的任何工作。不是地址空间中只有一个栈，而是每个线程都有一个栈。假设有一个多线程，结果地址空间看起来不同。在图 26.1 中，可以看到两个栈跨越了进程的地址空间。因此，所有位于栈上的变量、参数、返回值和其他放在栈上的东西，将被放置在有时称为线程本地(thread-local)存储的地方，即相关线程的栈。你可能注意到，多个栈也破坏了地址空间布局的美感。以前，堆和栈可以互不影响地增长，直到空间耗尽。多个栈就没有这么简单了。幸运的是，通常栈不会很大(除了大量使用递归的程序)。

  [!image](./images/30.png)

* 一旦线程创建，可能会立即运行(取决于调度程序的兴致)，或者处于就绪状态，等待执行。

* 线程创建有点像进行函数调用。然而，并不是首先执行函数然后返回给调用者，而是为被调用的例程创建一个新的执行线程，它可以独立于调用者运行，可能在从创建者返回之前运行，但也许会晚得多。


##### 共享数据

* 竞态条件(race condition)：结果取决于代码的时间执行。由于运气不好(即在执行过程中发生的上下文切换)，我们得到了错误的结果。事实上，可能每次都会得到不同的结果。因此，我们称这个结果是不确定的(indeterminate)。不确定的计算不知道输出是什么，它在不同运行中确实可能是不同的。
* 由于执行这段代码的多个线程可能导致竞争状态，因此我们将此段代码称为临界区(critical section)。临界区是访问共享变量(或更一般地说，共享资源)的代码片段，一定不能由多个线程同时执行。
* 对于共享资源，我们真正想要的代码就是所谓的互斥(mutual exclusion)。这个属性保证了如果一个线程在临界区内执行，其他线程将被阻止进入临界区。

* 解决这个问题的一种途径是拥有更强大的指令，单步就能完成要做的事，从而消除不合时宜的中断的可能性。如果有一条指令来做到这一点，我们可以发出这条指令然后完事。但在一般情况下，不会有这样的指令。

* 因此，我们要做的是要求硬件提供一些有用的指令，可以在这些指令上构建一个通用的集合，即所谓的同步原语(synchronization primitive)。通过使用这些硬件同步原语，加上操作系统的一些帮助，我们将能够构建多线程代码，以同步和受控的方式访问临界区，从而可靠地产生正确的结果—— 尽管有并发执行的挑战。

* 临界区、竞态条件、不确定性、互斥执行
   * 临界区是访问共享资源的一段代码，资源通常是一个变量或数据结构。
   * 竞态条件出现在多个执行线程大致同时进入临界区时，它们都试图更新共享的数据结构，导致了令人惊讶的结果。
   *  不确定性程序由一个或多个竞态条件组成，程序的输出因运行而异，具体取决于哪些线程在何时运行。这导致结果不是确定的，而我们通常期望计算机系统给出确定的结果。
   * 互斥执行可以保证只有一个线程进入临界区，从而避免出现竞态，并产生确定的程序输出。

##### 为什么操作系统课要研究并发 

* 操作系统是第一个并发程序，许多技术都是在操作系统内部使用的。从引入中断的一开始，OS 设计人员就不得不担心操作系统如何更新内部结构。不合时宜的中断会导致问题。毫不奇怪，页表、进程列表、文件系统结构以及几乎每个内核数据结构都必须小心地访问，并使用正确的同步原语才能正常工作。后来，在多线程的进程中，应用程序员也必须考虑这些事情。

* 原子操作是构建计算机系统的最强大的基础技术之一，从计算机体系结构到并行代码、文件系统、数据库管理系统，甚至分布式系统。将一系列动作原子化(atomic)背后的想法可以简单用一个短语表达：“全部或没有”。看上去，要么你希望组合在一起的所有活动都发生了，要么它们都没有发生。不会看到中间状态。有时，将许多行为组合为单个原子动作称为事务(transaction)，这是一个在数据库和事务处理世界中非常详细地发展的概念。


####  锁

* 并发编程的一个最基本问题：我们希望原子式执行一系列指令，但由于单处理器上的中断(或者多个线程在多处理器上并发执行)，我们做不到。在源代码中加锁，放在临界区周围，保证临界区能够像单条原子指令一样执行。

* 锁就是一个变量，因此我们需要声明一个某种类型的锁变量(lock variable)才能使用。这个锁变量(简称锁)保存了锁在某一时刻的状态。它要么是可用的(available，或 unlocked，或 free)，表示没有线程持有锁，要么是被占用的(acquired，或 locked， 或 held)，表示有一个线程持有锁，正处于临界区。我们也可以保存其他的信息，比如持有锁的线程，或请求获取锁的线程队列，但这些信息会隐藏起来，锁的使用者不会发现。

* lock()和 unlock()函数的语义很简单。调用 lock()尝试获取锁，如果没有其他线程持有锁，该线程会获得锁，进入临界区。这个线程有时被称为锁的持有者。如果另外一个线程对相同的锁变量调用 lock()，因为锁被另一线程持有，该调用不会返回。这样，当持有锁的线程在临界区时，其他线程就无法进入临界区。锁的持有者一旦调用 unlock()，锁就变成可用了。如果没有其他等待线程(即没有其他线程调用过 lock()并卡在那里)，锁的状态就变成可用了。如果有等待线程，其中一个会(最终)注意到(或收到通知)锁状态的变化，获取该锁，进入临界区。
* 锁为程序员提供了最小程度的调度控制。我们把线程视为程序员创建的实体，但是被操作系统调度，具体方式由操作系统选择。锁让程序员获得一些控制权。通过给临界区加锁，可以保证临界区内只有一个线程活跃。锁将原本由操作系统调度的混乱状态变得更为可控。

##### 实现一个锁 

* 评价锁 

  * 锁是否能完成它的基本任务，即提供互斥。最基本的，锁是否有效，能够阻止多个线程进入临界区
* 公平性， 当锁可用时，是否每一个竞争线程有公平的机会抢到锁？是否有竞争锁的线程会饿死，一直无法获得锁
  * 性能，具体来说，是使用锁之后增加的时间开销。有几种场景需要考虑。一种是没有竞争的情况，即只有一个线程抢锁、释放锁的开支如何？另外一种是一个 CPU 上多个线程竞争，性能如何？最后一种是多个 CPU、多个线程竞争时的性能。通过比较不同的场景，我们能够更好地理解不同的锁技术对性能的影响

* 控制中断 

  * 最早提供的互斥解决方案之一，就是在临界区关闭中断。这个解决方案是为单处理器系统开发的。代码如下：

    ```
    void lock() {
    	DisableInterrupts(); 
    }
    void unlock() { 
    	EnableInterrupts(); 
    } 
    ```

    通过在进入临界区之前关闭中断(使用特殊的硬件指令)，可以保证临界区的代码不会被中断，从而原子地执行。结束之后，我们重新打开中断(同样通过硬件指令)，程序正常运行。

  * 这个方法的主要优点就是简单。显然不需要费力思考就能弄清楚它为什么能工作。没有中断，线程可以确信它的代码会继续执行下去，不会被其他线程干扰。
  * 缺点很多。首先，这种方法要求我们允许所有调用线程执行特权操作(打开关闭中断)，即信任这种机制不会被滥用。众所周知，如果我们必须信任任意一个程序，可能就有麻烦了。这里，麻烦表现为多种形式：第一，一个贪婪的程序可能在它开始时就调用 lock()，从而独占处理器。更糟的情况是，恶意程序调用 lock()后，一直死循环。后一种情况，系统无法重新获得控制，只能重启系统。关闭中断对应用要求太多，不太适合作为通用的同步解决方案。第二，这种方案不支持多处理器。如果多个线程运行在不同的 CPU 上，每个线程都试图进入同一个临界区，关闭中断也没有作用。线程可以运行在其他处理器上，因此能够进入临界区。第三，关闭中断导致中断丢失，可能会导致严重的系统问题。假如磁盘设备完成了读取请求，但 CPU 错失了这一事实，那么，操作系统如何知道去唤醒等待读取的进程？最后一个不太重要的原因就是效率低。与正常指令执行相比，现代 CPU 对于关闭和打开中断的代码执行得较慢。基于以上原因，只在很有限的情况下用关闭中断来实现互斥原语。例如，在某些情况下操作系统本身会采用屏蔽中断的方式，保证访问自己数据结构的原子性，或至少避免某些复杂的中断处理情况。这种用法是可行的，因为在操作系统内部不存在信任问题，它总是信任自己可以执行特权操作

* DEKKER 算法和 PETERSON 算法

  * 只使用 load 和 store，保证不会有两个线程同时进入临界区。

    ```
    int flag[2]; 
    int turn; 
    void init() { 
        flag[0] = flag[1] = 0; // 1->thread wants to grab lock 
        turn = 0; // whose turn? (thread 0 or 1?) 
    } 
    void lock() { 
        flag[self] = 1; // self： thread ID of caller 
        turn = 1 - self; // make it other thread's turn 
        while ((flag[1-self] == 1) && (turn == 1 - self)) 
            ; // spin-wait 
    } 
    void unlock() { 
        flag[self] = 0; // simply undo your intent 
    } 
    ```

    一段时间以来，出于某种原因，大家都热衷于研究不依赖硬件支持的锁机制。后来这些工作都没有太多意义，因为只需要很少的硬件支持，实现锁就会容易很多(实际在多处理器的早期，就有这些硬件支持)。而且上面提到的方法无法运行在现代硬件(应为松散内存一致性模型)，导致它们更加没有用处。

##### 测试并设置指令(原子交换) 

* 因为关闭中断的方法无法工作在多处理器上，所以系统设计者开始让硬件支持锁。最简单的硬件支持是测试并设置指令(test-and-set instruction)，也叫作原子交换(atomic exchange)。为了理解 test-and-set 如何工作，我们首先实现一个不依赖它的锁，用一个变量标记锁是否被持有。

* 在第一次尝试中，想法很简单：用一个变量来标志锁是否被某些线程占用。第一个线程进入临界区，调用 lock()，检查标志是否为 1(这里不是 1)，然后设置标志为 1，表明线程持有该锁。结束临界区时，线程调用 unlock()，清除标志，表示锁未被持有。

  ```
  typedef struct lock_t { int flag; } lock_t; 
  void init(lock_t *mutex) { 
      mutex->flag = 0; 		// 初始化设置为可用
  } 
  void lock(lock_t *mutex) { 
      while (mutex->flag == 1) // 测试锁是否被占用
          ; // 自旋等待
      mutex->flag = 1; 		// 设置占用锁
  } 
  void unlock(lock_t *mutex) { 
      mutex->flag = 0; 		// 释放锁
  } 
  ```

  当第一个线程正处于临界区时，如果另一个线程调用 lock()，它会在 while 循环中自旋等待(spin-wait)，直到第一个线程调用 unlock()清空标志。然后等待的线程会退出 while 循环，设置标志，执行临界区代码。遗憾的是，这段代码有两个问题：正确性和性能。线程都将标志设置为 1，都能进入临界区。显然没有满足最基本的要求：互斥。性能问题主要是线程在等待已经被持有的锁时，采用了自旋等待(spin-waiting)的技术，就是不停地检查标志的值。自旋等待在等待其他线程释放锁的时候会浪费时间。尤其是在单处理器上，一个等待线程等待的目标线程甚至无法运行(至少在上下文切换之前)！

* 基于测试并设置指令(test-and-set)实现可用的自旋锁 

  * 我们用如下的 C 代码片段来定义测试并设置指令做了什么：

    ```
    int TestAndSet(int *old_ptr， int new) { // 原子性的设置新值并返回旧值; 因为既可以测试旧值，又可以设置新值，所以我们把这条指令叫作“测试并设置”
        int old = *old_ptr;
        *old_ptr = new;
        return old;
    } 
    ```

* 这一条指令完全可以实现一个简单的自旋锁

  ```
  typedef struct lock_t { int flag; } lock_t; 
  void init(lock_t *mutex) { 
      mutex->flag = 0;
  } 
  void lock(lock_t *mutex) { 
      while (TestAndSet(&mutex->flag， 1));
  	// 获取到锁
  } 
  void unlock(lock_t *mutex) { 
      mutex->flag = 0;
  } 
  ```

  我们来确保理解为什么这个锁能工作。首先假设一个线程在运行，调用 lock()，没有其他线程持有锁，所以 flag 是 0。当调用 ``TestAndSet(flag， 1)`` 方法，返回 0，线程会跳出 while循环，获取锁。同时也会原子的设置 flag 为 1，标志锁已经被持有。当线程离开临界区，调用 unlock()将 flag 清理为 0。第二种场景是，当某一个线程已经持有锁(即 flag 为 1)。本线程调用 lock()，然后调用``TestAndSet(flag， 1)``，这一次返回 1。只要另一个线程一直持有锁，``TestAndSet()``会重复返回 1，本线程会一直自旋。当 flag 终于被改为 0，本线程会调用 ``TestAndSet()``，返回 0 并且原子地设置为 1，从而获得锁，进入临界区。

* 将测试(test 旧的锁值)和设置(set 新的值)合并为一个原子操作之后，我们保证了只有一个线程能获取锁。这就实现了一个有效的互斥原语！
* 你现在可能也理解了为什么这种锁被称为自旋锁(spin lock)。这是最简单的一种锁，一直自旋，利用 CPU 周期，直到锁可用。在单处理器上，需要抢占式的调度器(preemptive scheduler，即不断通过时钟中断一个线程，运行其他线程)。否则，自旋锁在单 CPU 上无法使用，因为一个自旋的线程永远不会放弃 CPU。

##### 比较并交换 

* 某些系统提供了另一个硬件原语，即比较并交换指令(compare-and-exchange)。这条指令的 C 语言伪代码：

  ```
  int CompareAndSwap(int *ptr， int expected， int new) { 
      int actual = *ptr; 
      if (actual == expected) 
      	*ptr = new; 
      return actual; 
  } 
  // 比较并交换的基本思路是检测 ptr 指向的值是否和 expected 相等；如果是，更新 ptr 所指的值为新值。否则，什么也不做。不论哪种情况，都返回该内存地址的实际值，让调用者能够知道执行是否成功。
  ```

* 有了比较并交换指令，就可以实现一个锁，类似于用测试并设置那样。例如，我们只要用下面的代码替换 lock()函数：

  ```
  void lock(lock_t *lock) { 
      while (CompareAndSwap(&lock->flag， 0， 1) == 1) ;
  } 
  ```

  其余代码和上面测试并设置的例子完全一样。代码工作的方式很类似，检查标志是否为 0，如果是，原子地交换为 1，从而获得锁。锁被持有时，竞争锁的线程会自旋。

##### 链接的加载和条件式存储指令 

* 一些平台提供了实现临界区的一对指令。链接的加载(load-linked)和条件式存储(store-conditional)可以用来配合使用，实现其他并发结构。Alpha、PowerPC 和 ARM 都提供类似的指令。这些指令的 C 语言伪代码：

  ```
  int LoadLinked(int *ptr) { 
      return *ptr; 
  } 
  int StoreConditional(int *ptr， int value) { 
      if (no one has updated *ptr since the LoadLinked to this address) { 
          *ptr = value; 
          return 1;
      } else { 
          return 0;
      } 
  } 
  // 条件式存储(store-conditional)指令，只有上一次加载的地址在期间都没有更新时，才会成功，(同时更新刚才链接的加载的地址的值)。成功时，条件存储返回1，并将 ptr 指的值更新为 value。失败时，返回 0，并且不会更新值。
  ```

* 使用链接的加载和条件式存储来实现一个锁

  ```
  void lock(lock_t *lock) { 
      while (1) { 
          // 线程发现锁被释放且通过条件存储获取锁成功，从而可以进入临界区
       	while (LoadLinked(&lock->flag) || !StoreConditional(&lock->flag， 1)) ;
      } 
  } 
  void unlock(lock_t *lock) { 
      lock->flag = 0; 
  }
  ```

* 获取并增加

  * 一个硬件原语是获取并增加(fetch-and-add)指令，它能原子地返回特定地址的旧值，并且让该值自增一。获取并增加的 C 语言伪代码如下：在这个例子中，我用获取并增加指令，实现一个有趣的 ticket 锁

    ```
    int FetchAndAdd(int *ptr) { 
        int old = *ptr; 
        *ptr = old + 1; 
        return old; 
    } 
    typedef struct lock_t { 
        int ticket; 
        int turn; 
    } lock_t; 
    void lock_init(lock_t *lock) { 
        lock->ticket = 0; 
        lock->turn = 0; 
    } 
    void lock(lock_t *lock) { 
        int myturn = FetchAndAdd(&lock->ticket); 
        while (lock->turn != myturn) ; // spin 
    } 
    void unlock(lock_t *lock) { 
        FetchAndAdd(&lock->turn); 
    } 
    ```

    如果线程希望获取锁，首先对一个 ticket 值执行一个原子的获取并相加指令。这个值作为该线程的“turn”(顺位，即 myturn)。根据全局共享的 lock->turn 变量，当某一个线程的(myturn == turn)时，则轮到这个线程进入临界区。unlock 则是增加 turn，从而下一个等待线程可以进入临界区。不同于之前的方法：本方法能够保证所有线程都能抢到锁。只要一个线程获得了 ticket值，它最终会被调度。之前的方法则不会保证。比如基于测试并设置的方法，一个线程有可能一直自旋，即使其他线程在获取和释放锁。

* 评价自旋锁 

  * 正确性：自旋锁一次只允许一个线程进入临界区。因此，这是正确的锁。
  * 公平性： 自旋锁不提供任何公平性保证。实际上，自旋的线程在竞争条件下可能会永远自旋。自旋锁没有公平性，可能会导致饿死。
  * 性能： 对于自旋锁，在单 CPU 的情况下，性能开销相当大。假设一个线程持有锁进入临界区时被抢占。调度器可能会运行其他每一个线程(假设有 N−1 个这种线程)。而其他线程都在竞争锁，都会在放弃 CPU 之前，自旋一个时间片，浪费 CPU 周期。但是，在多 CPU 上，自旋锁性能不错(如果线程数大致等于 CPU 数)。假设线程 A 在CPU 1，线程 B 在 CPU 2 竞争同一个锁。线程 A(CPU 1)占有锁时，线程 B 竞争锁就会自旋(在 CPU 2 上)。然而，临界区一般都很短，因此很快锁就可用，然后线程 B 获得锁。自旋等待其他处理器上的锁，并没有浪费很多 CPU 周期，因此效果不错。

* 基于硬件的锁简单而且有效，这也是任何好的系统或者代码的特点。但是，某些场景下，这些解决方案会效率低下。以两个线程运行在单处理器上为例，当一个线程(线程 0)持有锁时，被中断。第二个线程(线程 1)去获取锁，发现锁已经被持有。因此，它就开始自旋。接着自旋。然后它继续自旋。最后，时钟中断产生，线程 0 重新运行，它释放锁。最后(比如下次它运行时)，线程 1 不需要继续自旋了，它获取了锁。因此，类似的场景下，一个线程会一直自旋检查一个不会改变的值，浪费掉整个时间片！如果有 N 个线程去竞争一个锁，情况会更糟糕。同样的场景下，会浪费 N-1 个时间片，只是自旋并等待一个线程释放该锁。

##### 放弃 CPU

* 硬件支持让我们有了很大的进展：我们已经实现了有效、公平(通过 ticket 锁)的锁。但是，问题仍然存在：如果临界区的线程发生上下文切换，其他线程只能一直自旋，等待被中断的(持有锁的)进程重新运行。有什么好办法？第一种简单友好的方法就是，在要自旋的时候，放弃 CPU。

  ```
  void lock() { 
      while (原子指令尝试获取并设置锁)	 
          yield();	// 操作系统提供原语 yield()，线程可以调用它主动放弃 CPU，让其他线程运行
  } 
  ```

  线程可以处于 3 种状态之一(运行、就绪和阻塞)。yield()系统调用能够让运行态变为就绪态，从而允许其他线程运行。因此，让出线程本质上取消调度(deschedules)了它自己。

* 考虑在单 CPU 上运行两个线程。在这个例子中，基于 yield 的方法十分有效。一个线程调用 lock()，发现锁被占用时，让出 CPU，另外一个线程运行，完成临界区。在这个简单的例子中，让出方法工作得非常好。
* 现在来考虑许多线程(例如 100 个)反复竞争一把锁的情况。在这种情况下，一个线程持有锁，在释放锁之前被抢占，其他 99 个线程分别调用 lock()，发现锁被抢占，然后让出 CPU。假定采用某种轮转调度程序，这 99 个线程会一直处于运行—让出这种模式，直到持有锁的线程再次运行。虽然比原来的浪费 99 个时间片的自旋方案要好，但这种方法仍然成本很高，上下文切换的成本是实实在在的，因此浪费很大。更糟的是，我们还没有考虑饿死的问题。一个线程可能一直处于让出的循环，而其他线程反复进出临界区。很显然，我们需要一种方法来解决这个问题。

##### 休眠替代自旋 

* 前面一些方法的真正问题是存在太多的偶然性。调度程序决定如何调度。如果调度不合理，线程或者一直自旋，或者立刻让出 CPU。无论哪种方法，都可能造成浪费，也可能饿死。因此，我们必须显式地施加某种控制，决定锁释放时，谁能抢到锁。为了做到这一点，我们需要操作系统的更多支持，并需要一个队列来保存等待锁的线程。

* 简单起见，我们提供了两个调用：park()能够让调用线程休眠，unpark(threadID) 则会唤醒 threadID 标识的线程。可以用这两个调用来实现锁，让调用者在获取不到锁时睡眠，在锁可用时被唤醒。

  ```
  typedef struct lock_t {
      int flag;               // 锁占用标识
      int guard;              // 共享资源操作临界区变量
      queue_t *q;             // 通过队列来控制谁会获得锁，避免饿死。
  } lock_t;
  void lock_init(lock_t *m) {
      m->flag = 0;
      m->guard = 0;
      queue_init(m->q);
  }
  void lock(lock_t *m) {
      while (TestAndSet(&m->guard， 1) == 1);  // 尝试进入临界区(只有一个线程可进入); 存在自旋等待， 不过等待时间较短(后续几段代码的时间)
      if (m->flag == 0) {                     // 锁被释放
          m->flag = 1;                        //      获取锁， 将 guard 设置为 0，然后让出 CPU。
          m->guard = 0;
      } else {                                // 锁已被持有
          queue_add(m->q， gettid());          //      把自己加入队列，将 guard 设置为 0，然后让出 CPU。
          m->guard = 0;
          park();
      }
  }
  void unlock(lock_t *m) {
      while (TestAndSet(&m->guard， 1) == 1);   // 尝试进入临界区
      if (queue_empty(m->q))                   // 不存在可被唤醒的线程， 锁释放
          m->flag = 0;
      else
          unpark(queue_remove(m->q));          // 不否存在可被唤醒的线程， 直接唤醒执行
      m->guard = 0;                            // 将 guard 设置为 0，然后让出 CPU。
  }
  ```

  当要唤醒另一个线程时，flag 并没有设置为 0。为什么呢？其实这不是错，而是必须的！线程被唤醒时，就像是从 park()调用返回。但是，此时它没有持有 guard，所以也不能将 flag 设置为 1。因此，我们就直接把锁从释放的线程传递给下一个获得锁的线程，期间 flag 不必设置为 0。最后，如果不凑巧，一个线程将要 park，假定它应该睡到锁可用时。这时切换到另一个线程(比如持有锁的线程)，这可能会导致麻烦。比如，如果该线程随后释放了锁。接下来第一个线程的 park 会永远睡下去(可能)。这种问题有时称为唤醒/等待竞争。为了避免这种情况，我们需要额外的工作。

* 通过增加了第三个系统调用 separk()来解决这一问题。通过 setpark()，一个线程表明自己马上要 park。如果刚好另一个线程被调度，并且调用了 unpark，那么后续的 park调用就会直接返回，而不是一直睡眠。lock()调用可以做一点小修改：

  ```
  queue_add(m->q， gettid()); 
  	// ....
      setpark(); // new code 
      m->guard = 0; 
      // ....
  ```

* 另外一种方案就是将 guard 传入内核。在这种情况下，内核能够采取预防措施，保证原子地释放锁，把运行线程移出队列。

* 为了构建更有效率的锁，一个操作系统提供的一种支持。其他操作系统也提供了类似的支持，但细节不同。

* Linux 采用的是一种古老的锁方案，多年来不断被采用，现在也称为两阶段锁(two-phase lock)。两阶段锁意识到自旋可能很有用，尤其是在很快就要释放锁的场景。因此，两阶段锁的第一阶段会先自旋一段时间，希望它可以获取锁。但是，如果第一个自旋阶段没有获得锁，第二阶段调用者会睡眠，直到锁可用。


#### 基于锁的并发数据结构

##### 并发计数器 

* 计数器是最简单的一种数据结构，使用广泛而且接口简单。没有同步机制的计数器很简单，只需要很少代码就能实现。现在我们的
  下一个挑战是：如何让计数器代码线程安全
  
  ```
  typedef struct counter_t {
      int value;
      pthread_mutex_t lock;
  } counter_t;
  void init(counter_t *c) {
      c->value = 0;
      Pthread_mutex_init(&c->lock， NULL);
  }
  void increment(counter_t *c) {
      Pthread_mutex_lock(&c->lock);
      c->value++;
      Pthread_mutex_unlock(&c->lock);
  }
  void decrement(counter_t *c) {
      Pthread_mutex_lock(&c->lock);
      c->value--;
      Pthread_mutex_unlock(&c->lock);
  }
  int get(counter_t *c) {
      Pthread_mutex_lock(&c->lock);
      int rc = c->value;
      Pthread_mutex_unlock(&c->lock);
      return rc;
  } 
  ```
  
  这个并发计数器简单、正确。实际上，它遵循了最简单、最基本的并发数据结构中常见的数据模式：它只是加了一把锁，在调用函数操作该数据结构时获锁，从调用返回时释放锁。
  
* 完美扩展： 多处理上运行的多线程就像单线程一样快。虽然总工作量增多，但是并行执行后，完成任务的时间并没有增加。
  
* 懒惰计数器： 通过多个局部计数器和一个全局计数器来实现一个逻辑计数器，其中每个CPU 核心有一个局部计数器。具体来说，在 4 个 CPU 的机器上，有 4 个局部计数器和 1 个全局计数器。除了这些计数器，还有锁：每个局部计数器有一个锁，全局计数器有一个。懒惰计数器的基本思想是这样的。如果一个核心上的线程想增加计数器，那就增加它的局部计数器，访问这个局部计数器是通过对应的局部锁同步的。因为每个 CPU 有自己的局部计数器，不同 CPU 上的线程不会竞争，所以计数器的更新操作可扩展性好。但是，为了保持全局计数器更新(以防某个线程要读取该值)，局部值会定期转移给全局计数器，方法是获取全局锁，让全局计数器加上局部计数器的值，然后将局部计数器置零。
  
* 这种局部转全局的频度，取决于一个阈值，这里称为 S(sloppiness)。S 越小，懒惰计数器则越趋近于非扩展的计数器。S 越大，扩展性越强，但是全局计数器与实际计数的偏差越大。
  
  ```
  typedef struct counter_t {
      int global; 				        // 全局计数器
      pthread_mutex_t glock; 		        // 全局锁
      int local[NUMCPUS];                 // 局部计数器
      pthread_mutex_t llock[NUMCPUS];     // 局部锁
      int threshold;                      // 同步临界值： 当局部计数器值>=threshold时，将其同步到全局计数器
  } counter_t;
  void init(counter_t *c， int threshold) {
      c->threshold = threshold;
      c->global = 0;
      pthread_mutex_init(&c->glock， NULL);
      int i;
      for (i = 0; i < NUMCPUS; i++) {
          c->local[i] = 0;
          pthread_mutex_init(&c->llock[i]， NULL);
      }
  }
  void update(counter_t *c， int threadID， int amt) {
      pthread_mutex_lock(&c->llock[threadID]);
      c->local[threadID] += amt;
      if (c->local[threadID] >= c->threshold) {
          pthread_mutex_lock(&c->glock);
          c->global += c->local[threadID];
          pthread_mutex_unlock(&c->glock);
          c->local[threadID] = 0;
      }
      pthread_mutex_unlock(&c->llock[threadID]);
  }
  int get(counter_t *c) {
      pthread_mutex_lock(&c->glock);
      int val = c->global;
      pthread_mutex_unlock(&c->glock);
      return val; // only approximate!
  }
  ```
##### 并发链表
* 接下来看一个更复杂的数据结构，链表。同样，我们从一个基础实现开始。简单起见，
  我们只关注链表的插入操作，其他操作比如查找、删除等就交给读者了。图 29.6 展示了这
  个基本数据结构的代码。
  
  ```
  void List_Init(list_t *L) {
      L->head = NULL;
      pthread_mutex_init(&L->lock， NULL);
  }
  void List_Insert(list_t *L， int key) {
      node_t *new = malloc(sizeof(node_t));
      if (new == NULL) {
          perror("malloc");
          return;
      }
      new->key = key;
      pthread_mutex_lock(&L->lock);       // 在对链表执行实际操作时才获取锁
      new->next = L->head;
      L->head = new;
      pthread_mutex_unlock(&L->lock);
  }
  int List_Lookup(list_t *L， int key) {
      int rv = -1;
      pthread_mutex_lock(&L->lock);
      node_t *curr = L->head;
      while (curr) {
          if (curr->key == key) {
              rv = 0;
              break;
          }
          curr = curr->next;
      }
      pthread_mutex_unlock(&L->lock);
      return rv;
  }
  ```
  
  
  
* 尽管我们有了基本的并发链表，但又遇到了这个链表扩展性不好的问题。研究人员发现的增加链表并发的技术中，有一种叫作过手锁(hand-over-hand locking，也叫作锁耦合，lock coupling)。原理也很简单。每个节点都有一个锁，替代之前整个链表一个锁。遍历链表的时候，首先抢占下一个节点的锁，然后释放当前节点的锁。从概念上说，过手锁链表有点道理，它增加了链表操作的并发程度。但是实际上，在遍历的时候，每个节点获取锁、释放锁的开销巨大，很难比单锁的方法快。即使有大量的线程和很大的链表，这种并发的方案也不一定会比单锁的方案快。
  
* 有一个通用建议，对并发代码和其他代码都有用，即注意控制流的变化导致函数返回和退出，或其他错误情况导致函数停止执行。因为很多函数开始就会获得锁，分配内存，或者进行其他一些改变状态的操作，如果错误发生，代码需要在返回前恢复各种状态，这容易出错。因此，最好组织好代码，减少这种模式。
##### 并发队列

* 总有一个标准的方法来创建一个并发数据结构：添加一把大锁。对于一个队列，我们将跳过这种方法。仔细研究这段代码，你会发现有两个锁，一个负责队列头，另一个负责队列尾。这两个锁使得入队列操作和出队列操作可以并发执行，因为入队列只访问 tail 锁，而出队列只访问 head 锁。队列在多线程程序里广泛使用。然而，这里的队列(只是加了锁)通常不能完全满足这种程序的需求。更完善的有界队列，在队列空或者满时，能让线程等待。

  ```
  typedef struct node_t {
      int value;
      struct node_t *next;
  } node_t;
  
  typedef struct queue_t {
      node_t *head;
      node_t *tail;
      pthread_mutex_t headLock;
      pthread_mutex_t tailLock;
  } queue_t;
  
  void Queue_Init(queue_t *q) {
      node_t *tmp = malloc(sizeof(node_t));
      tmp->next = NULL;
      q->head = q->tail = tmp;
      pthread_mutex_init(&q->headLock， NULL);
      pthread_mutex_init(&q->tailLock， NULL);
  }
  
  void Queue_Enqueue(queue_t *q， int value) {
      node_t *tmp = malloc(sizeof(node_t));
      assert(tmp != NULL);
      tmp->value = value;
      tmp->next = NULL;
  
      pthread_mutex_lock(&q->tailLock);
      q->tail->next = tmp;
      q->tail = tmp;
      pthread_mutex_unlock(&q->tailLock);
  }
  
  int Queue_Dequeue(queue_t *q， int *value) {
      pthread_mutex_lock(&q->headLock);
      node_t *tmp = q->head;
      node_t *newHead = tmp->next;
      if (newHead == NULL) {
          pthread_mutex_unlock(&q->headLock);
          return -1; // queue was empty
      }
      *value = newHead->value;
      q->head = newHead;
      pthread_mutex_unlock(&q->headLock);
      free(tmp);
      return 0;
  }
  ```
##### 并发散列表 

* 我们讨论最后一个应用广泛的并发数据结构，散列表。我们只关注不需要调整大小的简单散列表。支持调整大小还需要一些工作，留作练习。

  ```
  #define BUCKETS (101)
  typedef struct hash_t {
      list_t lists[BUCKETS];
  } hash_t;
  void Hash_Init(hash_t *H) {
      int i;
      for (i = 0; i < BUCKETS; i++) {
          List_Init(&H->lists[i]);
      }
  }
  int Hash_Insert(hash_t *H， int key) {
      int bucket = key % BUCKETS;
      return List_Insert(&H->lists[bucket]， key);
  }
  int Hash_Lookup(hash_t *H， int key) {
      int bucket = key % BUCKETS;
      return List_Lookup(&H->lists[bucket]， key);
  }
  ```

  本例的散列表使用我们之前实现的并发链表，性能特别好。每个散列桶(每个桶都是一个链表)都有一个锁，而不是整个散列表只有一个锁，从而支持许多并发操作。

* 实现并发数据结构时，先从最简单的方案开始，也就是加一把大锁来同步。这样做，你很可能构建了正确的锁。如果发现性能问题，那么就改进方法，只要优化到满足需要即可， 避免不成熟的优化，不成熟的优化是所有坏事的根源。许多操作系统，在最初过渡到多处理器时都是用一把大锁，包括 Sun 和 Linux。在Linux 中，这个锁甚至有个名字，叫作 BKL(大内核锁，big kernel lock)。这个方案在很多年里都很有效，直到多 CPU系统普及，内核只允许一个线程活动成为性能瓶颈。终于到了为这些系统优化并发性能的时候了。Linux采用了简单的方案，把一个锁换成多个。
#### 条件变量

* 在很多情况下，线程需要检查某一条件(condition)满足之后，才会继续运行。例如，父线程需要检查子线程是否执行完毕。这种等待如何实现呢
  
  ```
  void *child(void *arg) {
      printf("child\n");
      // XXX how to indicate we are done?
      return NULL;
  }
  int main(int argc， char *argv[]) {
      printf("parent： begin\n");
      pthread_t c;
      Pthread_create(&c， NULL， child， NULL); // create child
      // XXX how to wait for child?
      printf("parent： end\n");
      return 0;
  }
  ```
  
  我们可以尝试用一个共享变量，父进程检查该变量的值并自旋等待。这种解决方案一般能工作，但是效率低下，因为主线程会自旋检查，浪费 CPU 时间。我们希望有某种方式让父线程休眠，直到等待的条件满足(即子线程完成执行)。
  
  ```
  volatile int done = 0;
  void *child(void *arg) {
      printf("child\n");
      done = 1;
      return NULL;
  }
  int main(int argc， char *argv[]) {
      printf("parent： begin\n");
      pthread_t c;
      Pthread_create(&c， NULL， child， NULL); // create child
      while (done == 0)
          ; // spin
      printf("parent： end\n");
      return 0;
  }
  ```
  
  多线程程序中，一个线程等待某些条件是很常见的。简单的方案是自旋直到条件满足，这是极其低效的，某些情况下甚至是错误的。那么，线程应该如何等待一个条件？

##### 定义和程序

* 线程可以使用条件变量(condition variable)，来等待一个条件变成真。条件变量是一个显式队列，当某些执行状态(即条件，condition)不满足时，线程可以把自己加入队列，等待该条件。另外某个线程，当它改变了上述状态时，就可以唤醒一个或者多个等待线程(通过在该条件上发信号)，让它们继续执行。

* 条件变量有两种相关操作：wait()和 signal()。线程要睡眠的时候，调用 wait()。当线程想唤醒等待在某个条件变量上的睡眠线程时，调用 signal()。
  
  ```
  //pthread_cond_wait(pthread_cond_t *c， pthread_mutex_t *m);
  //pthread_cond_signal(pthread_cond_t *c);
  int done = 0;	// 记录线程的运行状态
  pthread_mutex_t m = PTHREAD_MUTEX_INITIALIZER;		// 确保对done的操作是原子性的 (父： done == 0  子： done =1)， 避免竞态条件
  pthread_cond_t c = PTHREAD_COND_INITIALIZER;
  
  void thr_exit() {
      Pthread_mutex_lock(&m);
      done = 1;
      Pthread_cond_signal(&c);
      Pthread_mutex_unlock(&m);
  }
  void *child(void *arg) {
      printf("child\n");
      thr_exit();
      return NULL;
  }
  void thr_join() {
      Pthread_mutex_lock(&m);
      while (done == 0) 		// 发信号给线程只是唤醒它们，暗示状态发生了变化，但并不会保证在它运行之前状态一直是期望的情况。
          Pthread_cond_wait(&c， &m);
      Pthread_mutex_unlock(&m);
  }
  int main(int argc， char *argv[]) {
      printf("parent： begin\n");
      pthread_t p;
      Pthread_create(&p， NULL， child， NULL);
      thr_join();
      printf("parent： end\n");
      return 0;
  }
  ```
  
  wait()调用有一个参数，它是互斥量。它假定在 wait()调用时，这个互斥量是已上锁状态。wait()的职责是释放锁，并让调用线程休眠(原子地)。当线程被唤醒时(在另外某个线程发信号给它后)，它必须重新获取锁，再返回调用者。这样复杂的步骤也是为了避免在线程陷入休眠时，产生一些竞态条件。有两种情况需要考虑。第一种情况是父线程创建出子线程，但自己继续运行(假设只有一个处理器)，然后马上调用 thr_join()等待子线程。在这种情况下，它会先获取锁，检查子进程是否完成(还没有完成)，然后调用 wait()，让自己休眠。子线程最终得以运行，打印出“child”，并调用 thr_exit()函数唤醒父进程，这段代码会在获得锁后设置状态变量 done，然后向父线程发信号唤醒它。最后，父线程会运行，释放锁，打印出“parent：end”。第二种情况是，子线程在创建后，立刻运行，设置变量 done 为 1，调用 signal 函数唤醒其他线程(这里没有其他线程)，然后结束。父线程运行后，调用 thr_join()时，发现 done已经是 1 了，就直接返回。最后一点说明：你可能看到父线程使用了一个 while 循环，而不是 if 语句来判断是否需要等待。虽然从逻辑上来说没有必要使用循环语句，但这样做总是好的。

* 发信号时总是持有锁， 尽管并不是所有情况下都严格需要，但有效且简单的做法，还是在使用条件变量发送信号时持有锁。虽然上面的例子是必须加锁的情况，但也有一些情况可以不加锁，而这可能是你应该避免的。因此，为了简单，请在调用 signal 时持有锁。这个提示的反面，即调用 wait 时持有锁，不只是建议，而是 wait 的语义强制要求的。因为 wait 调用总是假设你调用它时已经持有锁、调用者睡眠之前会释放锁以及返回前重新持有锁。因此，这个提示的一般化形式是正确的：调用 signal 和 wait 时要持有锁。
* 记住一条关于条件变量的简单规则：总是使用 while 循环。虽然有时候不需要重新检查条件，但这样做总是安全的

##### 生产者/消费者(有界缓冲区)问题

* 假设有一个或多个生产者线程和一个或多个消费者线程。生产者把生成的数据项放入缓冲区；消费者从缓冲区取走数据项，以某种方式消费。

* 很多实际的系统中都会有这种场景

  * 在多线程的网络服务器中，一个生产者将HTTP 请求放入工作队列(即有界缓冲区)，消费线程从队列中取走请求并处理。
  * 在使用管道连接不同程序的输出和输入时，也会使用有界缓冲区，例如 ``grep foofile.txt | wc -l``。这个例子并发执行了两个进程，grep 和 wc 。grep 进程是生产者，wc 是进程是消费者，它们之间是内核中的有界缓冲区。因为有界缓冲区是共享资源，所以我们必须通过同步机制来访问它，以免产生竞态条
    件。

* 为了更好地理解这个问题，我们来看一些实际的代码。首先需要一个共享缓冲区，让生产者放入数据，消费者取出数据。简单起见，我们就拿一个整数来做缓冲区，两个内部函数将值放入缓冲区，从缓冲区取值。

  ```
  int buffer;     // 共享缓冲区
  int count = 0;  // 标识缓冲区是否存在数据
  void put(int value) {		// put()函数会假设缓冲区是空的，把一个值存在缓冲区，然后把 count设置为 1 表示缓冲区满了 [put为临界区]
      assert(count == 0);
      count = 1;
      buffer = value;
  }
  int get() {				  // get()函数会假设缓冲区是满的，把缓冲区清空后(即将 count 设置为 0)，并返回该值。[get为临界区]
      assert(count == 1);
      count = 0;
      return buffer;
  }
  ```

* 生产者线程和消费者线程

  ```
  cond_t empty， fill;                     // 条件变量： 生产者等待`缓冲区空`， 消费者等待`缓冲区满`; 故需要两个条件变量
  mutex_t mutex;                          // 临界区锁
  void *producer(void *arg) {             // 生产者
      int i;
      for (i = 0; i < loops; i++) {
          Pthread_mutex_lock(&mutex);
          while (count == 1)              // 当多个生产者存在时， 被唤醒不代表可以执行缓冲区可以生产
              Pthread_cond_wait(&empty， &mutex);
          put(i);
          Pthread_cond_signal(&fill);     // 生产者线程等待条件变量 empty，发信号给变量 fill
          Pthread_mutex_unlock(&mutex);
      }
  }
  void *consumer(void *arg) {             // 消费者
      int i;
      for (i = 0; i < loops; i++) {
          Pthread_mutex_lock(&mutex);
          while (count == 0)              // 当多个消费者存在时， 被唤醒不代表可以执行缓冲区可以消费
              Pthread_cond_wait(&fill， &mutex);
          int tmp = get();
          Pthread_cond_signal(&empty);    // 消费者线程等待 fill，发信号给 empty
          Pthread_mutex_unlock(&mutex);
          printf("%d\n"， tmp);
      }
  }
  ```

  必须对条件变量使用while： 假设有两个消费者(Tc1 和 Tc2)，一个生产者(Tp)。首先，一个消费者(Tc1)先开始执行，它获得锁，检查缓冲区是否可以消费，然后等待。接着生产者运行。它获取锁，检查缓冲区是否满，发现没满就给缓冲区加入一个数字。然后生产者发出信号，说缓冲区已满。关键的是，这让第一个消费者不再睡在条件变量上，进入就绪队列。Tc1 现在可以运行(但还未运行)。生产者继续执行，直到发现缓冲区满后睡眠。这时问题发生了：另一个消费者(Tc2)抢先执行，消费了缓冲区中的值。现在假设 Tc1 运行，在从 wait 返回之前，它获取了锁，然后返回。然后它调用了 get() ，但缓冲区已无法消费！断言触发，代码不能像预期那样工作。显然，我们应该设法阻止 Tc1 去消费，因为 Tc2 插进来，消费了缓冲区中之前生产的一个值。

  必须使用多个条件变量： 假设两个消费者(Tc1 和 Tc2)先运行，都睡眠了。生产者开始运行，在缓冲区放入一个值，唤醒了一个消费者(假定是 Tc1)，并开始睡眠。现在是一个消费者马上要运行(Tc1)，两个线程(Tc2 和 Tp)都等待在同一个条件变量上。消费者 Tc1 醒过来并从 wait()调用返回，重新检查条件，发现缓冲区是满的，消费了这个值。这个消费者然后在该条件上发信号，唤醒一个在睡眠的线程。但是，应该唤醒哪个线程呢？因为消费者已经清空了缓冲区，很显然，应该唤醒生产者。但是，如果它唤醒了 Tc2(这绝对是可能的，取决于等待队列是如何管理的)，问题就出现了。具体来说，消费者 Tc2 会醒过来，发现队列为空，又继续回去睡眠。生产者 Tp 刚才在缓冲区中放了一个值，现在在睡眠。另一个消费者线程 Tc1 也回去睡眠了。3 个线程都在睡眠，显然是一个缺陷。

##### 最终的生产者/消费者方案 
* 我们现在有了可用的生产者/消费者方案，但不太通用。我们最后的修改是提高并发和效率。具体来说，增加更多缓冲区槽位，这样在睡眠之前，可以生产多个值。同样，睡眠之前可以消费多个值。单个生产者和消费者时，这种方案因为上下文切换少，提高了效率。多个生产者和消费者时，它甚至支持并发生产和消费，从而提高了并发。幸运的是，和现有方案相比，改动也很小。第一处修改是缓冲区结构本身，以及对应的 put()和 get()方法)。我们还稍稍修改了生产者和消费者的检查条件，以便决定是否要睡眠。生产者只有在缓冲区满了的时候才会睡眠，消费者也只有在队列为空的时候睡眠。至此，我们解决了生产者/消费者问题
  
  ```
  #define MAX 2
  int loops = 100;
  int buffer[MAX];
  int curr = 0;
  int use = 0;
  int count = 0;
  pthread_cond_t empty， fill;
  pthread_mutex_t mutex;
  void put(int value) {
      buffer[curr] = value;
      curr = (curr + 1) % MAX;
      count++;
  }
  int get() {
      int tmp = buffer[use];
      use = (use + 1) % MAX;
      count--;
      return tmp;
  }
  void *producer(void *arg) {
      int i;
      for (i = 0; i < loops; i++) {
          pthread_mutex_lock(&mutex);
          while (count == MAX)
              pthread_cond_wait(&empty， &mutex);
          put(i);
          pthread_cond_signal(&fill);
          pthread_mutex_unlock(&mutex);
          printf("%s producer %d\n"， (char*)arg， i);
      }
  }
  void *consumer(void *arg) {
      int i;
      for (i = 0; i < loops; i++) {
          pthread_mutex_lock(&mutex);
          while (count == 0)
              pthread_cond_wait(&fill， &mutex);
          int tmp = get();
          pthread_cond_signal(&empty);
          pthread_mutex_unlock(&mutex);
          printf("%s consumer %d\n"， (char*)arg， tmp);
      }
  }
  int main(int argc， char *argv[]) {
      printf("main run\n");
      pthread_t p1， p2， t1， t2;
      pthread_mutex_init(&mutex， NULL);
      pthread_cond_init(&empty， NULL);
      pthread_cond_init(&fill， NULL);
      assert(!pthread_create(&p1， NULL， producer， "p1"));
      assert(!pthread_create(&p2， NULL， producer， "p2"));
      assert(!pthread_create(&t1， NULL， consumer， "t1"));
      assert(!pthread_create(&t2， NULL， consumer， "t2"));
      pthread_join(p1， NULL);
      pthread_join(p2， NULL);
      pthread_join(t1， NULL);
      pthread_join(t2， NULL);
      pthread_cond_destroy(&empty);
      pthread_cond_destroy(&fill);
      pthread_mutex_destroy(&mutex);
  }
  ```
##### 覆盖条件
* 现在再来看条件变量的一个例子。一个简单的多线程内存分配库。
  
  ```
  // how many bytes of the heap are free?
  int bytesLeft = MAX_HEAP_SIZE;
  // need lock and condition too
  cond_t c;
  mutex_t m;
  void *allocate(int size) {
      Pthread_mutex_lock(&m);
      while (bytesLeft < size)
          Pthread_cond_wait(&c， &m);
      void *ptr = ...; // get mem from heap
      bytesLeft -= size;
      Pthread_mutex_unlock(&m);
      return ptr;
  }
  void free(void *ptr， int size) {
      Pthread_mutex_lock(&m);
      bytesLeft += size;
      Pthread_cond_signal(&c); // whom to signal??
      Pthread_mutex_unlock(&m);
  }
  ```
  
  从代码中可以看出，当线程调用进入内存分配代码时，它可能会因为内存不足而等待。相应的，线程释放内存时，会发信号说有更多内存空闲。但是，代码中有一个问题：应该唤醒哪个等待线程(可能有多个线程)？考虑以下场景。假设目前没有空闲内存，线程 Ta 调用 allocate(100)，接着线程 Tb 请求较少的内存，调用 allocate(10)。Ta和 Tb 都等待在条件上并睡眠，没有足够的空闲内存来满足它们的请求。这时，假定第三个线程 Tc调用了 free(50)。遗憾的是，当它发信号唤醒等待线程时，可能不会唤醒申请 10 字节的 Tb 线程。而 Ta 线程由于内存不够，仍然等待。因为不知道唤醒哪个(或哪些)线程，所以图中代码无法正常工作。所以在此情况， 需要唤醒所有等待线程.
#### 信号量

##### 信号量的定义 

* 信号量是有一个整数值的对象，可以用两个函数来操作它。是sem_wait()和 sem_post()。因为信号量的初始值能够决定其行为，所以首先要初始化信号量，才能调用其他函数与之交互。
  
  ```
  #include <semaphore.h>
  sem_t s;
  sem_init(&s， 0， 1);
  
  int sem_wait(sem_t *s) { // sem_wait()要么立刻返回(调用 sem_wait()时，信号量的值大于等于 1)，要么会让调用线程挂起，直到之后的一个 post 操作
      decrement the value of semaphore s by one
      wait if value of semaphore s is negative
  }
  int sem_post(sem_t *s) { // sem_post()并没有等待某些条件满足。它直接增加信号量的值，如果有等待线程，唤醒其中一个。
      increment the value of semaphore s by one
      if there are one or more threads waiting， wake one
  }
  ```
  
  当信号量的值为负数时，这个值就是等待线程的个数。

##### 二值信号量(锁) 

* 信号量的第一种用法是：用信号量作为锁。直接把临界区用一对 sem_wait()/sem_post()环绕。但是，为了使这段代码正常工作，信号量 m 的初始应该是 1.

  ```
  sem_t m;
  sem_init(&m， 0， X); // initialize semaphore to X; what should X be?
  sem_wait(&m);
  // critical section here
  sem_post(&m);
  ```

  为了说明清楚，我们假设有两个线程的场景。第一个线程(线程 0)调用了 sem_wait()，它把信号量的值减为 0。然后，它只会在值小于 0 时等待。因为值是 0，调用线程从函数返回并继续，线程 0 现在可以自由进入临界区。线程 0 在临界区中，如果没有其他线程尝试获取锁，当它调用 sem_post()时，会将信号量重置为 1(因为没有等待线程，不会唤醒其他线程)。如果线程 0 持有锁(即调用了 sem_wait()之后，调用 sem_post()之前)，另一个线程(线程 1)调用 sem_wait()尝试进入临界区，这种情况下，线程 1把信号量减为−1，然后等待(自己睡眠，放弃处理器)。线程 0 再次运行，它最终调用sem_post()，将信号量的值增加到 0，唤醒等待的线程(线程 1)，然后线程 1 就可以获取锁。线程 1 执行结束时，再次增加信号量的值，将它恢复为 1。
##### 信号量用作条件变量 

* 信号量也可以用在一个线程暂停执行，等待某一条件成立的场景。例如，一个线程要等待一个链表非空，然后才能删除一个元素。在这种场景下，通常一个线程等待条件成立，另外一个线程修改条件并发信号给等待线程，从而唤醒等待线程。因为等待线程在等待某些条件发生变化，所以我们将信号量作为条件变量。
  
* 下面是一个简单例子。假设一个线程创建另外一线程，并且等待它结束。
  
  ```
  sem_t s;
  void *child(void *arg) {
      printf("child\n");
      sem_post(&s);
      return NULL;
  }
  int main(int argc， char *argv[]) {
      sem_init(&s， 0， 0); 				// 信号量初始化为0： 当main直接执行时，wait等待; 当child执行时， 信号量更新为1， main可直接执行完成
      printf("parent： begin\n");
      pthread_t c;
      Pthread_create(c， NULL， child， NULL);
      sem_wait(&s);
      printf("parent： end\n");
      return 0;
  }
  ```
  
  第一种情况，父线程创建了子线程，但是子线程并没有运行。这种情况下，父线程将信号量减为−1，然后睡眠等待；子线程运行的时候，调用 sem_post()，信号量增加为 0，唤醒父线程，父线程然后从 sem_wait()返回，完成该程序。第二种情况是子线程在父线程调用 sem_wait()之前就运行结束。在这种情况下，子线程会先调用 sem_post()，将信号量从 0 增加到 1。然后当父线程有机会运行时，会调用sem_wait()，发现信号量的值为 1。于是父线程将信号量从 1 减为 0，没有等待，直接从sem_wait()返回，也达到了预期效果。
  
##### 生产者/消费者(有界缓冲区)问题 
* 第一次尝试解决该问题，我们用两个信号量 empty 和 full 分别表示缓冲区空或者满。
  
  ```
  #define MAX 2
  int loops = 100;
  int buffer[MAX];        // 缓冲区
  int fill = 0;           // 生产指针
  int use = 0;            // 消费指针
  sem_t empty;            // 有多少空槽位可供生产数据
  sem_t full;             // 有多少数据可供消费
  sem_t mutex;            // 临界区操作互斥锁： 多生产者/多消费者情况下， 可能有多个线程同时进入临界区进行生产/消费活动。此时会产生竞态条件
  void put(int value) {   // 生产数据：临界区(需保护)
      buffer[fill] = value;
      fill = (fill + 1) % MAX;
  }
  int get() {             // 消费数据：临界区(需保护)
      int tmp = buffer[use];
      use = (use + 1) % MAX;
      return tmp;
  }
  void *producer(void *arg) { // 生产者
      int i;
      for (i = 0; i < loops; i++) {
          sem_wait(&empty);
          sem_wait(&mutex);	// 应当尽可能减小互斥锁的作用域.避免死锁
          put(i);
          sem_post(&mutex);
          printf("producer %d ： %d\n"， *(int *)arg， i);
          sem_post(&full);
      }
  }
  void *consumer(void *arg) { // 消费者
      for (int i = 0; i < loops; i++) {
          sem_wait(&full);
          sem_wait(&mutex);
          int tmp = get();
          sem_post(&mutex);
          sem_post(&empty);
          printf("consumer %d ： %d\n"， *(int *)arg， tmp);
      }
  }
  int main(int argc， char *argv[]) {
      // sem
      sem_init(&empty， PTHREAD_PROCESS_PRIVATE， MAX);
      sem_init(&full， PTHREAD_PROCESS_PRIVATE， 0);
      sem_init(&mutex，  PTHREAD_PROCESS_PRIVATE， 1);
      // pthread
      pthread_t p1， p2， c1， c2;
      int pid1 = 1， pid2 = 2， cid1 = 1， cid2 = 2;
      assert(!pthread_create(&p1， NULL， producer， &pid1));
      assert(!pthread_create(&p2， NULL， producer， &pid2));
      assert(!pthread_create(&c1， NULL， consumer， &cid1));
      assert(!pthread_create(&c2， NULL， consumer， &cid2));
      // destroy
      assert(!pthread_join(p1， NULL));
      assert(!pthread_join(p2， NULL));
      assert(!pthread_join(c1， NULL));
      assert(!pthread_join(c2， NULL));
      sem_destroy(&empty);
      sem_destroy(&full);
  }
  ```
  
##### 读者—写者锁
* 另一个经典问题源于对更加灵活的锁定原语的渴望，它承认不同的数据结构访问可能需要不同类型的锁。例如，一个并发链表有很多插入和查找操作。插入操作会修改链表的状态(因此传统的临界区有用)，而查找操作只是读取该结构，只要没有进行插入操作，我们可以并发的执行多个查找操作。读者—写者锁(reader-writer lock)就是用来完成这种操作的。
  
  ```
  typedef struct _rwlock_t {
      sem_t lock;             // 读者操作互斥锁(二元信号量)
      sem_t writelock;        // 保证只有一个写者能获得锁进入临界区.从而更新数据结构(二元信号量)
      int readers;            // 读者数量
  } rwlock_t;
  void rwlock_init(rwlock_t *rw) {
      rw->readers = 0;
      sem_init(&rw->lock， 0， 1);
      sem_init(&rw->writelock， 0， 1);
  }
  void rwlock_acquire_readlock(rwlock_t *rw) {    // 获取读锁时，读者首先要获取 lock，然后增加 reader变 量，追踪目前有多少个读者在访问该数据结构
      sem_wait(&rw->lock);
      rw->readers++;
      if (rw->readers == 1)
          sem_wait(&rw->writelock);               // 当第一个读者获取该锁时。在这种情况下，读者也会获取写
      sem_post(&rw->lock);
  }
  void rwlock_release_readlock(rwlock_t *rw) {
      sem_wait(&rw->lock);
      rw->readers--;
      if (rw->readers == 0)
          sem_post(&rw->writelock);               // 最后一个退出的写者在“writelock”信号量上调用sem_post()，从而让等待的写者能够获取该锁。
      sem_post(&rw->lock);
  }
  void rwlock_acquire_writelock(rwlock_t *rw) {   // 获得写锁
      sem_wait(&rw->writelock);                   // 想要获取写锁的线程，就必须等到所有的读者都结束。
  }
  void rwlock_release_writelock(rwlock_t *rw) {   // 释放写锁
      sem_post(&rw->writelock);
  }
  ```
  
  当写者先执行并获取到writelock时，所有后续读者和第一个读者都在writelock上等待锁释放(其它写者等待第一个读者的lock锁释放)。当第一个读者释放writelock之后， 第一个读者和后续写者可以竞争writelock锁，当第一个读者获取到writelock后， 它执行读取操作，释放lock， 后续读者也可以继续并发读取。后续写者想要获取写锁的线程，就必须等到所有的读者都结束。这一方案可行(符合预期)，但有一些缺陷，尤其是公平性。读者很容易饿死写者。存在复杂一些的解决方案，如：有写者等待时，如何能够避免更多的读者进入并持有锁。
  
* 哲学家就餐问题是一个著名的并发问题，它由 Dijkstra提出来并解决。这个问题的基本情况是：假定有 5 位“哲学家”围着一个圆桌。每两位哲学家之间有一把餐叉(一共 5 把)。哲学家有时要思考一会，不需要餐叉；有时又要就餐。而一位哲学家只有同时拿到了左手边和右手边的两把餐叉，才能吃到东西。关于餐叉的竞争以及随之而来的同步问题，就是我们在并发编程中研究它的原因。下面是每个哲学家的基本循环：
  
  ```
  while (1) {
      think();	
      getforks();
      eat();
      putforks();
  }
  ```
  
  关键的挑战就是如何实现 getforks()和 putforks()函数，保证没有死锁，没有哲学家饿死，并且并发度更高(尽可能让更多哲学家同时吃东西)。我们会用一些辅助函数，帮助构建解决方案。它们是：
  
  ```
  int left(int p) { return p; }				// 哲学家 p 希望用左手边的叉子，他们就调用 left(p)
  int right(int p) { return (p + 1) % 5; } 	 // 手边的叉子就用 right(p) 
  ```
  
  我们开始第一次尝试， 需要一些信号量来解决这个问题。假设需要 5 个，每个餐叉一个：sem_t forks[5]。假设我们把每个信号量(在 fork 数组中)都用 1 初始化。同时假设每个哲学家知道自己的编号(p)。我们可以写出 getforks()和 putforks()函数。
  
  ```
  void getforks() {
      sem_wait(forks[left(p)]);
      sem_wait(forks[right(p)]);
  }
  void putforks() {
      sem_post(forks[left(p)]);
      sem_post(forks[right(p)]);
  }
  ```
  
  这个(有问题的)解决方案背后的思路如下。为了拿到餐叉，我们依次获取每把餐叉的锁——先是左手边的，然后是右手边的。结束就餐时，释放掉锁。问题是死锁。假设每个哲学家都拿到了左手边的餐叉，他们每个都会阻塞住，并且一直等待另一个餐叉。具体来说，哲学家 0 拿到了餐叉 0，哲学家 1 拿到了餐叉 1，哲学家 2 拿到餐叉 2，哲学家 3 拿到餐叉 3，哲学家 4 拿到餐叉 4。所有的餐叉都被占有了，所有的哲学家都阻塞着，并且等待另一个哲学家占有的餐叉。
  
  破除依赖解： 决上述问题最简单的方法，就是修改某个或者某些哲学家的取餐叉顺序。事实上，Dijkstra 自己也是这样解决的。具体来说，假定哲学家 4(编写最大的一个)取餐叉的顺序不同。相应的代码如下：
  
  ```
  void getforks() {
      if (p == 4) {
          sem_wait(forks[right(p)]);
          sem_wait(forks[left(p)]);
      } else {
          sem_wait(forks[left(p)]);
          sem_wait(forks[right(p)]);
      }
  }
  ```
  
  因为最后一个哲学家会尝试先拿右手边的餐叉，然后拿左手边，所以不会出现每个哲学家都拿着一个餐叉，卡住等待另一个的情况，等待循环被打破了。想想这个方案的后果，让你自己相信它有效。还有其他一些类似的“著名”问题，比如吸烟者问题(cigarette smoker’s problem)，理发师问题(sleeping barber problem)。大多数问题只是让我们去理解并发。

* 哲学家就餐问题完整代码

  ```
  #define NUM 10000
  int left(int p) { return p; }               // 左手餐具号
  int right(int p) { return (p + 1) % NUM; }  // 右手餐具号
  sem_t forks[NUM];                           // 餐具互斥锁
  // 思考
  void think () { sleep(rand() % 5); }
  // 获取餐具
  void get_forks(int p) {
      if (p == NUM - 1) {
          sem_wait(&forks[right(p)]);
          sem_wait(&forks[left(p)]);
      } else {
          sem_wait(&forks[left(p)]);
          sem_wait(&forks[right(p)]);
      }
  }
  // 放下餐具
  void put_forks(int p) {
      sem_post(&forks[left(p)]);
      sem_post(&forks[right(p)]);
  }
  // 就餐
  void *dining(void *arg) {
      int p = *(int *) arg;
      think();
      get_forks(p);
      printf("哲学家 %d 就餐成功! \n"， p);
      put_forks(p);
  }
  int main(int argc， char *argv[]) {
      // 创建哲学家和自身编号， 初始化sem
      pthread_t * philosopher = (pthread_t *)calloc(NUM， sizeof(pthread_t));
      int * num = (int *)calloc(NUM， sizeof(int ));
      assert(philosopher);
      assert(num);
      for (int i = 0; i < NUM; ++i)           // 信号量须在子进程运行前初始化
          assert(!sem_init(&forks[i]， PTHREAD_PROCESS_PRIVATE， 1));
      for (int i = 0; i < NUM; ++i) {
          num[i] = i;
          assert(!pthread_create(&philosopher[i]， NULL， dining， &num[i]));
      }
      // 清除
      for (int i = 0; i < NUM; ++i)
          assert(!pthread_join(philosopher[i]， NULL));
      for (int i = 0; i < NUM; ++i)           // 信号量须在子进程运行后销毁
          assert(!sem_destroy(&forks[i]));
      free(philosopher);
      free(num);
  }
  ```

##### 如何实现信号量
* 最后，我们用底层的同步原语(锁和条件变量)，来实现自己的信号量。这个任务相当简单。
  
  ```
  typedef struct _Zem_t {
      int value;                  // 信号量值
      pthread_cond_t cond;        // 条件变量
      pthread_mutex_t lock;       // 锁
  } Zem_t;
  // 初始化线进行程调用： 初始化信号量
  void Zem_init(Zem_t *s， int value) {
      s->value = value;
      pthread_cond_init(&s->cond， NULL);
      pthread_mutex_init(&s->lock， NULL);
  }
  void Zem_wait(Zem_t *s) {
      pthread_mutex_lock(&s->lock);       // 获取锁， 依据信号量值判断是等待还是直接执行(递减信号量值)
      while (s->value <= 0)
          pthread_cond_wait(&s->cond， &s->lock);
      s->value--;
      pthread_mutex_unlock(&s->lock);
  }
  void Zem_post(Zem_t *s) {
      pthread_mutex_lock(&s->lock);       // 获取锁， 递增信号量值并唤醒一个等待线程
      s->value++;
      pthread_cond_signal(&s->cond);
      pthread_mutex_unlock(&s->lock);
  }
  void Zem_destroy(Zem_t *s) {
      pthread_cond_destroy(&s->cond);
      pthread_mutex_destroy(&s->lock);
  }
  ```

* 使用实例

  ```
  int num = 0; // 共享资源
  Zem_t mutex;
  void * incr(void *arg) {
      int upper = *(int*)arg;
      for (int i = 1; i <= upper; ++i) {
          Zem_wait(&mutex);
          num++;
          Zem_post(&mutex);
      }
  }
  int main(int argc， char *argv[]) {
      if (argc != 2 || atoi(argv[1]) < 1) {
          fprintf(stderr， "usage： ./a.out <integer(>0)>\n");
          exit(1);
      }
      Zem_init(&mutex， 1);
      int a = atoi(argv[1]);
      pthread_t t1， t2;
      assert(!pthread_create(&t1， NULL， incr， &a));
      assert(!pthread_create(&t2， NULL， incr， &a));
      pthread_join(t1， NULL);
      pthread_join(t2， NULL);
      Zem_destroy(&mutex);
      printf("Expect： %d Actual： %d\n"， a*2， num);
  }
  ```

  

#### 常见并发问题

##### 非死锁缺陷 

* 非死锁缺陷：违反原子性(atomicity violation)缺陷和错误顺序(order violation)缺陷。

* 违反原子性缺陷的例子
  
  ```
  Thread 1：：
  if (thd->proc_info) {		// 和p1处产生竞态条件
      ...
  fputs(thd->proc_info， ...);	
      ...
  }
  Thread 2：：
  thd->proc_info = NULL;		// p1
  // 解决策略： 对访问共享变量的临界区执行加锁访问
  ```
  
  这个例子中，两个线程都要访问 thd 结构中的成员 proc_info。第一个线程检查 proc_info非空，然后打印出值；第二个线程设置其为空。显然，当第一个线程检查之后，在 fputs()调用之前被中断，第二个线程把指针置为空；当第一个线程恢复执行时，由于引用空指针，导致程序奔溃。

* 违反原子性的定义是：“违反了多次内存访问中预期的可串行性(即代码段本意是原子的，但在执行中并没有强制实现原子性)”。


* 违反顺序缺陷的简单的例子
  
  ```
  Thread 1：：
  void init() {
      ...
      mThread = PR_CreateThread(mMain， ...);
      ...
  }
  Thread 2：：
  void mMain(...) {
      ...
      mState = mThread->State; // 此处假定变量 mThread 已经被初始化了(不为空)然而，如果线程 1 并没有首先执行，线程 2 就可能因为引用空指针奔溃(假设 mThread初始值为空；否则，可能会产生更加奇怪的问题，因为线程 2 中会读到任意的内存位置并引用)。		
      ...
  }
  // 通过强制顺序来修复这种缺陷： 条件变量
  ```
  
  ```
  pthread_mutex_t mtLock = PTHREAD_MUTEX_INITIALIZER;
  pthread_cond_t mtCond = PTHREAD_COND_INITIALIZER;
  int mtInit = 0;
  Thread 1：：
  void init() {
      ...
      mThread = PR_CreateThread(mMain， ...);
  
      // signal that the thread has been created...
      pthread_mutex_lock(&mtLock);
      mtInit = 1;
      pthread_cond_signal(&mtCond);
      pthread_mutex_unlock(&mtLock);
      ...
  }
  Thread 2：：
  void mMain(...) {
      ...
      // wait for the thread to be initialized...
      pthread_mutex_lock(&mtLock);
      while (mtInit == 0)
          pthread_cond_wait(&mtCond， &mtLock);
      pthread_mutex_unlock(&mtLock);
  
      mState = mThread->State;
      ...
  }
  ```

##### 死锁缺陷
* 死锁是一种在许多复杂并发系统中出现的经典问题。例如，当线程 1 持有锁 L1，正在等待另外一个锁 L2，而线程 2持有锁 L2，却在等待锁 L1 释放时，死锁就产生了。以下的代码片段就可能出现这种死锁：
  
  ```
  Thread 1： Thread 2：
  lock(L1); lock(L2);
  lock(L2); lock(L1); 
  ```
  
  这段代码运行时，不是一定会出现死锁的。当线程 1 占有锁 L1，上下文切换到线程 2。线程 2 锁住 L2，试图锁住 L1。这时才产生了死锁，两个线程互相等待。
  
* 为什么发生死锁
  
  * 在大型的代码库里，组件之间会有复杂的依赖。以操作系统为例。虚拟内存系统在需要访问文件系统才能从磁盘读到内存页；文件系统随后又要和虚拟内存交互，去申请一页内存，以便存放读到的块。因此，在设计大型系统的锁机制时，你必须要仔细地去避免循环依赖导致的死锁。
  * 封装(encapsulation)。软件开发者一直倾向于隐藏实现细节，以模块化的方式让软件开发更容易。然而，模块化和锁不是很契合。某些看起来没有关系的接口可能会导致死锁。
  
* 产生死锁的条件
  
  * 互斥：线程对于需要的资源进行互斥的访问(例如一个线程抢到锁)。
  * 持有并等待：线程持有了资源(例如已将持有的锁)，同时又在等待其他资源(例如，需要获得的锁)。
  * 非抢占：线程获得的资源(例如锁)，不能被抢占。
  * 循环等待：线程之间存在一个环路，环路上每个线程都额外持有一个资源，而这个资源又是下一个线程要申请的。
  
* 如果这 4 个条件的任何一个没有满足，死锁就不会产生。

##### 预防 

* 我们首先研究一下预防死锁的方法；每个策略都设法阻止某一个条件，从而解决死锁的问题。

* 循环等待
  
  * 也许最实用的预防技术(当然也是经常采用的)，就是让代码不会产生循环等待。最直接的方法就是获取锁时提供一个全序。假如系统共有两个锁(L1 和L2)，那么我们每次都先申请 L1 然后申请 L2，就可以避免死锁。这样严格的顺序避免了循环等待，也就不会产生死锁。
  
  * 当然，更复杂的系统中不会只有两个锁，锁的全序可能很难做到。因此，偏序可能是一种有用的方法，安排锁的获取并避免死锁。Linux 中的内存映射代码就是一个偏序锁的好例子。全序和偏序都需要细致的锁策略的设计和实现。另外，顺序只是一种约定，粗心的程序员很容易忽略，导致死锁。最后，有序加锁需要深入理解代码库，了解各种函数的调用关系
  
  * 通过锁的地址来强制锁的顺序： 当一个函数要抢多个锁时，我们需要注意死锁。比如有一个函数：`do_something(mutex t *m1， mutext *m2)`，如果函数总是先抢 m1，然后 m2，那么当一个线程调用 `do_something(L1， L2)`，而另一个线程调用 `do_something(L2， L1)` 时，就可能会产生死锁。为了避免这种特殊问题，聪明的程序员根据锁的地址作为获取锁的顺序。按照地址从高到低，或者从低到高的顺序加锁，do_something()函数就可以保证不论传入参数是什么顺序，函数都会用固定的顺序加锁。
  
    ```
    if (m1 > m2) { 				// 按锁地址关系进行加锁。当m1=m2时会产生死锁.
        pthread_mutex_lock(m1);
        pthread_mutex_lock(m2);
    } else {
        pthread_mutex_lock(m2);
        pthread_mutex_lock(m1); 
    }
    ```
  
* 持有并等待
  
  * 死锁的持有并等待条件，可以通过原子地抢锁来避免。实践中，可以通过如下代码来实现：
  
    ```
    lock(prevention);
    lock(L1);
    lock(L2);
    ...
    unlock(prevention);
    ```
  
    先抢到 prevention 这个锁之后，代码保证了在抢锁的过程中，不会有不合时宜的线程切换，从而避免了死锁。当然，这需要任何线程在任何时候抢占锁时，先抢到全局的 prevention锁。例如，如果另一个线程用不同的顺序抢锁 L1 和 L2，也不会有问题，因为此时，线程已经抢到了 prevention 锁。注意，出于某些原因，这个方案也有问题。和之前一样，它不适用于封装：因为这个方案需要我们准确地知道要抢哪些锁，并且提前抢到这些锁。因为要提前抢到所有锁(同时)，而不是在真正需要的时候，所以可能降低了并发。
  
* 非抢占
  
  * 在调用 unlock 之前，都认为锁是被占有的，多个抢锁操作通常会带来麻烦，因为我们等待一个锁时，同时持有另一个锁。很多线程库提供更为灵活的接口来避免这种情况。具体来说，trylock()函数会尝试获得锁，或者返回−1，表示锁已经被占有。你可以稍后重试一下。可以用这一接口来实现无死锁的加锁方法：
    
    ```
    top：
    lock(L1);
    if (trylock(L2) == -1) {
        unlock(L1);
    	goto top;
    }
    ```
    
    注意，另一个线程可以使用相同的加锁方式，但是不同的加锁顺序(L2 然后 L1)，程序仍然不会产生死锁。但是会引来一个新的问题：活锁。两个线程有可能一直重复这一序列，又同时都抢锁失败。这种情况下，系统一直在运行这段代码(因此不是死锁)，但是又不会有进展，因此名为活锁。也有活锁的解决方法：例如，可以在循环结束的时候，先随机等待一个时间，然后再重复整个动作，这样可以降低线程之间的重复互相干扰。关于这个方案的最后一点：使用 trylock 方法可能会有一些困难。第一个问题仍然是封装：如果其中的某一个锁，是封装在函数内部的，那么这个跳回开始处就很难实现。如果
    代码在中途获取了某些资源，必须要确保也能释放这些资源。例如，在抢到 L1 后，我们的代码分配了一些内存，当抢 L2 失败时，并且在返回开头之前，需要释放这些内存。当然，在某些场景下，这种方法很有效。
  
* 互斥
  
  * 通常来说，代码都会存在临界区，因此很难避免互斥。那么我们应该怎么做呢？Herlihy 提出了设计各种无等待(wait-free)数据结构的思想。想法很简单：通过强大的硬件指令，我们可以构造出不需要锁的数据结构。举个简单的例子，假设我们有比较并交换指令，是一种由硬件提供的原子指令，做下面的事：
    
    ```
    int CompareAndSwap(int *address， int expected， int new) {
        if (*address == expected) {
            *address = new;
            return 1; // success
        }
            return 0; // failure
    }
    ```
    
    假定我们想原子地给某个值增加特定的数量。我们可以这样实现：
    
    ```
    void AtomicIncrement(int *value， int amount) {
        do {
            int old = *value;
        } while (CompareAndSwap(value， old， old + amount) == 0);
    }
    ```
    
    无须获取锁，更新值，然后释放锁这些操作，我们使用比较并交换指令，反复尝试将值更新到新的值。这种方式没有使用锁，因此不会有死锁(有可能产生活锁)。链表插入。这是在链表头部插入元素的代码：
    
    ```
      void insert(int value) {
          node_t *n = malloc(sizeof(node_t));
          assert(n != NULL);
          n->value = value;
          do {
              n->next = head;
          } while (CompareAndSwap(&head， n->next， n) == 0);
      }
    ```
    
    这段代码，首先把 next 指针指向当前的链表头(head)，然后试着把新节点交换到链表头。但是，如果此时其他的线程成功地修改了 head 的值，这里的交换就会失败，导致这个线程根据新的 head 值重试。当然，只有插入操作是不够的，要实现一个完善的链表还需要删除、查找等其他工作。
  
* 除了死锁预防，某些场景更适合死锁避免(avoidance)。我们需要了解全局的信息，包括不同线程在运行中对锁的需求情况，从而使得后续的调度能够避免产生死锁。
  
* 银行家算法

  * 在银行中，客户申请贷款的数量是有限的，每个客户在第一次申请贷款时要声明完成该项目所需的最大资金量，在满足所有贷款要求时，客户应及时归还。银行家在客户申请的贷款数量不超过自己拥有的最大值时，都应尽量满足客户的需要。在这样的描述中，银行家就好比操作系统，资金就是资源，客户就相当于要申请资源的进程。
  * 银行家算法是一种最有代表性的避免死锁的算法。在避免死锁方法中允许进程动态地申请资源，但系统在进行资源分配之前，应先计算此次分配资源的安全性，若分配不会导致系统进入不安全状态，则分配，否则等待。为实现银行家算法，系统必须设置若干数据结构。
  * 要解释银行家算法，必须先解释操作系统安全状态和不安全状态。安全序列是指一个进程序列 `P1，…，Pn` 是安全的，即对于每一个进程Pi(1≤i≤n)，它以后尚需要的资源量不超过系统当前剩余资源量与所有进程Pj (j < i )当前占有资源量之和。如果存在一个由系统中所有进程构成的安全序列 `P1，…，Pn`，则系统处于安全状态。安全状态一定是没有死锁发生。不安全状态不一定导致死锁。

  * 我们可以把操作系统看作是银行家，操作系统管理的资源相当于银行家管理的资金，进程向操作系统请求分配资源相当于用户向银行家贷款。为保证资金的安全，银行家规定：
    * 当一个顾客对资金的最大需求量不超过银行家现有的资金时就可接纳该顾客；
    * 顾客可以分期贷款，但贷款的总数不能超过最大需求量；
    * 当银行家现有的资金不能满足顾客尚需的贷款数额时，对顾客的贷款可推迟支付，但总能使顾客在有限的时间里得到贷款；
    * 当顾客得到所需的全部资金后，一定能在有限的时间里归还所有的资金.
  * 操作系统按照银行家制定的规则为进程分配资源，当进程首次申请资源时，要测试该进程对资源的最大需求量，如果系统现存的资源可以满足它的最大需求量则按当前的申请量分配资源，否则就推迟分配。当进程在执行中继续申请资源时，先测试该进程本次申请的资源数是否超过了该资源所剩余的总量。若超过则拒绝分配资源，若能满足则按当前的申请量分配资源，否则也要推迟分配。

  * 动态避免的缺陷就是需要知道你将来需要什么，而由于我们没有什么有效的办法计算出一个线程所需要的资源额度，因此在实际的操作中没有采用这种动态避免方法.但是银行家却有这种能力解决这个问题.他们通过一种复杂的公式计算出你的信用额度.大部分时候这种计算比较保守，可以避免进入死锁状态.当然，他们也有算错的时候.

* 最后一种常用的策略就是允许死锁偶尔发生，检查到死锁时再采取行动。举个例子，如果一个操作系统一年死机一次，你会重启系统，然后继续工作。如果死锁很少见，这种不是办法的办法也是很实用的。很多数据库系统使用了死锁检测和恢复技术。死锁检测器会定期运行，通过构建资源图来检查循环。当循环(死锁)发生时，系统需要重启。如果还需要更复杂的数据结构相关的修复，那么需要人工参与。
#### 基于事件的并发(进阶)
* 目前为止，我们提到的并发，似乎只能用线程来实现。这不完全对。具体来说，一些基于图形用户界面(GUI)的应用，或某些类型的网络服务器，常常采用另一种并发方式。这种方式称为基于事件的并发，在一些现代系统中较为流行，比如 node.js。
* 基于事件的并发针对两方面的问题。一方面是多线程应用中，正确处理并发很有难度。正如我们讨论的，忘加锁、死锁和其他烦人的问题会发生。另一方面，开发者无法控制多线程在某一时刻的调度。程序员只是创建了线程，然后就依赖操作系统能够合理地调度线程。要实现一个在各种不同负载下，都能够良好运行的通用调度程序，是极有难度的。因此，某些时候操作系统的调度并不是最优的。

##### 基本想法：事件循环 
* 基本方法就是基于事件的并发。该方法很简单：我们等待某事(即“事件”)发生；当它发生时，检查事件类型，然后做少量的相应工作(可能是 I/O 请求，或者调度其他事件准备后续处理)。

* 在深入细节之前，我们先看一个典型的基于事件的服务器。这种应用都是基于一个简单的结构，称为事件循环(event loop)。事件循环的伪代码如下：
  
  ```
  while (1) {
      events = getEvents();
      for (e in events)
          processEvent(e);
  }
  ```
  
  它确实如此简单。主循环等待某些事件发生，然后依次处理这些发生的事件。处理事件的代码叫作事件处理程序。重要的是，处理程序在处理一个事件时，它是系统中发生的唯一活动。因此，调度就是决定接下来处理哪个事件。这种对调度的显式控制，是基于事件方法的一个重要优点。但这也带来一个更大的问题：基于事件的服务器如何决定哪个事件发生，尤其是对于网络和磁盘 I/O？具体来说，事件服务器如何确定是否有它的消息已经到达？
##### 一个问题：阻塞系统调用
* 如果某个事件要求你发出可能会阻塞的系统调用，该怎么办？例如，假定一个请求从客户端进入服务器，要从磁盘读取文件并将其内容返回给发出请求的客户端(很像简单的 HTTP 请求)。为了处理这样的请求，某些事件处理程序最终将不得不发出 open() 系统调用来打开文件，然后通过一系列 read( )调用来读取文件。当文件被读入内存时，服务器可能会开始将结果发送到客户端。open() 和 read() 调用都可能向存储系统发出 I/O 请求(当所需的元数据或数据不在内存
  中时)，因此可能需要很长时间才能提供服务。使用基于线程的服务器时，这不是问题 ：在发出 I/O 请求的线程挂起(等待 I/O 完成)时，其他线程可以运行，从而使服务器能够取得进展。事实上，I/O 和其他计算的自然重叠使得基于线程的编程非常自然和直接。但是，使用基于事件的方法时，没有其他线程可以运行：只是主事件循环。这意味着如果一个事件处理程序发出一个阻塞的调用，整个服务器就会这样做：阻塞直到调用完成。当事件循环阻塞时，系统处于闲置状态，因此是潜在的巨大资源浪费。因此，我们在基于事件的系统中必须遵守一条规则：不允许阻塞调用。

##### 解决方案：异步 I/O

* 为了克服这个限制，许多现代操作系统已经引入了新的方法来向磁盘系统发出 I/O 请求，一般称为异步 I/O(asynchronous I/O)。这些接口使应用程序能够发出 I/O 请求，并在 I/O 完成之前立即将控制权返回给调用者，另外的接口让应用程序能够确定各种 I/O 是否已完成。让我们来看看在 macOS X 上提供的接口(其他系统有类似的 API)。这些 API围绕着一个基本的结构，即 struct aiocb 或 AIO 控制块(AIO control block)。该结构的简化版本如下所示：

  ```
  struct aiocb {
      int aio_fildes;			// 要读取文件的文件描述符
      off_t aio_offset; 		// 文件内的偏移量以及长度的请求
      volatile void *aio_buf;  // 复制读取结果的目标内存位置
      size_t aio_nbytes;		// 转移的长度
  };
  ```

* 我们必须解决最后一个难题。我们如何知道 I/O 何时完成，并且缓冲区(由 aio_buf 指向)现在有了请求的数据？还需要最后一个 API。在 macOS X 上，它被称为 aio_error()。API 看起来像这样：`int aio_error(const struct aiocb *aiocbp);`该系统调用检查 aiocb 引用的请求是否已完成。如果有，则函数返回成功(用零表示)。如果不是，则返回 EINPROGRESS。因此，对于每个未完成的异步 I/O，应用程序可以通过调用 aio_error() 来周期性地轮询系统，以确定所述 I/O 是否尚未完成。你可能已经注意到，检查一个 I/O 是否已经完成是很痛苦的。如果一个程序在某个特定时间点发出数十或数百个 I/O，是否应该重复检查它们中的每一个…… 为了解决这个问题，一些系统提供了基于中断的方法。此方法使用 UNIX 信号在异步 I/O 完成时通知应用程序，从而消除了重复询问系统的需要。这种轮询与中断问题也可以在设备中看到，正如你将在 I/O 设备章节中看到的。在没有异步 I/O 的系统中，纯基于事件的方法无法实现。然而，聪明的研究人员已经推出了相当适合他们的方法。

##### 另一个问题：状态管理
* 基于事件的方法的另一个问题是，这种代码通常比传统的基于线程的代码更复杂。原因如下：当事件处理程序发出异步 I/O 时，它必须打包一些程序状态，以便下一个事件处理程序在 I/O 最终完成时使用。这个额外的工作在基于线程的程序中是不需要的，因为程序需要的状态在线程栈中。Adya 等人称之为手工栈管理，这是基于事件编程的基础。

* 为了使这一点更加具体一些，我们来看一个简单的例子，在这个例子中，一个基于线程的服务器需要从文件描述符(fd)中读取数据，一旦完成，将从文件中读取的数据写入网络套接字描述符 (fd)。代码(忽略错误检查)如下所示：
  
  ```
  int rc = read(fd， buffer， size);
  rc = write(fd， buffer， size);
  ```
  
  如你所见，在一个多线程程序中，做这种工作很容易。当 read()最终返回时，代码立即知道要写入哪个套接字，因为该信息位于线程堆栈中。在基于事件的系统中，并没有那么容易。为了执行相同的任务，我们首先使用上面描述的 AIO 调用异步地发出读取。假设我们使用 aio_error()调用定期检查读取的完成情况。当该调用告诉我们读取完成时，基于事件的服务器如何知道该怎么做？解决方案，如 Adya 等人所述，是使用一种称为“延续(continuation)”的老编程语言结构。虽然听起来很复杂，但这个想法很简单：基本上，在某些数据结构中，记录完成处理该事件需要的信息。当事件发生时(即磁盘 I/O 完成时)，查找所需信息并处理事件。

##### 什么事情仍然很难
* 基于事件的方法还有其他一些困难。例如，当系统从单个 CPU 转向多个 CPU 时，基于事件的方法的一些简单性就消失了。具体来说，为了利用多个 CPU，事件服务器必须并行运行多个事件处理程序。发生这种情况时，就会出现常见的同步问题(例如临界区)，并且必须采用通常的解决方案(例如锁定)。因此，在现代多核系统上，无锁的简单事件处理已不再可能。

* 基于事件的方法的另一个问题是，它不能很好地与某些类型的系统活动集成，如分页。例如，如果事件处理程序发生页错误，它将被阻塞，并且因此服务器在页错误完成之前不会有进展。尽管服务器的结构可以避免显式阻塞，但由于页错误导致的这种隐式阻塞很难避免，因此在频繁发生时可能会导致较大的性能问题。

* 还有一个问题是随着时间的推移，基于事件的代码可能很难管理，因为各种函数的确切语义发生了变化。例如，如果函数从非阻塞变为阻塞，调用该例程的事件处理程序也必须更改以适应其新性质，方法是将其自身分解为两部分。由于阻塞对于基于事件的服务器而言是灾难性的，因此程序员必须始终注意每个事件使用的 API 语义的这种变化。

  