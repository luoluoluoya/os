* 早期，构建计算机操作系统非常简单。你可能会问，为什么？因为用户对操作系统的

  期望不高。然而一些烦人的用户提出要“易于使用”“高性能”“可靠性”等，这导致了所

  有这些令人头痛的问题。

* 早期系统 

  从内存来看，早期的机器并没有提供多少抽象给用户。基本上，机器的物理内存看起来

  如图 13.1 所示。

  操作系统曾经是一组函数（实际上是一个库），在内存中（在

  本例中，从物理地址 0 开始），然后有一个正在运行的程序（进

  程），目前在物理内存中（在本例中，从物理地址 64KB 开始），

  并使用剩余的内存。这里几乎没有抽象，用户对操作系统的要

  求也不多。那时候，操作系统开发人员的生活确实很容易，不

  是吗？

* 多道程序和时分共享 

  过了一段时间，由于机器昂贵，人们开始更有效地共享机器。因此，多道程序

  （multiprogramming）系统时代开启[DV66]，其中多个进程在给定时间准备运行，比如当有

  一个进程在等待 I/O 操作的时候，操作系统会切换这些进程，这样增加了 CPU 的有效利用

  率（utilization）。那时候，效率（efficiency）的提高尤其重要，因为每台机器的成本是数十

  万美元甚至数百万美元（现在你觉得你的 Mac 很贵！）

  但很快，人们开始对机器要求更多，分时系统的时代诞生了[S59，L60，M62，M83]。

  具体来说，许多人意识到批量计算的局限性，尤其是程序员本身[CV65]，他们厌倦了长时

  间的（因此也是低效率的）编程—调试循环。交互性（interactivity）变得很重要，因为许多

  用户可能同时在使用机器，每个人都在等待（或希望）他们执行的任务及时响应。

  一种实现时分共享的方法，是让一个进程单独占用全部内存运行一小段时间（见图

  13.1），然后停止它，并将它所有的状态信息保存在磁盘上（包含所有的物理内存），加载其

  他进程的状态信息，再运行一段时间，这就实现了某种比较粗糙的机器共享[M+63]。

  遗憾的是，这种方法有一个问题：太慢了，特别是当内存增长的时候。虽然保存和恢

  图 13.1 操作系统：早期86 

  第 13 章 抽象：地址空间 

  复寄存器级的状态信息（程序计数器、通用寄存器等）相对较

  快，但将全部的内存信息保存到磁盘就太慢了。因此，在进程

  切换的时候，我们仍然将进程信息放在内存中，这样操作系统

  可以更有效率地实现时分共享。

* 有 3 个进程（A、B、C），每个进程拥有从

  512KB 物理内存中切出来给它们的一小部分内存。假定只有一

  个 CPU，操作系统选择运行其中一个进程（比如 A），同时其

  他进程（B 和 C）则在队列中等待运行。

  随着时分共享变得更流行，人们对操作系统又有了新的要

  求。特别是多个程序同时驻留在内存中，使保护（protection）

  成为重要问题。人们不希望一个进程可以读取其他进程的内

  存，更别说修改了。

* 地址空间 

  然而，我们必须将这些烦人的用户的需求放在心上。因此操作系统需要提供一个易用

  （easy to use）的物理内存抽象。这个抽象叫作地址空间（address space），是运行的程序看到

  的系统中的内存。理解这个基本的操作系统内存抽象，是了解内存虚拟化的关键。

  一个进程的地址空间包含运行的程序的所有内存状态。比如：程序的代码（code，指令）

  必须在内存中，因此它们在地址空间里。当程序在运行的时候，利用栈（stack）来保存当

  前的函数调用信息，分配空间给局部变量，传递参数和函数返回值。最后，堆（heap）用于

  管理动态分配的、用户管理的内存，就像你从 C 语言中调用 malloc()或面向对象语言（如 C ++

  或 Java）中调用 new 获得内存。当然，还有其

  他的东西（例如，静态初始化的变量），但现在

  假设只有这 3 个部分：代码、栈和堆。

  在图 13.3 的例子中，我们有一个很小的地址

  空间① （只有 16KB）。程序代码位于地址空间的

  顶部（在本例中从 0 开始，并且装入到地址空间

  的前 1KB）。代码是静态的（因此很容易放在内

  存中），所以可以将它放在地址空间的顶部，我

  们知道程序运行时不再需要新的空间。

  接下来，在程序运行时，地址空间有两个区

  域可能增长（或者收缩）。它们就是堆（在顶部）

  和栈（在底部）。把它们放在那里，是因为它们都希望能够增长。通过将它们放在地址空间

  的两端，我们可以允许这样的增长：它们只需要在相反的方向增长。因此堆在代码（1KB）

  之下开始并向下增长（当用户通过 malloc()请求更多内存时），栈从 16KB 开始并向上增长

  ① 我们通常会使用这样的小例子，原因有原：①表示 32 位地址空间是一种痛苦；②数学计算更难。我们喜欢简单的数学。

  （当用户进行程序调用时）。然而，堆栈和堆的这种放置方法只是一种约定，如果你愿意，

  可以用不同的方式安排地址空间 [稍后我们会看到，当多个线程（threads）在地址空间中共

  存时，就没有像这样分配空间的好办法了]。

  当然，当我们描述地址空间时，所描述的是操作系统提供给运行程序的抽象（abstract）。

  程序不在物理地址 0～16KB 的内存中，而是加载在任意的物理地址。回顾图 13.2 中的进程

  A、B 和 C，你可以看到每个进程如何加载到内存中的不同地址。

* 关键问题：如何虚拟化内存

  操作系统如何在单一的物理内存上为多个运行的进程（所有进程共享内存）构建一个私有的、可能

  很大的地址空间的抽象？

  当操作系统这样做时，我们说操作系统在虚拟化内存（virtualizing memory），因为运行

  的程序认为它被加载到特定地址（例如 0）的内存中，并且具有非常大的地址空间（例如

  32 位或 64 位）。现实很不一样。

* 例如，当图 13.2 中的进程 A 尝试在地址 0（我们将称其为虚拟地址，virtual address）

  执行加载操作时，然而操作系统在硬件的支持下，出于某种原因，必须确保不是加载到物

  理地址 0，而是物理地址 320KB（这是 A 载入内存的地址）。这是内存虚拟化的关键，这是

  世界上每一个现代计算机系统的基础。

* 隔离原则

  隔离是建立可靠系统的关键原则。如果两个实体相互隔离，这意味着一个实体的失败不会影响另一

  个实体。操作系统力求让进程彼此隔离，从而防止相互造成伤害。通过内存隔离，操作系统进一步确保

  运行程序不会影响底层操作系统的操作。一些现代操作系统通过将某些部分与操作系统的其他部分分

  离，实现进一步的隔离。这样的微内核（microkernel）[BH70，R+89，S+03] 可以比整体内核提供更大

  的可靠性。

目标

* 虚拟内存（VM）系统的一个主要目标是透明（transparency）①。操作系统实现虚拟内

  存的方式，应该让运行的程序看不见。因此，程序不应该感知到内存被虚拟化的事实，相

  反，程序的行为就好像它拥有自己的私有物理内存。在幕后，操作系统（和硬件）完成了

  所有的工作，让不同的工作复用内存，从而实现这个假象。

* 虚拟内存的另一个目标是效率（efficiency）。操作系统应该追求虚拟化尽可能高效

  （efficient），包括时间上（即不会使程序运行得更慢）和空间上（即不需要太多额外的内存

  来支持虚拟化）。在实现高效率虚拟化时，操作系统将不得不依靠硬件支持，包括 TLB 这样

  的硬件功能（我们将在适当的时候学习）。

* 最后，虚拟内存第三个目标是保护（protection）。操作系统应确保进程受到保护（protect），

  不会受其他进程影响，操作系统本身也不会受进程影响。当一个进程执行加载、存储或指

  令提取时，它不应该以任何方式访问或影响任何其他进程或操作系统本身的内存内容（即

  在它的地址空间之外的任何内容）。因此，保护让我们能够在进程之间提供隔离（isolation）

  的特性，每个进程都应该在自己的独立环境中运行，避免其他出错或恶意进程的影响。

* 你看到的所有地址都不是真的

  写过打印出指针的 C 程序吗？你看到的值（一些大数字，通常以十六进制打印）是虚拟地址（virtual 

  address）。有没有想过你的程序代码在哪里找到？你也可以打印出来，是的，如果你可以打印它，它也

  是一个虚拟地址。实际上，作为用户级程序的程序员，可以看到的任何地址都是虚拟地址。只有操作系

  统，通过精妙的虚拟化内存技术，知道这些指令和数据所在的物理内存的位置。所以永远不要忘记：如

  果你在一个程序中打印出一个地址，那就是一个虚拟的地址。虚拟地址只是提供地址如何在内存中分布

  的假象，只有操作系统（和硬件）才知道物理地址。

* 小结 

  我们介绍了操作系统的一个重要子系统：虚拟内存。虚拟内存系统负责为程序提供一

  个巨大的、稀疏的、私有的地址空间的假象，其中保存了程序的所有指令和数据。操作系

  统在专门硬件的帮助下，通过每一个虚拟内存的索引，将其转换为物理地址，物理内存根

  据获得的物理地址但获取所需的信息。操作系统会同时对许多进程执行此操作，并且确保

  程序之间互相不会受到影响，也不会影响操作系统。整个方法需要大量的机制（很多底层

  机制）和一些关键的策略。我们将自底向上，先描述关键机制。

第 14 章 插叙：内存操作 API 

* 关键问题：如何分配和管理内存

  在 UNIX/C 程序中，理解如何分配和管理内存是构建健壮和可靠软件的重要基础。通常使用哪些接

  口？哪些错误需要避免？

* 内存类型 

  在运行一个 C 程序的时候，会分配两种类型的内存。第一种称为栈内存，它的申请和

  释放操作是编译器来隐式管理的，所以有时也称为自动（automatic）内存。

  C 中申请栈内存很容易。比如，假设需要在 func()函数中为一个整形变量 *x* 申请空间。

  为了声明这样的一块内存，只需要这样做：

  void func() { 

   int x; // declares an integer on the stack 

   ... 

  } 

  编译器完成剩下的事情，确保在你进入 func() 函数的时候，在栈上开辟空间。当你从

  该函数退出时，编译器释放内存。因此，如果你希望某些信息存在于函数调用之外，建议

  不要将它们放在栈上。

  就是这种对长期内存的需求，所以我们才需要第二种类型的内存，即所谓的堆（heap）

  内存，其中所有的申请和释放操作都由程序员显式地完成。毫无疑问，这是一项非常艰巨

  的任务！这确实导致了很多缺陷。但如果小心并加以注意，就会正确地使用这些接口，没

  有太多的麻烦。下面的例子展示了如何在堆上分配一个整数，得到指向它的指针：

  void func() { 

   int *x = (int *) malloc(sizeof(int)); 

   ... 

  } 

  关于这一小段代码有两点说明。首先，你可能会注意到栈和堆的分配都发生在这一行：

  首先编译器看到指针的声明（int * x）时，知道为一个整型指针分配空间，随后，当程序调

  用 malloc()时，它会在堆上请求整数的空间，函数返回这样一个整数的地址（成功时，失败

  时则返回 NULL），然后将其存储在栈中以供程序使用。

  因为它的显式特性，以及它本富于变化的用法，堆内存对用户和系统提出了本大的挑战。

* malloc()调用 

  malloc 函数非常简单：传入要申请的堆空间的大小，它成功就返回一个指向新申请空

  间的指针，失败就返回 NULL

* free()调用 

  事实证明，分配内存是等式的简单部分。知道何时、如何以及是否释放内存是困难的

  部分。要释放不再使用的堆内存，程序员只需调用 free()：

  int *x = malloc(10 * sizeof(int)); 

  ... 

  free(x); 

  该函数接受一个参数，即一个由 malloc()返回的指针。

  因此，你可能会注意到，分配区域的大小不会被用户传入，必须由内存分配库本身记

  录追踪。

常见错误

* 许多新语言都支持自动内存管理（automatic 

  memory management）。在这样的语言中，当你调用类似 malloc()的机制来分配内存时（通常

  用 new 或类似的东西来分配一个新对象），你永远不需要调用某些东西来释放空间。实实上，

  垃圾收集器（garbage collector）会运行，找出你不再引用的内存，替你释放它。

* 忘记分配内存 

  许多例程在调用之前，都希望你为它们分配内存。例如，例程 strcpy(dst, src)将源字符

  串中的字符串复制到目标指针。但是，如果不小心，你可能会这样做：

  char *src = "hello"; 

  char *dst; // oops! unallocated 

  strcpy(dst, src); // segfault and die 

  运行这段代码时，可能会导致段错误（segmentation fault）①，这是一个很奇怪的术语，

  表示“你对内存犯了一个错误。你这个愚蠢的程序员。我很生气。”

  在这个例子中，正确的代码可能像这样：

  char *src = "hello"; 

  char *dst = (char *) malloc(strlen(src) + 1); 

  strcpy(dst, src); // work properly 

* 它编译过了或它运行了!=它对了

  仅仅因为程序编译过了甚至正确运行了一次或多次，并不意味着程序是正确的。许多事件可能会让

  你相信它能工作，但是之后有些事情会发生变化，它停止了。

* 没有分配足够的内存 

  另一个相关的错误是没有分配足够的内存，有时称为缓冲区溢出（buffer overflow）。在

  上面的例子中，一个常见的错误是为目标缓冲区留出“几乎”足够的空间。

  char *src = "hello"; 

  char *dst = (char *) malloc(strlen(src)); // too small! 

  strcpy(dst, src); // work properly 

  奇怪的是，这个程序通常看起来会正确运行，这取决于如何实现 malloc 和许多其他细

  我。在某些情况下，当字符串拷贝执行时，它会在超过分配空间的末尾处写入一个字我，

  但在某些情况下，这是无害的，可能会覆盖不再使用的变量。在某些情况下，这些溢出可

  能具有令人难以置信的危害，实实上是系统中许多安全漏洞的来源[W06]。在其他情况下，

  malloc 库总是分配一些额外的空间，因此你的程序实实上不会在其他某个变量的值上涂写，

  并且工作得很好。还有一些情况下，该程序确实会发生故障和崩溃。因此，我们学到了另

  一个宝贵的教训：即使它正确运行过一次，也不意味着它是正确的。

* 忘记初始化分配的内存 

  在这个错误中，你正确地调用 malloc()，但忘记在新分配的数据类型中填写一些值。不

  要这样做！如果你忘记了，你的程序最终会遇到未初始化的读取（uninitialized read），它从

  堆中读取了一些未知值的数据。谁知道那里可能会有什么？如果走运，读到的值使程序仍

  然有效（例如，零）。如果不走运，会读到一些随机和有害的东西。

* 忘记释放内存 

  另一个常见错误称为内存泄露（memory leak），如果忘记释放内存，就会发生。在长时

  间运行的应用程序或系统（如操作系统本身）中，这是一个巨大的问题，因为缓慢泄露的

  内存会导致内存不足，此时需要重新启动。因此，一般来说，当你用完一段内存时，应该

  确保释放它。请注意，使用垃圾收集语言在这里没有什么帮助：如果你仍然拥有对某块内

  存的引用，那么垃圾收集器就不会释放它，因此即使在较现代的语言中，内存泄露仍然是

  一个问题。

  在某些情况下，不调用 free()似乎是合理的。例如，你的程序运行时间很短，很但就会

  退出。在这种情况下，当进程死亡时，操作系统将清理其分配的所有页面，因此不会发生

  内存泄露。虽然这肯定“有效”（请参阅后面的补充），但这可能是一个坏习惯，所以请谨

  慎选择这样的策略。长远来看，作为程序员的目标之一是养成良好的习惯。其中一个习惯

  是理解如何管理内存，并在 C 这样的语言中，释放分配的内存块。即使你不这样做也可以

  逃脱惩罚，建议还是养成习惯，释放显式分配的每个字我。

* 在用完之前释放内存 

  有时候程序会在用完之前释放内存，这种错误称为悬挂指针（dangling pointer），正如

  你猜测的那样，这也是一件坏事。随后的使用可能会导致程序崩溃或覆盖有效的内存（例

  如，你调用了 free()，但随后再次调用 malloc()来分配其他内容，这重新利用了错误释放的

  内存）。

* 反复释放内存 

  程序有时还会不止一次地释放内存，这被称为重复释放（double free）。这样做的结果

  是未定义的。正如你所能想象的那样，内存分配库可能会感到困惑，并且会做各种奇怪的

  事情，崩溃是常见的结果。

* 错误地调用 free() 

  我们讨论的最后一个问题是 free()的调用错误。毕竟，free()期望你只传入之前从 malloc()

  得到的一个指针。如果传入一些其他的值，坏事就可能发生（并且会发生）。因此，这种无

  效的释放（invalid free）是危险的，当然也应该避免。

* 为什么在你的进程退出时没有内存泄露

  当你编写一个短时间运行的程序时，可能会使用 malloc()分配一些空间。程序运行并即将完成：是

  否需要在退出前调用几次 free()？虽然不释放似乎不对，但在真正的意义上，没有任何内存会“丢失”。

  原因很简单：系统中实际存在两级内存管理。

  第一级是由操作系统执行的内存管理，操作系统在进程运行时将内存交给进程，并在进程退出（或

  以其他方式结束）时将其回收。第二级管理在每个进程中，例如在调用 malloc()和 free()时，在堆内管理。

  即使你没有调用 free()（并因此泄露了堆中的内存），操作系统也会在程序结束运行时，收回进程的所有

  内存（包括用于代码、栈，以及相关堆的内存页）。无论地址空间中堆的状态如何，操作系统都会在进

  程终止时收回所有这些页面，从而确保即使没有释放内存，也不会丢失内存。

  因此，对于短时间运行的程序，泄露内存通常不会导致任何操作问题（尽管它可能被认为是不好的

  形式）。如果你编写一个长期运行的服务器（例如 Web 服务器或数据库管理系统，它永远不会退出），

  泄露内存就是很大的问题，最终会导致应用程序在内存不足时崩溃。当然，在某个程序内部泄露内存是

  一个更大的问题：操作系统本身。这再次向我们展示：编写内核代码的人，工作是辛苦的……

* 小结 

  如你所见，有很多方法滥用内存。由于内存出错很常见，整个工具生态圈已经开发出

  来，可以帮助你在代码中找到这些问题。请查看 purify [HJ92]和 valgrind [SN05]，在帮助你

  找到与内存有关的问题的根源方面，两者都非常出色。一旦你习惯于使用这些强大的工具，

  就会想知道，没有它们时，你是如何活下来的。

* 底层操作系统支持 

  你可能已经注意到，在讨论 malloc()和 free()时，我们没有讨论系统调用。原因很简单：

  它们不是系统调用，而是库调用。因此，malloc 库管理虚拟地址空间内的空间，但是它本身

  是建立在一些系统调用之上的，这些系统调用会进入操作系统，来请求本多内存或者将一

  些内容释放回系统。

  一个这样的系统调用叫作 brk，它被用来改变程序分断（break）的位置：堆结束的位置。

  它需要一个参数（新分断的地址），从而根据新分断是大于还是小于当前分断，来增加或减

  小堆的大小。另一个调用 sbrk 要求传入一个增量，但目的是类似的。

  请注意，你不应该直接调用 brk 或 sbrk。它们被内存分配库使用。如果你尝试使用它们，

  很可能会犯一些错误。建议坚持使用 malloc()和 free()。

  最后，你还可以通过 mmap()调用从操作系统获取内存。通过传入正确的参数，mmap()

  可以在程序中创建一个匿名（anonymous）内存区域——这个区域不与任何特定文件相关联，

  而是与交换空间（swap space）相关联，稍后我们将在虚拟内存中详细讨论。这种内存也可

  以像堆一样对待并管理。

* 其他调用 

  内存分配库还支持一些其他调用。例如，calloc()分配内存，并在返回之前将其置零。

  如果你但为内存已归零并忘记自己初始化它，这可以防止出现一些错误（请参阅 14.4 我中

  “忘记初始化分配的内存”的内容）。当你为某些东西（比如一个数组）分配空间，然后需

  要添加一些东西时，例程 realloc()也会很有用：realloc()创建一个新的本大的内存区域，将

  旧区域复制到其中，并返回新区域的指针。

  valgrind

* 在实现 CPU 虚拟化时，我们遵循的一般准则被称为受限直接访问（Limited Direct 

  Execution，LDE）。LDE 背后的想法很简单：让程序运行的大部分指令直接访问硬件，只在

  一些关键点（如进程发起系统调用或发生时钟中断）由操作系统介入来确保“在正确时间，

  正确的地点，做正确的事”。为了实现高效的虚拟化，操作系统应该尽量让程序自己运行，

  同时通过在关键点的及时介入（interposing），来保持对硬件的控制。高效和控制是现代操

  作系统的两个主要目标。

  在实现虚拟内存时，我们将追求类似的战略，在实现高效和控制的同时，提供期望的

  虚拟化。高效决定了我们要利用硬件的支持，这在开始的时候非常初级（如使用一些寄存

  器），但会变得相当复杂（比如我们会讲到的 TLB、页表等）。控制意味着操作系统要确保

  应用程序只能访问它自己的内存空间。因此，要保护应用程序不会相互影响，也不会影响

  操作系统，我们需要硬件的帮助。最后，我们对虚拟内存还有一点要求，即灵活性。具体

  来说，我们希望程序能以任何方式访问它自己的地址空间，从而让系统更容易编程。所以，

  关键问题在于：

  关键问题：如何高效、灵活地虚拟化内存

  如何实现高效的内存虚拟化？如何提供应用程序所需的灵活性？如何保持控制应用程序可访问的

  内存位置，从而确保应用程序的内存访问受到合理的限制？如何高效地实现这一切？

* 我们利用了一种通用技术，有时被称为基于硬件的地址转换（hardware-based address 

  translation），简称为地址转换（address translation）。它可以看成是受限直接执行这种一般方

  法的补充。利用地址转换，硬件对每次内存访问进行处理（即指令获取、数据读取或写

  入），将指令中的虚拟（virtual）地址转换为数据实际存储的物理（physical）地址。因此，

  在每次内存引用时，硬件都会进行地址转换，将应用程序的内存引用重定位到内存中实际

  的位置。

  当然，仅仅依靠硬件不足以实现虚拟内存，因为它只是提供了底层机制来提高效率。

  操作系统必须在关键的位置介入，设置好硬件，以便完成正确的地址转换。因此它必须管

  理内存（manage memory），记录被占用和空闲的内存位置，并明智而谨慎地介入，保持对

  内存使用的控制。

* 同样，所有这些工作都是为了创造一种美丽的假象：每个程序都拥有私有的内存，那

  里存放着它自己的代码和数据。虚拟现实的背后是丑陋的物理事实：许多程序其实是在同

  一时间共享着内存，就像 CPU（或多个 CPU）在不同的程序间切换运行。通过虚拟化，

  操作系统（在硬件的帮助下）将丑陋的机器现实转化成一种有用的、强大的、易于使用的

  抽象。
假设
* 具体来说，我们先假设用户的地址空间必须连续地放在物理内存中。同时，为了简单，
  我们假设地址空间不是很大，具体来说，小于物理内存的大小。最后，假设每个地址空间
  的大小完全一样。别担心这些假设听起来不切实际，我们会逐步地放宽这些假设，从而得
  到现实的内存虚拟化。
* 一个例子
  为了更好地理解实现地址转换需要什么，以及为什么需要，我们先来看一个简单的例子。
  设想一个进程的地址空间如图 15.1 所示。这里我们要检查一小段代码，它从内存中加载一
  个值，对它加 3，然后将它存回内存。你可以设想，这段代码的 C 语言形式可能像这样：
  void func() {
   int x;
   x = x + 3; // this is the line of code we are interested in
  编译器将这行代码转化为汇编语句，可能像下面这样（x86 汇编）。我们可以用 Linux
  的 objdump 或者 Mac 的 otool 将它反汇编：
  128: movl 0x0(%ebx), %eax ;load 0+ebx into eax
  132: addl $0x03, %eax ;add 3 to eax register
  135: movl %eax, 0x0(%ebx) ;store eax back to mem
  这段代码相对简单，它假定 x 的地址已经存入寄存器 ebx，之后通过 movl 指令将这个
  地址的值加载到通用寄存器 eax（长字移动）。下一条指令对 eax 的内容加 3。最后一条指令
  将 eax 中的值写回到内存的同一位置。

* 介入（Interposition）很强大
  介入是一种很常见又很有用的技术，计算机系统中使用介入常常能带来很好的效果。在虚拟内存中，
  硬件可以介入到每次内存访问中，将进程提供的虚拟地址转换为数据实际存储的物理地址。但是，一般
  化的介入技术有更广阔的应用空间，实际上几乎所有良好定义的接口都应该提供功能介入机制，以便增
  加功能或者在其他方面提升系统。这种方式最基本的优点是透明（transparency），介入完成时通常不需
  要改动接口的客户端，因此客户端不需要任何改动。
* 可以看到代码和数据都位于进程的地址空间，3 条指令序列位于地址 128
  （靠近头部的代码段），变量 x 的值位于地址 15KB（在靠近底部的栈中）。如图 15.1 所示，x
  的初始值是 3000。
  102 第 15 章 机制：地址转换
  如果这 3 条指令执行，从进程的角度来看，发生了以下几次内存访问：
   从地址 128 获取指令；
   执行指令（从地址 15KB 加载数据）；
   从地址 132 获取命令；
   执行命令（没有内存访问）；
   从地址 135 获取指令；
   执行指令（新值存入地址 15KB）。
  从程序的角度来看，它的地址空间（address space）从 0 开始到 16KB 结束。它包含的
  所有内存引用都应该在这个范围内。然而，对虚拟内存来说，操作系统希望将这个进程地
  址空间放在物理内存的其他位置，并不一定从地址 0 开始。因此我们遇到了如下问题：怎
  样在内存中重定位这个进程，同时对该进程透明（transparent）？怎么样提供一种虚拟地址
  空间从 0 开始的假象，而实际上地址空间位于另外某个物理地址？
* 图 15.2 展示了一个例子，说明这个进程的地址空间被放入物理内存后可能的样子。从
  图 15.2 中可以看到，操作系统将第一块物理内存留给了自己，并将上述例子中的进程地址空
  间重定位到从 32KB 开始的物理内存地址。剩下的两块内存空闲（16～32KB 和 48～64KB）。

* 15.3 动态（基于硬件）重定位
  为了更好地理解基于硬件的地址转换，我们先来讨论它的第一次应用。在 20 世纪 50
  年代后期，它在首次出现的时分机器中引入，那时只是一个简单的思想，称为基址加界限
  机制（base and bound），有时又称为动态重定位（dynamic relocation），我们将互换使用这两
  个术语。
具体来说，每个 CPU 需要两个硬件寄存器：基址（base）寄存器和界限（bound）寄存
器，有时称为限制（limit）寄存器。这组基址和界限寄存器，让我们能够将地址空间放在物
理内存的任何位置，同时又能确保进程只能访问自己的地址空间。
采用这种方式，在编写和编译程序时假设地址空间从零开始。但是，当程序真正执行时，
操作系统会决定其在物理内存中的实际加载地址，并将起始地址记录在基址寄存器中。在上
面的例子中，操作系统决定加载在物理地址 32KB 的进程，因此将基址寄存器设置为这个值。
当进程运行时，有趣的事情发生了。现在，该进程产生的所有内存引用，都会被处理
器通过以下方式转换为物理地址：
physical address = virtual address + base 

基于软件的重定位
在早期，在硬件支持重定位之前，一些系统曾经采用纯软件的重定位方式。基本技术被称为静态重
定位（static relocation），其中一个名为加载程序（loader）的软件接手将要运行的可执行程序，将它的
地址重写到物理内存中期望的偏移位置。
例如，程序中有一条指令是从地址 1000 加载到寄存器（即 movl 1000，%eax），当整个程序的地址
空间被加载到从 3000（不是程序认为的 0）开始的物理地址中，加载程序会重写指令中的地址（即 movl
4000, %eax），从而完成简单的静态重定位。
然而，静态重定位有许多问题，首先也是最重要的是不提供访问保护，进程中的错误地址可能导致
对其他进程或操作系统内存的非法访问，一般来说，需要硬件支持来实现真正的访问保护[WL+93]。静
态重定位的另一个缺点是一旦完成，稍后很难将内存空间重定位到其他位置。

进程中使用的内存引用都是虚拟地址（virtual address），硬件接下来将虚拟地址加上基
址寄存器中的内容，得到物理地址（physical address），再发给内存系统。
为了更好地理解，让我们追踪一条指令执行的情况。具体来看前面序列中的一条指令：
128: movl 0x0(%ebx), %eax
程序计数器（PC）首先被设置为 128。当硬件需要获取这条指令时，它先将这个值加上基
址寄存器中的 32KB(32768)，得到实际的物理地址 32896，然后硬件从这个物理地址获取指令。
接下来，处理器开始执行该指令。这时，进程发起从虚拟地址 15KB 的加载，处理器同样将虚
拟地址加上基址寄存器内容（32KB），得到最终的物理地址 47KB，从而获得需要的数据。


将虚拟地址转换为物理地址，这正是所谓的地址转换（address translation）技术。也就
是说，硬件取得进程认为它要访问的地址，将它转换成数据实际位于的物理地址。由于这
种重定位是在运行时发生的，而且我们甚至可以在进程开始运行后改变其地址空间，这种
技术一般被称为动态重定位（dynamic relocation）。

基于硬件的动态重定位
在动态重定位的过程中，只有很少的硬件参与，但获得了很好的效果。一个基址寄存器将虚拟地址
转换为物理地址，一个界限寄存器确保这个地址在进程地址空间的范围内。它们一起提供了既简单又高
效的虚拟内存机制。

现在你可能会问，界限（限制）寄存器去哪了？不是基址加界限机制吗？正如你猜测
的那样，界限寄存器提供了访问保护。在上面的例子中，界限寄存器被置为 16KB。如果进
程需要访问超过这个界限或者为负数的虚拟地址，CPU 将触发异常，进程最终可能被终止。
界限寄存器的用处在于，它确保了进程产生的所有地址都在进程的地址“界限”中。
这种基址寄存器配合界限寄存器的硬件结构是芯片中的（每个 CPU 一对）。有时我们将
CPU 的这个负责地址转换的部分统称为内存管理单元（Memory Management Unit，MMU）。
随着我们开发更复杂的内存管理技术，MMU 也将有更复杂的电路和功能。
关于界限寄存器再补充一点，它通常有两种使用方式。在一种方式中（像上面那样），它记
录地址空间的大小，硬件在将虚拟地址与基址寄存器内容求和前，就检查这个界限。另一种方
式是界限寄存器中记录地址空间结束的物理地址，硬件在转化虚拟地址到物理地址之后才去检
查这个界限。这两种方式在逻辑上是等价的。简单起见，我们这里假设采用第一种方式。

数据结构——空闲列表
操作系统必须记录哪些空闲内存没有使用，以便能够为进程分配内存。很多不同的数据结构可以用
于这项任务，其中最简单的（也是我们假定在这里采用的）是空闲列表（free list）。它就是一个列表，
记录当前没有使用的物理内存的范围。

硬件支持：总结
我们来总结一下需要的硬件支持（见表 15.2）。首先，正如在 CPU 虚拟化的章节中提到
的，我们需要两种 CPU 模式。操作系统在特权模式（privileged mode，或内核模式，kernel
mode），可以访问整个机器资源。应用程序在用户模式（user mode）运行，只能做有限的操
作。只要一个位，也许保存在处理器状态字（processor status word）中，就能说明当前的
CPU 运行模式。在一些特殊的时刻（如系统调用、异常或中断），CPU 会切换状态。
表 15.2 动态重定位：硬件要求
硬件要求 解释
特权模式 需要，以防用户模式的进程执行特权操作
基址/界限寄存器 每个 CPU 需要一对寄存器来支持地址转换和界限检查
能够转换虚拟地址并检查它是否越界 电路来完成转换和检查界限，在这种情况下，非常简单
修改基址/界限寄存器的特权指令 在让用户程序运行之前，操作系统必须能够设置这些值
注册异常处理程序的特权指令 操作系统必须能告诉硬件，如果异常发生，那么执行哪些代码
能够触发异常 如果进程试图使用特权指令或越界的内存

硬件还必须提供基址和界限寄存器（base and bounds register），因此每个 CPU 的内存管
理单元（Memory Management Unit，MMU）都需要这两个额外的寄存器。用户程序运行时，
硬件会转换每个地址，即将用户程序产生的虚拟地址加上基址寄存器的内容。硬件也必须
能检查地址是否有用，通过界限寄存器和 CPU 内的一些电路来实现。
硬件应该提供一些特殊的指令，用于修改基址寄存器和界限寄存器，允许操作系统在
切换进程时改变它们。这些指令是特权（privileged）指令，只有在内核模式下，才能修改
这些寄存器。想象一下，如果用户进程在运行时可以随意更改基址寄存器，那么用户进程
可能会造成严重破坏①。想象一下吧！然后迅速将这些阴暗的想法从你的头脑中赶走，因为
它们很可怕，会导致噩梦。
最后，在用户程序尝试非法访问内存（越界访问）时，CPU必须能够产生异常（exception）。
在这种情况下，CPU 应该阻止用户程序的执行，并安排操作系统的“越界”异常处理程序
（exception handler）去处理。操作系统的处理程序会做出正确的响应，比如在这种情况下终
止进程。类似地，如果用户程序尝试修改基址或者界限寄存器时，CPU 也应该产生异常，
并调用“用户模式尝试执行特权指令”的异常处理程序。CPU 还必须提供一种方法，来通
知它这些处理程序的位置，因此又需要另一些特权指令。

操作系统的问题
为了支持动态重定位，硬件添加了新的功能，使得操作系统有了一些必须处理的新问
题。硬件支持和操作系统管理结合在一起，实现了一个简单的虚拟内存。具体来说，在一
些关键的时刻操作系统需要介入，以实现基址和界限方式的虚拟内存，见表 15.3。
第一，在进程创建时，操作系统必须采取行动，为进程的地址空间找到内存空间。由
于我们假设每个进程的地址空间小于物理内存的大小，并且大小相同，这对操作系统来说
很容易。它可以把整个物理内存看作一组槽块，标记了空闲或已用。当新进程创建时，操
作系统检索这个数据结构（常被称为空闲列表，free list），为新地址空间找到位置，并将其
标记为已用。如果地址空间可变，那么生活就会更复杂，我们将在后续章节中讨论。
我们来看一个例子。在图 15.2 中，操作系统将物理内存的第一个槽块分配给自己，然
后将例子中的进程重定位到物理内存地址 32KB。另两个槽块（16～32KB，48～64KB）空
闲，因此空闲列表（free list）就包含这两个槽块。
第二，在进程终止时（正常退出，或因行为不端被强制终止），操作系统也必须做一些
工作，回收它的所有内存，给其他进程或者操作系统使用。在进程终止时，操作系统会将
这些内存放回到空闲列表，并根据需要清除相关的数据结构。
第三，在上下文切换时，操作系统也必须执行一些额外的操作。每个 CPU 毕竟只有一
个基址寄存器和一个界限寄存器，但对于每个运行的程序，它们的值都不同，因为每个程
序被加载到内存中不同的物理地址。因此，在切换进程时，操作系统必须保存和恢复基础
和界限寄存器。具体来说，当操作系统决定中止当前的运行进程时，它必须将当前基址和
界限寄存器中的内容保存在内存中，放在某种每个进程都有的结构中，如进程结构（process
structure）或进程控制块（Process Control Block，PCB）中。类似地，当操作系统恢复执行
某个进程时（或第一次执行），也必须给基址和界限寄存器设置正确的值。

动态重定位：操作系统的职责
操作系统的要求 解释
内存管理
需要为新进程分配内存
从终止的进程回收内存
一般通过空闲列表（free list）来管理内存
基址/界限管理 必须在上下文切换时正确设置基址/界限寄存器
异常处理 当异常发生时执行的代码，可能的动作是终止犯错的进程

需要注意，当进程停止时（即没有运行），操作系统可以改变其地址空间的物理位置，这
很容易。要移动进程的地址空间，操作系统首先让进程停止运行，然后将地址空间拷贝到新
位置，最后更新保存的基址寄存器（在进程结构中），指向新位置。当该进程恢复执行时，它
的（新）基址寄存器会被恢复，它再次开始运行，显然它的指令和数据都在新的内存位置了。
第四，操作系统必须提供异常处理程序（exception handler），或要一些调用的函数，像
上面提到的那样。操作系统在启动时加载这些处理程序（通过特权命令）。例如，当一个进
程试图越界访问内存时，CPU 会触发异常。在这种异常产生时，操作系统必须准备采取行
动。通常操作系统会做出充满敌意的反应：终止错误进程。操作系统应该尽力保护它运行
的机器，因此它不会对那些企图访问非法地址或执行非法指令的进程客气。再见了，行为
不端的进程，很高兴认识你。

表 15.4 为按时间线展示了大多数硬件与操作系统的交互。可以看出，操作系统在启动时
15.5 操作系统的问题 107
做了什么，为我们准备好机器，然后在进程（进程 A）开始运行时发生了什么。请注意，地
址转换过程完全由硬件处理，没有操作系统的介入。在这个时候，发生时钟中断，操作系统
切换到进程 B 运行，它执行了“错误的加载”（对一个非法内存地址），这时操作系统必须介
入，终止该进程，清理并释放进程 B 占用的内存，将它从进程表中移除。从表中可以看出，
我们仍然遵循受限直接访问（limited direct execution）的基本方法，大多数情况下，操作系统
正确设置硬件后，就任凭进程直接运行在 CPU 上，只有进程行为不端时才介入。

本章通过虚拟内存使用的一种特殊机制，即地址转换（address translation），扩展了受限
直接访问的概念。利用地址转换，操作系统可以控制进程的所有内存访问，确保访问在地
址空间的界限内。这个技术高效的关键是硬件支持，硬件快速地将所有内存访问操作中的
虚拟地址（进程自己看到的内存位置）转换为物理地址（实际位置）。所有的这一切对进程
来说都是透明的，进程并不知道自己使用的内存引用已经被重定位，制造了美妙的假象。
我们还看到了一种特殊的虚拟化方式，称为基址加界限的动态重定位。基址加界限的
虚拟化方式非常高效，因为只需要很少的硬件逻辑，就可以将虚拟地址和基址寄存器加起
来，并检查进程产生的地址没有越界。基址加界限也提供了保护，操作系统和硬件的协作，
确保没有进程能够访问其地址空间之外的内容。保护肯定是操作系统最重要的目标之一。
没有保护，操作系统不可能控制机器（如果进程可以随意修改内存，它们就可以轻松地做
出可怕的事情，比如重写陷阱表并完全接管系统）。

遗憾的是，这个简单的动态重定位技术有效率低下的问题。例如，从图 15.2 中可以看到，
重定位的进程使用了从 32KB 到 48KB 的物理内存，但由于该进程的栈区和堆区并不很大，
导致这块内存区域中大量的空间被浪费。这种浪费通常称为内部碎片（internal fragmentation），
指的是已经分配的内存单元内部有未使用的空间（即碎片），造成了浪费。在我们当前的方式
中，即使有足够的物理内存容纳更多进程，但我们目前要求将地址空间放在固定大小的槽块
中，因此会出现内部碎片①。所以，我们需要更复杂的机制，以便更好地利用物理内存，避免
内部碎片。第一次尝试是将基址加界限的概念稍稍泛化，得到分段（segmentation）的概念


到目前为止，我们一直假设将所有进程的地址空间完整地加载到内存中。利用基址和
界限寄存器，操作系统很容易将不同进程重定位到不同的物理内存区域。但是，对于这些
内存区域，你可能已经注意到一件有趣的事：栈和堆之间，有一大块“空闲”空间。

如果我们将整个地址空间放入物理内存，那么栈和堆之间的空间并
没有被进程使用，却依然占用了实际的物理内存。因此，简单的通过基址寄存器和界限寄
存器实现的虚拟内存很浪费。另外，如果剩余物理内存无法提供连续区域来放置完整的地
址空间，进程便无法运行。这种基址加界限的方式看来并不像我们期望的那样灵活。


怎样支持大地址空间
怎样支持大地址空间，同时栈和堆之间（可能）有大量空闲空间？在之前的例子里，地址空间非常
小，所以这种浪费并不明显。但设想一个 32 位（4GB）的地址空间，通常的程序只会使用几兆的内存，
但需要整个地址空间都放在内存中。

分段：泛化的基址/界限
为了解决这个问题，分段（segmentation）的概念应运而生。分段并不是一个新概念，
它甚至可以追溯到 20 世纪 60 年代初期。这个想法很简单，在 MMU 中引入不止
一个基址和界限寄存器对，而是给地址空间内的每个逻辑段（segment）一对。一个段只是
地址空间里的一个连续定长的区域，在典型的地址空间里有 3 个逻辑不同的段：代码、栈
和堆。分段的机制使得操作系统能够将不同的段放到不同的物理内存区域，从而避免了虚
拟地址空间中的未使用部分占用物理内存。

我们来看一个例子。假设我们希望将图 16.1 中的地址空间放入物理内存。通过给每个
段一对基址和界限寄存器，可以将每个段独立地放入物理内存。如图 16.2 所示，64KB 的物
理内存中放置了 3 个段（为操作系统保留 16KB）。
从图中可以看到，只有已用的内存才在物理内存中分配空间，因此可以容纳巨大的地
址空间，其中包含大量未使用的地址空间（有时又称为稀疏地址空间，sparse address spaces）。
你会想到，需要 MMU 中的硬件结构来支持分断：在这种情况下，需要一组 3 对基址
和界限寄存器。表 16.1 展示了上面的例子中的寄存器值，每个界限寄存器记录了一个段
的大小。

如表 16.1 所示，代码段放在物理地址 32KB，大小是 2KB。堆在 34KB，大小也是 2KB。
利用图 16.1 中的地址空间，我们来看一个地址转换的例子。假设现在要引用虚拟地址
100（在代码段中），MMU 将基址值加上偏移量（100）得到实际的物理地址：100 + 32KB =
32868。然后它会检查该地址是否在界限内（100 小于 2KB），发现是的，于是发起对物理地
址 32868 的引用。

：段错误
段错误指的是在支持分段的机器上发生了非法的内存访问。有趣的是，即使在不支持分段的机器上
这个术语依然保留。

来看一个堆中的地址，虚拟地址 4200（同样参考图 16.1）。如果用虚拟地址 4200 加上
16.2 我们引用哪个段 113
堆的基址（34KB），得到物理地址 39016，这不是正确的地址。我们首先应该先减去堆的偏
移量，即该地址指的是这个段中的哪个字节。因为堆从虚拟地址 4K（4096）开始，4200 的
偏移量实际上是 4200 减去 4096，即 104，然后用这个偏移量（104）加上基址寄存器中的
物理地址（34KB），得到真正的物理地址 34920。
如果我们试图访问非法的地址，例如 7KB，它超出了堆的边界呢？你可以想象发生的情况：
硬件会发现该地址越界，因此陷入操作系统，很可能导致终止出错进程。这就是每个 C 程序员
都感到恐慌的术语的来源：段异常（segmentation violation）或段错误（segmentation fault）。

我们引用哪个段
硬件在地址转换时使用段寄存器。它如何知道段内的偏移量，以及地址引用了哪个段？
一种常见的方式，有时称为显式（explicit）方式，就是用虚拟地址的开头几位来标识
不同的段，VAX/VMS 系统使用了这种技术。在我们之前的例子中，有 3 个段，因此
需要两位来标识。如果我们用 14 位虚拟地址的前两位来标识，那么虚拟地址如下所示：
那么在我们的例子中，如果前两位是 00，硬件就知道这是属于代码段的地址，因此使
用代码段的基址和界限来重定位到正确的物理地址。如果前两位是 01，则是堆地址，对应
地，使用堆的基址和界限。下面来看一个 4200 之上的堆虚拟地址，进行进制转换，确保弄
清楚这些内容。虚拟地址 4200 的二进制形式如下：
从图中可以看到，前两位（01）告诉硬件我们引用哪个段。剩下的 12 位是段内偏移：
0000 0110 1000（即十六进制 0x068 或十进制 104）。因此，硬件就用前两位来决定使用哪个
段寄存器，然后用后 12 位作为段内偏移。偏移量与基址寄存器相加，硬件就得到了最终的
物理地址。请注意，偏移量也简化了对段边界的判断。我们只要检查偏移量是否小于界限，
大于界限的为非法地址。因此，如果基址和界限放在数组中（每个段一项），为了获得需要
的物理地址，硬件会做下面这样的事：
1 // get top 2 bits of 14-bit VA
2 Segment = (VirtualAddress & SEG_MASK) >> SEG_SHIFT
3 // now get offset
4 Offset = VirtualAddress & OFFSET_MASK
5 if (Offset >= Bounds\[Segment])
6 RaiseException(PROTECTION_FAULT)
7 else
8 PhysAddr = Base\[Segment] + Offset
9 Register = AccessMemory(PhysAddr)


在我们的例子中，可以为上面的常量填上值。具体来说，SEG_MASK 为 0x3000，
SEG_SHIFT 为 12，OFFSET_MASK 为 0xFFF。
你或许已经注意到，上面使用两位来区分段，但实际只有 3 个段（代码、堆、栈），因
此有一个段的地址空间被浪费。因此有些系统中会将堆和栈当作同一个段，因此只需要一
位来做标识。
硬件还有其他方法来决定特定地址在哪个段。在隐式（implicit）方式中，硬件通过地
址产生的方式来确定段。例如，如果地址由程序计数器产生（即它是指令获取），那么地址
在代码段。如果基于栈或基址指针，它一定在栈段。其他地址则在堆段。 

栈怎么办
到目前为止，我们一直没有讲地址空间中的一个重要部分：栈。在表 16.1 中，栈被重
定位到物理地址 28KB。但有一点关键区别，它反向增长。在物理内存中，它始于 28KB，
增长回到 26KB，相应虚拟地址从 16KB 到 14KB。地址转换必须有所不同。
首先，我们需要一点硬件支持。除了基址和界限外，硬件还需要知道段的增长方向（用
一位区分，比如 1 代表自小而大增长，0 反之）。在表 16.2 中，我们更新了硬件记录的视图。

硬件理解段可以反向增长后，这种虚拟地址的地址转换必须有点不同。下面来看一个
栈虚拟地址的例子，将它进行转换，以理解这个过程：
在这个例子中，假设要访问虚拟地址 15KB，它应该映射到物理地址 27KB。该虚拟地
址的二进制形式是：11 1100 0000 0000（十六进制 0x3C00）。硬件利用前两位（11）来指定
段，但然后我们要处理偏移量 3KB。为了得到正确的反向偏移，我们必须从 3KB 中减去最
大的段地址：在这个例子中，段可以是 4KB，因此正确的偏移量是 3KB 减去 4KB，即−1KB。
只要用这个反向偏移量（−1KB）加上基址（28KB），就得到了正确的物理地址 27KB。用
户可以进行界限检查，确保反向偏移量的绝对值小于段的大小。

 支持共享
随着分段机制的不断改进，系统设计人员很快意识到，通过再多一点的硬件支持，就
能实现新的效率提升。具体来说，要节省内存，有时候在地址空间之间共享（share）某些
内存段是有用的。尤其是，代码共享很常见，今天的系统仍然在使用。
为了支持共享，需要一些额外的硬件支持，这就是保护位（protection bit）。基本为每个
段增加了几个位，标识程序是否能够读写该段，或执行其中的代码。通过将代码段标记为只
读，同样的代码可以被多个进程共享，而不用担心破坏隔离。虽然每个进程都认为自己独占
这块内存，但操作系统秘密地共享了内存，进程不能修改这些内存，所以假象得以保持。

表 16.3 展示了一个例子，是硬件（和操作系统）记录的额外信息。可以看到，代码段
的权限是可读和可执行，因此物理内存中的一个段可以映射到多个虚拟地址空间。
有了保护位，前面描述的硬件算法也必须改变。除了检查虚拟地址是否越界，硬件还
需要检查特定访问是否允许。如果用户进程试图写入只读段，或从非执行段执行指令，硬
件会触发异常，让操作系统来处理出错进程。

细粒度与粗粒度的分段
到目前为止，我们的例子大多针对只有很少的几个段的系统（即代码、栈、堆）。我们
可以认为这种分段是粗粒度的（coarse-grained），因为它将地址空间分成较大的、粗粒度的
块。但是，一些早期系统（如 Multics）更灵活，允许将地址空间划分为大量
较小的段，这被称为细粒度（fine-grained）分段。
支持许多段需要进一步的硬件支持，并在内存中保存某种段表（segment table）。这种段
表通常支持创建非常多的段，因此系统使用段的方式，可以比之前讨论的方式更灵活。例如，
像 Burroughs B5000 这样的早期机器可以支持成千上万的段，有了操作系统和硬件的支持，编
译器可以将代码段和数据段划分为许多不同的部分。当时的考虑是，通过更细粒度的
段，操作系统可以更好地了解哪些段在使用哪些没有，从而可以更高效地利用内存。

操作系统支持
现在你应该大致了解了分段的基本原理。系统运行时，地址空间中的不同段被重定位
到物理内存中。与我们之前介绍的整个地址空间只有一个基址/界限寄存器对的方式相比，
大量节省了物理内存。具体来说，栈和堆之间没有使用的区域就不需要再分配物理内存，
让我们能将更多地址空间放进物理内存。
然而，分段也带来了一些新的问题。我们先介绍必须关注的操作系统新问题。第一个
是老问题：操作系统在上下文切换时应该做什么？你可能已经猜到了：各个段寄存器中的
内容必须保存和恢复。显然，每个进程都有自己独立的虚拟地址空间，操作系统必须在进
程运行前，确保这些寄存器被正确地赋值。

第二个问题更重要，即管理物理内存的空闲空间。新的地址空间被创建时，操作系统
需要在物理内存中为它的段找到空间。之前，我们假设所有的地址空间大小相同，物理内
存可以被认为是一些槽块，进程可以放进去。现在，每个进程都有一些段，每个段的大小
也可能不同。
一般会遇到的问题是，物理内存很快充满了许多空闲空间的小洞，因而很难分配给新
的段，或扩大已有的段。这种问题被称为外部碎片（external fragmentation），如图 16.3
（左边）所示。

在这个例子中，一个进程需要分配一个 20KB 的段。当前有 24KB 空闲，但并不连续（是
3 个不相邻的块）。因此，操作系统无法满足这个 20KB 的请求。
该问题的一种解决方案是紧凑（compact）物理内存，重新安排原有的段。例如，操作
系统先终止运行的进程，将它们的数据复制到连续的内存区域中去，改变它们的段寄存器
中的值，指向新的物理地址，从而得到了足够大的连续空闲空间。这样做，操作系统能让
新的内存分配请求成功。但是，内存紧凑成本很高，因为拷贝段是内存密集型的，一般会
占用大量的处理器时间。图 16.3（右边）是紧凑后的物理内存。
一种更简单的做法是利用空闲列表管理算法，试图保留大的内存块用于分配。相关的
算法可能有成百上千种，包括传统的最优匹配（best-fit，从空闲链表中找最接近需要分配空
间的空闲块返回）、最坏匹配（worst-fit）、首次匹配（first-fit）以及像伙伴算法（buddy algorithm）
这样更复杂的算法。Wilson 等人做过一个很好的调查，如果你想对这些算法了
解更多，可以从它开始，或者等到第 17 章，我们将介绍一些基本知识。但遗憾的是，无论
算法多么精妙，都无法完全消除外部碎片，因此，好的算法只是试图减小它。
唯一真正的解决办法就是（我们会在后续章节看到），完全避免这
个问题，永远不要分配不同大小的内存块。

小结
分段解决了一些问题，帮助我们实现了更高效的虚拟内存。不只是动态重定位，通过
避免地址空间的逻辑段之间的大量潜在的内存浪费，分段能更好地支持稀疏地址空间。它
还很快，因为分段要求的算法很容易，很适合硬件完成，地址转换的开销极小。分段还有
一个附加的好处：代码共享。如果代码放在独立的段中，这样的段就可能被多个运行的程
序共享。
但我们已经知道，在内存中分配不同大小的段会导致一些问题，我们希望克服。首先，
是我们上面讨论的外部碎片。由于段的大小不同，空闲内存被割裂成各种奇怪的大小，因
此满足内存分配请求可能会很难。用户可以尝试采用聪明的算法，或定期紧凑内存，
但问题很根本，难以避免。
第二个问题也许更重要，分段还是不足以支持更一般化的稀疏地址空间。例如，如果
有一个很大但是稀疏的堆，都在一个逻辑段中，整个堆仍然必须完整地加载到内存中。换
言之，如果使用地址空间的方式不能很好地匹配底层分段的设计目标，分段就不能很好地
工作。因此我们需要找到新的解决方案。你准备好了吗？

管理空闲空间当然可以很容易，我们会在讨论分页概念时看到。
如果需要管理的空间被划分为固定大小的单元，就很容易。在这种情况下，只需要维护这
些大小固定的单元的列表，如果有请求，就返回列表中的第一项。

如果要管理的空闲空间由大小不同的单元构成，管理就变得困难（而且有趣）。这种情
况出现在用户级的内存分配库（如 malloc()和 free()），或者操作系统用分段（segmentation）
的方式实现虚拟内存。在这两种情况下，出现了外部碎片（external fragmentation）的问题：
空闲空间被分割成不同大小的小块，成为碎片，后续的请求可能失败，因为没有一块足够
大的连续空闲空间，即使这时总的空闲空间超出了请求的大小。

关键问题：如何管理空闲空间
要满足变长的分配请求，应该如何管理空闲空间？什么策略可以让碎片最小化？不同方法的时间和
空间开销如何？

该库管理的空间由于历史原因被称为堆，在堆上管理空闲空间的数据结构通常称为空
闲列表（free list）。该结构包含了管理内存区域中所有空闲块的引用。当然，该数据结构不
一定真的是列表，而只是某种可以追踪空闲空间的数据结构。
进一步假设，我们主要关心的是外部碎片（external fragmentation），如上所述。当然，
分配程序也可能有内部碎片（internal fragmentation）的问题。如果分配程序给出的内存块超
出请求的大小，在这种块中超出请求的空间（因此而未使用）就被认为是内部碎片（因为
浪费发生在已分配单元的内部），这是另一种形式的空间浪费。但是，简单起见，同时也因
为它更有趣，这里主要讨论外部碎片。
我们还假设，内存一旦被分配给客户，就不可以被重定位到其他位置。例如，一个程
序调用 malloc()，并获得一个指向堆中一块空间的指针，这块区域就“属于”这个程序了，
库不再能够移动，直到程序调用相应的 free()函数将它归还。因此，不可能进行紧凑
（compaction）空闲空间的操作，从而减少碎片①。但是，操作系统层在实现分段（segmentation）
时，却可以通过紧凑来减少碎片（正如第 16 章讨论的那样）。
最后我们假设，分配程序所管理的是连续的一块字节区域。在一些情况下，分配程序
可以要求这块区域增长。例如，一个用户级的内存分配库在空间快用完时，可以向内核申
请增加堆空间（通过 sbrk 这样的系统调用），但是，简单起见，我们假设这块区域在整个生
命周期内大小固定。


追踪已分配空间的大小
你可能注意到，free(void *ptr)接口没有块大小的参数。因此它是假定，对于给定的指针，
内存分配库可以很快确定要释放空间的大小，从而将它放回空闲列表。
要完成这个任务，大多数分配程序都会在头块（header）中保存一点额外的信息，它在
内存中，通常就在返回的内存块之前。我们再看一个例子（见图 17.1）。在这个例子中，我
们检查一个 20 字节的已分配块，由 ptr 指着，设想用户调用了 malloc()，并将结果保存在
ptr 中：ptr = malloc(20)。
该头块中至少包含所分配空间的大小（这个例子中是 20）。它也可能包含一些额外的指
针来加速空间释放，包含一个幻数来提供完整性检查，以及其他信息。我们假定，一个简
单的头块包含了分配空间的大小和一个幻数：
typedef struct header_t {
 int size;
 int magic;
} header_t;
上面的例子看起来会像图 17.2 的样子。用户调用 free(ptr)时，库会通过简单的指针运算
得到头块的位置：
void free(void *ptr) {
 header_t *hptr = (void *)ptr - sizeof(header_t);
} 
[!image](./images/14.png)
获得头块的指针后，库可以很容易地确定幻数是否符合预期的值，作为正常性检查
（assert（hptr->magic == 1234567）），并简单计算要释放的空间大小（即头块的大小加区域长
度）。请注意前一句话中一个小但重要的细节：实际释放的是头块大小加上分配给用户的空
间的大小。因此，如果用户请求 N 字节的内存，库不是寻找大小为 N 的空闲块，而是寻找
N 加上头块大小的空闲块。

嵌入空闲列表
到目前为止，我们这个简单的空闲列表还只是一个概念上的存在，它就是一个列表，
描述了堆中的空闲内存块。但如何在空闲内存自己内部建立这样一个列表呢？
在更典型的列表中，如果要分配新节点，你会调用 malloc()来获取该节点所需的空间。
遗憾的是，在内存分配库内，你无法这么这！你需要在空闲空间本身中建立空闲空间列表。
虽然听起来有点奇怪，但别担心，这是可以这到的。
假设我们需要管理一个 4096 字节的内存块（即堆是 4KB）。为了将它作为一个空闲空
间列表来管理，首先要初始化这个列表。开始，列表中只有一个条目，记录了大小为 4096
的空间（减去头块的大小）。下面是该列表中一个节点描述：
typedef struct node_t {
 int size; 
  struct node_t *next;
 } node_t; 
现在来看一些代码，它们初始化堆，并将空闲列表的第一个元素放在该空间中。假设
堆构建在某块空闲空间上，这块空间通过系统调用 mmap()获得。这不是构建这种堆的唯一
选择，但在这个例子中很合适。下面是代码：
// mmap() returns a pointer to a chunk of free space
node_t *head = mmap(NULL, 4096, PROT_READ|PROT_WRITE,
 MAP_ANON|MAP_PRIVATE, -1, 0);
head->size = 4096 - sizeof(node_t);
head->next = NULL;
执行这段代码之后，列表的状态是它只有一个条目，记录大小为 4088。
是的，这是一个小堆，但对我们是一个很好的例子。head 指针指向这块区域的起始地址，
假设是 16KB（尽管任何虚拟地址都可以）。堆看起来如图 17.3 所示。
现在，假设有一个 100 字节的内存请求。为了满足这个请求，库首先要找到一个足够
大小的块。因为只有一个 4088 字节的块，所以选中这个块。然后，这个块被分割（split）
为两块：一块足够满足请求（以及头块，如前所述），一块是剩余的空闲块。假设记录头块
为 8 个字节（一个整数记录大小，一个整数记录幻数），堆中的空间如图 17.4 所示。
[!image](./images/15.png)
至此，对于 100 字节的请求，库从原有的一个空闲块中分配了 108 字节，返回指向它
的一个指针（在上图中用 ptr 表示），并在其之前连续的 8 字节中记录头块信息，供未来的
free()函数使用。同时将列表中的空闲节点缩小为 3980 字节（4088−108）。
现在再来看该堆，其中有 3 个已分配区域，每个 100（加上头块是 108）。这个堆如图 17.5
所示。
可以看出，堆的前 324 字节已经分配，因此我们看到该空间中有 3 个头块，以及 3 个 100
字节的用户使用空间。空闲列表还是无趣：只有一个节点（由 head 指向），但在 3 次分割后，
现在大小只有 3764 字节。但如果用户程序通过 free()归还一些内存，会发生什么？
在这个例子中，应用程序调用 free(16500)，归还了中间的一块已分配空间（内存块的起
始地址 16384 加上前一块的 108，和这一块的头块的 8 字节，就得到了 16500）。这个值在
前图中用 sptr 指向。
库马上弄清楚了这块要释放空间的大小，并将空闲块加回空闲列表。假设我们将它插
入到空闲列表的头位置，该空间如图 17.6 所示。
[!image](./images/16.png)
现在的空闲列表包括一个小空闲块（100 字节，由列表的头指向）和一个大空闲块（3764
字节）。
我们的列表终于有不止一个元素了！是的，空闲空间被分割成了两段，但很常见。
最后一个例子：现在假设剩余的两块已分配的空间也被释放。没有合并，空闲列表将
非常破碎，如图 17.7 所示。
从图中可以看出，我们现在一团糟！为什么？简单，我们忘了合并（coalesce）列表项，
虽然整个内存空间是空闲的，但却被分成了小段，因此形成了碎片化的内存空间。解决方
案很简单：遍历列表，合并（merge）相邻块。完成之后，堆又成了一个整体。
[!image](./images/17.png)
让堆增长
我们应该讨论最后一个很多内存分配库中都有的机制。具体来说，如果堆中的内存空
间耗尽，应该怎么办？最简单的方式就是返回失败。在某些情况下这也是唯一的选择，因
此返回 NULL 也是一种体面的方式。别太难过！你尽力了，即使失败，你也虽败犹荣。
大多数传统的分配程序会从很小的堆开始，当空间耗尽时，再向操作系统申请更大的空
间。通常，这意味着它们进行了某种系统调用（例如，大多数 UNIX 系统中的 sbrk），让堆增
长。操作系统在执行 sbrk 系统调用时，会找到空闲的物理内存页，将它们映射到请求进程的
地址空间中去，并返回新的堆的末尾地址。这时，就有了更大的堆，请求就可以成功满足。

基本策略 
理想的分配程序可以同时保证快速和碎片最小化。遗憾的是，由于分配及释放的请求
序列是任意的（毕竟，它们由用户程序决定），任何特定的策略在某组不匹配的输入下都会
变得非常差。所以我们不会描述“最好”的策略，而是介绍一些基本的选择，并讨论它们
的优缺点。

最优匹配
最优匹配（best fit）策略非常简单：首先遍历整个空闲列表，找到和请求大小一样或更
大的空闲块，然后返回这组候选者中最小的一块。这就是所谓的最优匹配（也可以称为最
小匹配）。只需要遍历一次空闲列表，就足以找到正确的块并返回。
最优匹配背后的想法很简单：选择最接它用户请求大小的块，从而尽量避免空间浪费。
然而，这有代价。简单的实现在遍历查找正确的空闲块时，要付出较高的性能代价。
最差匹配
最差匹配（worst fit）方法与最优匹配相反，它尝试找最大的空闲块，分割并满足用户
需求后，将剩余的块（很大）加入空闲列表。最差匹配尝试在空闲列表中保留较大的块，
而不是向最优匹配那样可能剩下很多难以利用的小块。但是，最差匹配同样需要遍历整个
空闲列表。更糟糕的是，大多数研究表明它的表现非常差，导致过量的碎片，同时还有很
高的开销。
首次匹配
首次匹配（first fit）策略就是找到第一个足够大的块，将请求的空间返回给用户。同样，
剩余的空闲空间留给后续请求。
首次匹配有速度优势（不需要遍历所有空闲块），但有时会让空闲列表开头的部分有很
多小块。因此，分配程序如何管理空闲列表的顺序就变得很重要。一种方式是基于地址排
序（address-based ordering）。通过保持空闲块按内存地址有序，合并操作会很容易，从而减
少了内存碎片。
下次匹配
不同于首次匹配每次都从列表的开始查找，下次匹配（next fit）算法多维护一个指针，
指向上一次查找结束的位置。其想法是将对空闲空间的查找操作扩散到整个列表中去，避
免对列表开头频繁的分割。这种策略的性能与首次匹配很接它，同样避免了遍历查找。
分离空闲列表
一直以来有一种很有趣的方式叫作分离空闲列表（segregated list）。基本想法很简单：
如果某个应用程序经常申请一种（或几种）大小的内存空间，那就用一个独立的列表，只
管理这样大小的对象。其他大小的请求都一给更通用的内存分配程序。
这种方法的好处显而易见。通过拿出一部分内存专门满足某种大小的请求，碎片就不再
是问题了。而且，由于没有复杂的列表查找过程，这种特定大小的内存分配和释放都很快。
就像所有好主意一样，这种方式也为系统引入了新的复杂性。例如，应该拿出多少内
存来专门为某种大小的请求服务，而将剩余的用来满足一般请求？
具体来说，在内核启动时，它为可能频繁请求的内核对象创建一些对象缓存（object
cache），如锁和文件系统 inode 等。这些的对象缓存每个分离了特定大小的空闲列表，因此
能够很快地响应内存请求和释放。如果某个缓存中的空闲空间快耗尽时，它就向通用内存
分配程序申请一些内存厚块（slab）（总量是页大小和对象大小的公倍数）。相反，如果给定
厚块中对象的引用计数变为 0，通用的内存分配程序可以从专门的分配程序中回收这些空
间，这通常发生在虚拟内存系统需要更多的空间的时候。

厚块分配程序比大多数分离空闲列表这得更多，它将列表中的空闲对象保持在预初始
化的状态。Bonwick 指出，数据结构的初始化和销毁的开销很大。通过将空闲对象保
持在初始化状态，厚块分配程序避免了频繁的初始化和销毁，从而显著降低了开销。

伙伴系统
因为合并对分配程序很关键，所以人们设计了一些方法，让合并变得简单，一个好例
子就是二分伙伴分配程序（binary buddy allocator）。
在这种系统中，空闲空间首先从概念上被看成大小为 2N 的大空间。当有一个内存分配
请求时，空闲空间被递归地一分为二，直到刚好可以满足请求的大小（再一分为二就无法
满足）。这时，请求的块被返回给用户。在下面的例子中，一个 64KB 大小的空闲空间被切
分，以便提供 7KB 的块：
[!image](./images/18.png)
在这个例子中，最左边的 8KB 块被分配给用户（如上图中深灰色部分所示）。请注意，
这种分配策略只允许分配 2 的整数次幂大小的空闲块，因此会有内部碎片（internal fragment）
的麻烦。
伙伴系统的漂亮之处在于块被释放时。如果将这个 8KB 的块归还给空闲列表，分配程
序会检查“伙伴”8KB 是否空闲。如果是，就合二为一，变成 16KB 的块。然后会检查这
个 16KB 块的伙伴是否空闲，如果是，就合并这两块。这个递归合并过程继续上溯，直到合
并整个内存区域，或者某一个块的伙伴还没有被释放。
伙伴系统运转良好的原因，在于很容易确定某个块的伙伴。怎么找？仔细想想上面例
子中的各个块的地址。如果你想得够仔细，就会发现每对互为伙伴的块只有一位不同，正
是这一位决定了它们在整个伙伴树中的层次。现在你应该已经大致了解了二分伙伴分配程
序的工作方式。
小结
在本章中，我们讨论了最基本的内存分配程序形式。这样的分配程序存在于所有地方，
与你编写的每个 C 程序链接，也和管理其自身数据结构的内存的底层操作系统链接。与许
多系统一样，在构建这样一个系统时需要这许多折中。对分配程序提供的确切工作负载了
解得越多，就越能调整它以更好地处理这种工作负载。在现代计算机系统中，构建一个适
用于各种工作负载、快速、空间高效、可扩展的分配程序仍然是一个持续的挑战。
