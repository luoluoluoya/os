* 

* 标准设备 

  现在来看一个标准设备（不是真实存在的），通过它来帮助我们更好地理解设备交互的

  机制。从图 36.2 中，可以看到一个包含两部

  分重要组件的设备。第一部分是向系统其他部

  分展现的硬件接口（interface）。同软件一样，

  硬件也需要一些接口，让系统软件来控制它的

  操作。因此，所有设备都有自己的特定接口以

  及典型交互的协议。

  第 2 部分是它的内部结构（internal structure）。这部分包含设备相关的特定实现，负责

  具体实现设备展示给系统的抽象接口。非常简单的设备通常用一个或几个芯片来实现它们

  的功能。更复杂的设备会包含简单的 CPU、一些通用内存、设备相关的特定芯片，来完成

  它们的工作。

  [!image](./images/42.png)

* 标准协议 

  一个（简化的）设备接口包含 3 个寄存器：一个状态（status）寄存器，

  可以读取并查看设备的当前状态；一个命令（command）寄存器，用于通知设备执行某个具

  体任务；一个数据（data）寄存器，将数据传给设备或从设备接收数据。通过读写这些寄存

  器，操作系统可以控制设备的行为。

  我们现在来描述操作系统与该设备的典型交互，以便让设备为它做某事。

  While (STATUS == BUSY) 

   ; // wait until device is not busy 

  Write data to DATA register 

  Write command to COMMAND register 

   (Doing so starts the device and executes the command) 

  While (STATUS == BUSY) 

   ; // wait until device is done with your request 

  该协议包含 4 步。第 1 步，操作系统通过反复读取状态寄存器，等待设备进入可以接

  收命令的就绪状态。我们称之为轮询（polling）设备（基本上，就是问它正在做什么）。第

  2 步，操作系统下发数据到数据寄存器。例如，你可以想象如果这是一个磁盘，需要多次写

  入操作，将一个磁盘块（比如 4KB）传递给设备。如果主 CPU 参与数据移动（就像这个示

  例协议一样），我们就称之为编程的 I/O（programmed I/O，PIO）。第 3 步，操作系统将命令

  写入命令寄存器；这样设备就知道数据已经准备好了，它应该开始执行命令。最后一步，

  操作系统再次通过不断轮询设备，等待并判断设备是否执行完成命令（有可能得到一个指

  示成功或失败的错误码）。

  这个简单的协议好处是足够简单并且有效。但是难免会有一些低效和不方便。我们注

  意到这个协议存在的第一个问题就是轮询过程比较低效，在等待设备执行完成命令时浪费

  大量 CPU 时间，如果此时操作系统可以切换执行下一个就绪进程，就可以大大提高 CPU 的

  利用率。

* 利用中断减少 CPU 开销 

  多年前，工程师们发明了我们目前已经很常见的中断（interrupt）来减少 CPU 开销。有

  了中断后，CPU 不再需要不断轮询设备，而是向设备发出一个请求，然后就可以让对应进

  程睡眠，切换执行其他任务。当设备完成了自身操作，会抛出一个硬件中断，引发 CPU 跳

  转执行操作系统预先定义好的中断服务例程（Interrupt Service Routine，ISR），或更为简单

  的中断处理程序（interrupt handler）。中断处理程序是一小段操作系统代码，它会结束之前

  的请求（比如从设备读取到了数据或者错误码）并且唤醒等待 I/O 的进程继续执行。

  因此，中断允许计算与 I/O 重叠（overlap），这是提高 CPU 利用率的关键。

  注意，使用中断并非总是最佳方案。假如有一个非常高性能的设备，它处理请求很快：

  通常在 CPU 第一次轮询时就可以返回结果。此时如果使用中断，反而会使系统变慢：切换到

  其他进程，处理中断，再切换回之前的进程代价不小。因此，如果设备非常快，那么最好的

  办法反而是轮询。如果设备比较慢，那么采用允许发生重叠的中断更好。如果设备的速度未

  知，或者时快时慢，可以考虑使用混合（hybrid）策略，先尝试轮询一小段时间，如果设备没

  有完成操作，此时再使用中断。这种两阶段（two-phased）的办法可以实现两种方法的好处。

  另一个最好不要使用中断的场景是网络。网络端收到大量数据包，如果每一个包都发

  生一次中断，那么有可能导致操作系统发生活锁（livelock），即不断处理中断而无法处理用

  户层的请求。例如，假设一个 Web 服务器因为“点杠效应”而突然承受很重的负载。这种

  情况下，偶尔使用轮询的方式可以更好地控制系统的行为，并允许 Web 服务器先服务一些

  用户请求，再回去检查网卡设备是否有更多数据包到达。

  另一个基于中断的优化就是合并（coalescing）。设备在抛出中断之前往往会等待一小段

  时间，在此期间，其他请求可能很快完成，因此多次中断可以合并为一次中断抛出，从而

  降低处理中断的代价。当然，等待太长会增加请求的延迟，这是系统中常见的折中。

* 中断并非总是比 **PIO** 好

  尽管中断可以做到计算与 I/O 的重叠，但这仅在慢速设备上有意义。否则，额外的中断处理和上下

  文切换的代价反而会超过其收益。另外，如果短时间内出现大量的中断，可能会使得系统过载并且引发

  活锁[MR96]。这种情况下，轮询的方式可以在操作系统自身的调度上提供更多的控制，反而更有效。

* 利用 DMA 进行更高效的数据传送

  DMA 工作过程如下。为了能够将数据传送给设备，操作系统会通过编程告诉 DMA 引

  擎数据在内存的位置，要拷贝的大小以及要拷贝到哪个设备。在此之后，操作系统就可以

  处理其他请求了。当 DMA 的任务完成后，DMA 控制器会抛出一个中断来告诉操作系统自

  己已经完成数据传输。数据的拷贝工作都是由 DMA 控制器来完成的。

* 设备交互的方法 

  现在，我们了解了执行 I/O 涉及的效率问题后，还有其他一些问题需要解决，以便将设

  备合并到系统中。你可能已经注意到了一个问题：我们还没有真正讨论过操作系统究竟如

  何与设备进行通信！所以问题如下。

  随着技术的不断发展，主要有两种方式来实现与设备的交互。第一种办法相对老一些

  （在 IBM 主机中使用了多年），就是用明确的 I/O 指令。这些指令规定了操作系统将数据发

  送到特定设备寄存器的方法，从而允许构造上文提到的协议。

  例如在 x86 上，in 和 out 指令可以用来与设备进行交互。当需要发送数据给设备时，调

  用者指定一个存入数据的特定寄存器及一个代表设备的特定端口。执行这个指令就可以实

  现期望的行为。

  这些指令通常是特权指令（privileged）。操作系统是唯一可以直接与设备交互的实体。

  例如，设想如果任意程序都可以直接读写磁盘：完全混乱（总是会这样），因为任何用户程

  序都可以利用这个漏洞来取得计算机的全部控制权。

  第二种方法是内存映射 I/O（memory- mapped I/O）。通过这种方式，硬件将设备寄存器

  作为内存地址提供。当需要访问设备寄存器时，操作系统装载（读取）或者存入（写入）

  到该内存地址；然后硬件会将装载/存入转移到设备上，而不是物理内存。

  两种方法没有一种具备极大的优势。内存映射 I/O 的好处是不需要引入新指令来实现设

  备交互，但两种方法今天都在使用。

* 纳入操作系统：设备驱动程序 

  每个设备都有非常具体的接口，如何将它们纳入操作系统，而我们希望操作系统尽可能通用。例如文件系统，我们希望开发一个文件系统可以工作在

  SCSI 硬盘、IDE 硬盘、USB 钥匙串设备等设备之上，并且希望这个文件系统不那么清楚对

  这些不同设备发出读写请求的全部细节。

  这个问题可以通过古老的抽象（abstraction）技术来解决。在最底层，操作系统的一部

  分软件清楚地知道设备如何工作，我们将这部分软件称为设备驱动程序（device driver），所

  有设备交互的细节都封装在其中。我们来看看 Linux 文件系统栈，理解抽象技术如何应用于操作系统的设计和实现。图

  36.3 粗略地展示了 Linux 软件的组织方式。可以看出，文件系统（当然也包括在其之上的应

  用程序）完全不清楚它使用的是什么类型的磁盘。它只需要简单地向通用块设备层发送读

  写请求即可，块设备层会将这些请求路由给对应的设备驱动，然后设备驱动来完成真正的

  底层操作。

  [!image](./images/43.png)

  注意，这种封装也有不足的地方。例如，如果有一个设备可以提供很多特殊的功能，

  但为了兼容大多数操作系统它不得不提供一个通用的接口，这样就使得自身的特殊功能无

  法使用。这种情况在使用 SCSI 设备的 Linux 中就发生了。SCSI 设备提供非常丰富的报告错

  误信息，但其他的块设备（比如 ATA/IDE）只提供非常简单的报错处理，这样上层的所有

  软件只能在出错时收到一个通用的 EIO 错误码（一般 IO 错误），SCSI 可能提供的所有附加

  信息都不能报告给文件系统。

#### 磁盘驱动器

* 接口 

  我们先来了解一个现代磁盘驱动器的接口。所有现代驱动器的基本接口都很简单。驱

  动器由大量扇区（512 字节块）组成，每个扇区都可以读取或写入。在具有 *n* 个扇区的磁盘

  上，扇区从 0 到 *n*−1 编号。因此，我们可以将磁盘视为一组扇区，0 到 *n*−1 是驱动器的地址

  空间（address space）。

  多扇区操作是可能的。实际上，许多文件系统一次读取或写入 4KB（或更多）。但是，

  在更新磁盘时，驱动器制造商唯一保证的是单个 512 字节的写入是原子的（atomic，即它将

  完整地完成或者根本不会完成）。因此，如果发生不合时宜的掉电，则只能完成较大写入的

  一部分 [有时称为不完整写入（torn write）]。

  大多数磁盘驱动器的客户端都会做出一些假设，但这些假设并未直接在接口中指定。具体来说，通常可以假

  设访问驱动器地址空间内两个彼此靠近的块将比访问两个相隔很远的块更快。人们通常也

  可以假设访问连续块（即顺序读取或写入）是最快的访问模式，并且通常比任何更随机的

  访问模式快得多。

* 基本几何形状 

  让我们开始了解现代磁盘的一些组件。我们从一个盘片（platter）开始，它是一个圆形

  坚硬的表面，通过引入磁性变化来永久存储数据。磁盘可能有一个或多个盘片。每个盘片

  有两面，每面都称为表面。这些盘片通常由一些硬质材料（如铝）制成，然后涂上薄薄的

  磁性层，即使驱动器断电，驱动器也能持久存储数据位。

  所有盘片都围绕主轴（spindle）连接在一起，主轴连接到一个电机，以一个恒定（固定）

  的速度旋转盘片（当驱动器接通电源时）。旋转速率通常以每分钟转数（Rotations Per Minute，

  RPM）来测量，典型的现代数值在 7200～15000 RPM 范围内。请注意，我们经常会对单次

  旋转的时间感兴趣，例如，以 10000 RPM 旋转的驱动器意味着一次旋转需要大约 6ms。

  数据在扇区的同心圆中的每个表面上被编码。我们称这样的同心圆为一个磁道（track）。

  一个表面包含数以千计的磁道，紧密地排在一起，数百个磁道只有头发的宽度。

  要从表面进行读写操作，我们需要一种机制，使我们能够感应（即读取）磁盘上的磁

  性图案，或者让它们发生变化（即写入）。读写过程由磁头（disk head）完成；驱动器的每

  个表面有一个这样的磁头。磁头连接到单个磁盘臂（disk arm）上，磁盘臂在表面上移动，

  将磁头定位在期望的磁道上。

* 磁头必须等待期望的扇区旋转

  到磁头下。这种等待在现代驱动器中经常发生，并且是 I/O 服务时间的重要组成部分，它有

  一个特殊的名称：旋转延迟

  驱动器必须首先将磁盘臂移动到正确的磁道（在

  这种情况下，是最外面的磁道），通过一个所谓的寻道（seek）过程。寻道，以及旋转，是

  最昂贵的磁盘操作之一。

  I/O 的最后阶段将发生，称为传输（transfer），数据从表面

  读取或写入表面。因此，我们得到了完整的 I/O 时间图：首先寻道，然后等待转动延迟，最

  后传输。

* 一些其他细节 

  扇区往往会偏斜，因为从一个磁道切换到另一个磁道

  时，磁盘需要时间来重新定位磁头（即便移到相邻磁道）。

  如果没有这种偏斜，磁头将移动到下一个磁道，但所需的

  下一个块已经旋转到磁头下，因此驱动器将不得不等待整

  个旋转延迟，才能访问下一个块。

  外圈磁道通常比内圈磁道具有更多扇

  区，这是几何结构的结果。那里空间更多。这些磁道通常

  被称为多区域（multi-zoned）磁盘驱动器，其中磁盘被组

  织成多个区域，区域是表面上连续的一组磁道。每个区域

  每个磁道具有相同的扇区数量，并且外圈区域具有比内圈

  区域更多的扇区。

  最后，任何现代磁盘驱动器都有一个重要组成部分，即它的缓存（cache），由于历史原

  因有时称为磁道缓冲区（track buffer）。该缓存只是少量的内存（通常大约 8MB 或 16MB），

  驱动器可以使用这些内存来保存从磁盘读取或写入磁盘的数据。例如，当从磁盘读取扇区

  时，驱动器可能决定读取该磁道上的所有扇区并将其缓存在其存储器中。这样做可以让驱

  动器快速响应所有后续对同一磁道的请求。

  在写入时，驱动器面临一个选择：它应该在将数据放入其内存之后，还是写入实际写

  入磁盘之后，回报写入完成？前者被称为后写（write back）缓存（有时称为立即报告，immediate 

  reporting），后者则称为直写（write through）。后写缓存有时会使驱动器看起来“更快”，但

  可能有危险。如果文件系统或应用程序要求将数据按特定顺序写入磁盘以保证正确性，后

  写缓存可能会导致问题

* I/O 时间：用数学 

  既然我们有了一个抽象的磁盘模型，就可以通过一些分析来更好地理解磁盘性能。具

  体来说，现在可以将 I/O 时间表示为 3 个主要部分之和：

  *T*I/O = *T* 寻道 + *T* 旋转 + *T* 传输 

  请注意，通常比较驱动器用 I/O 速率（*R*I/O）更容易（如下所示），它很容易从时间计算

  出来。只要将传输的大小除以所花的时间：

  RI/O = 	传输大小/TI/O

  为了更好地感受 I/O 时间，我们执行以下计算。假设有两个我们感兴趣的工作负载。第

  一个工作负载称为随机（random）工作负载，它向磁盘上的随机位置发出小的（例如 4KB）

  读取请求。随机工作负载在许多重要的应用程序中很常见，包括数据库管理系统。第二种

  称为顺序（sequential）工作负载，只是从磁盘连续读取大量的扇区，不会跳过。顺序访问

  模式很常见，因此也很重要。

* 顺序地使用磁盘

  尽可能以顺序方式将数据传输到磁盘，并从磁盘传输数据。如果顺序不可行，至少应考虑以大块传

  输数据：越大越好。如果 I/O 是以小而随机方式完成的，则 I/O 性能将受到显著影响。

* 磁盘调度

  由于 I/O 的高成本，操作系统在决定发送给磁盘的 I/O 顺序方面历来发挥作用。更具体

  地说，给定一组 I/O 请求，磁盘调度程序检查请求并决定下一个要调度的请求。

  与任务调度不同，每个任务的长度通常是不知道的，对于磁盘调度，我们可以很好地

  猜测“任务”（即磁盘请求）需要多长时间。通过估计请求的查找和可能的旋转延迟，磁盘

  调度程序可以知道每个请求将花费多长时间，因此（贪婪地）选择先服务花费最少时间的

  请求。因此，磁盘调度程序将尝试在其操作中遵循 SJF（最短任务优先）的原则（principle of 

  SJF，shortest job first）。

  SSTF：最短寻道时间优先  SSTF 按磁道对 I/O 请求队列排序，选择在最近磁道上的请求先完成。 

  SSTF 不是万能的，原因如下。第

  一个问题，主机操作系统无法利用驱动器的几何结构，而

  是只会看到一系列的块。幸运的是，这个问题很容易解决。

  操作系统可以简单地实现最近块优先（Nearest-Block-First，NBF），而不是 SSTF，然后用最

  近的块地址来调度请求。

  第二个问题更为根本：饥饿（starvation）。想象一下，在我们上面的例子中，是否有对

  磁头当前所在位置的内圈磁道有稳定的请求。然后，纯粹的 SSTF 方法将完全忽略对其他磁

  道的请求。

  电梯（又称 SCAN 或 C-SCAN）  

  如何实现类 SSTF 调度，但避免饥饿？这个问题的答案是很久以前得到的，并且相对比较简单。该

  算法最初称为 SCAN，简单地以跨越磁道的顺序来服务磁盘请求。我们将一次跨越磁盘称为

  扫一遍。因此，如果请求的块所属的磁道在这次扫一遍中已经服务过了，它就不会立即处

  理，而是排队等待下次扫一遍。

  SCAN 有许多变种，所有这些变种都是一样的。例如，Coffman 等人引入了 F-SCAN，

  它在扫一遍时冻结队列以进行维护[CKR72]。这个操作会将扫一遍期间进入的请求放入队列

  中，以便稍后处理。这样做可以避免远距离请求饥饿，延迟了迟到（但更近）请求的服务。

  C-SCAN 是另一种常见的变体，即循环 SCAN（Circular SCAN）的缩写。不是在一个

  方向扫过磁盘，该算法从外圈扫到内圈，然后从内圈扫到外圈，如此下去。然而，SCAN 及其变种并不是最好的调度技术。特别是，SCAN（甚至 SSTF）实际上

  并没有严格遵守 SJF 的原则。具体来说，它们忽视了旋转。

  SPTF：最短定位时间优先 

* 其他调度问题 

  在这个基本磁盘操作，调度和相关主题的简要描述中，还有很多问题我们没有讨论。

  其中一个问题是：在现代系统上执行磁盘调度的地方在哪里？在较早的系统中，操作系统

  完成了所有的调度。在查看一系列挂起的请求之后，操作系统会选择最好的一个，并将其

  发送到磁盘。当该请求完成时，将选择下一个，如此下去。磁盘当年比较简单，生活也是。

  在现代系统中，磁盘可以接受多个分离的请求，它们本身具有复杂的内部调度程序（它

  们可以准确地实现 SPTF。在磁盘控制器内部，所有相关细节都可以得到，包括精确的磁头

  位置）。因此，操作系统调度程序通常会选择它认为最好的几个请求（如 16），并将它们全

  部发送到磁盘。磁盘然后利用其磁头位置和详细的磁道布局信息等内部知识，以最佳可能

  （SPTF）顺序服务于这些请求。

  磁盘调度程序执行的另一个重要相关任务是 I/O 合并（I/O merging）。调度程序执行的所有请求都基于合并后的请求。合并在操作系统级别尤其重要，因为它减少了发送到磁盘的请求数量，从而降低了开销。

  现代调度程序关注的最后一个问题是：在向磁盘发出 I/O 之前，系统应该等待多久？有

  人可能天真地认为，即使有一个磁盘 I/O，也应立即向驱动器发出请求。这种方法被称为工

  作保全（work-conserving），因为如果有请求就要服务，磁盘将永远不会闲下来。然而，对预

  期磁盘调度的研究表明，有时最好等待一段时间，即所谓的非工作保全

  （non-work-conserving）方法。通过等待，新的和“更好”的请求可能会到达磁盘，从而整

  体效率提高。当然，决定何时等待以及多久可能会非常棘手。

#### 廉价冗余磁盘阵列（Redundant Array of Inexpensive Disks）

* 这种技术使用多个磁盘一起构建更快、更大、更可靠的磁盘系统。从外部看，RAID 看起来像一个磁盘：一组可以读取或写入的块。在内部，RAID 是一

  个复杂的庞然大物，由多个磁盘、内存（包括易失性和非易失性）以及一个或多个处理器

  来管理系统。硬件 RAID 非常像一个计算机系统，专门用于管理一组磁盘。

  与单个磁盘相比，RAID 具有许多优点。一个好处就是性能。并行使用多个磁盘可以大

  大加快 I/O 时间。另一个好处是容量。大型数据集需要大型磁盘。最后，RAID 可以提高可

  靠性。在多个磁盘上传输数据（无 RAID 技术）会使数据容易受到单个磁盘丢失的影响。通

  过某种形式的冗余（redundancy），RAID 可以容许损失一个磁盘并保持运行，就像没有错误

  一样。	

* 透明支持部署

  在考虑如何向系统添加新功能时，应该始终考虑是否可以透明地（transparently）添加这样的功能，

  而不需要对系统其余部分进行更改。要求彻底重写现有软件（或激进的硬件更改）会减少创意产生影响

  的机会。RAID 就是一个很好的例子，它的透明肯定有助于它的成功。RAID 为使用它们的系统透明地（transparently）提供了这些优势，即

  RAID 对于主机系统看起来就像一个大磁盘。当然，透明的好处在于它可以简单地用 RAID

  替换磁盘，而不需要更换一行软件。操作系统和客户端应用程序无须修改，就可以继续运

  行。通过这种方式，透明极大地提高了 RAID 的可部署性（deployability），使用户和管理员

  可以使用 RAID，而不必担心软件兼容性问题。

* 当文件系统向 RAID 发出逻辑 I/O 请求时，RAID 内部必须计算要访问的磁盘（或多个

  磁盘）以完成请求，然后发出一个或多个物理 I/O 来执行此操作。这些物理 I/O 的确切性质

  取决于 RAID 级别，我们将在下面详细讨论。但是，举一个简单的例子，考虑一个 RAID，

  它保留每个块的两个副本（每个都在一个单独的磁盘上）。当写入这种镜像（mirrored）RAID

  系统时，RAID 必须为它发出的每一个逻辑 I/O 执行两个物理 I/O。

  RAID 系统通常构建为单独的硬件盒，并通过标准连接（例如，SCSI 或 SATA）接入主

  机。然而，在内部，RAID 相当复杂。它包括一个微控制器，运行固件以指导 RAID 的操作。

  它还包括 DRAM 这样的易失性存储器，在读取和写入时缓冲数据块。在某些情况下，还包

  括非易失性存储器，安全地缓冲写入。它甚至可能包含专用的逻辑电路，来执行奇偶校验

  计算（在某些 RAID 级别中非常有用，下面会提到）。在很高的层面上，RAID 是一个非常

  专业的计算机系统：它有一个处理器，内存和磁盘。然而，它不是运行应用程序，而是运

  行专门用于操作 RAID 的软件。

  

