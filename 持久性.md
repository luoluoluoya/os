* 

* 标准设备 

  现在来看一个标准设备（不是真实存在的），通过它来帮助我们更好地理解设备交互的

  机制。从图 36.2 中，可以看到一个包含两部

  分重要组件的设备。第一部分是向系统其他部

  分展现的硬件接口（interface）。同软件一样，

  硬件也需要一些接口，让系统软件来控制它的

  操作。因此，所有设备都有自己的特定接口以

  及典型交互的协议。

  第 2 部分是它的内部结构（internal structure）。这部分包含设备相关的特定实现，负责

  具体实现设备展示给系统的抽象接口。非常简单的设备通常用一个或几个芯片来实现它们

  的功能。更复杂的设备会包含简单的 CPU、一些通用内存、设备相关的特定芯片，来完成

  它们的工作。

  [!image](./images/42.png)

* 标准协议 

  一个（简化的）设备接口包含 3 个寄存器：一个状态（status）寄存器，

  可以读取并查看设备的当前状态；一个命令（command）寄存器，用于通知设备执行某个具

  体任务；一个数据（data）寄存器，将数据传给设备或从设备接收数据。通过读写这些寄存

  器，操作系统可以控制设备的行为。

  我们现在来描述操作系统与该设备的典型交互，以便让设备为它做某事。

  While (STATUS == BUSY) 

   ; // wait until device is not busy 

  Write data to DATA register 

  Write command to COMMAND register 

   (Doing so starts the device and executes the command) 

  While (STATUS == BUSY) 

   ; // wait until device is done with your request 

  该协议包含 4 步。第 1 步，操作系统通过反复读取状态寄存器，等待设备进入可以接

  收命令的就绪状态。我们称之为轮询（polling）设备（基本上，就是问它正在做什么）。第

  2 步，操作系统下发数据到数据寄存器。例如，你可以想象如果这是一个磁盘，需要多次写

  入操作，将一个磁盘块（比如 4KB）传递给设备。如果主 CPU 参与数据移动（就像这个示

  例协议一样），我们就称之为编程的 I/O（programmed I/O，PIO）。第 3 步，操作系统将命令

  写入命令寄存器；这样设备就知道数据已经准备好了，它应该开始执行命令。最后一步，

  操作系统再次通过不断轮询设备，等待并判断设备是否执行完成命令（有可能得到一个指

  示成功或失败的错误码）。

  这个简单的协议好处是足够简单并且有效。但是难免会有一些低效和不方便。我们注

  意到这个协议存在的第一个问题就是轮询过程比较低效，在等待设备执行完成命令时浪费

  大量 CPU 时间，如果此时操作系统可以切换执行下一个就绪进程，就可以大大提高 CPU 的

  利用率。

* 利用中断减少 CPU 开销 

  多年前，工程师们发明了我们目前已经很常见的中断（interrupt）来减少 CPU 开销。有

  了中断后，CPU 不再需要不断轮询设备，而是向设备发出一个请求，然后就可以让对应进

  程睡眠，切换执行其他任务。当设备完成了自身操作，会抛出一个硬件中断，引发 CPU 跳

  转执行操作系统预先定义好的中断服务例程（Interrupt Service Routine，ISR），或更为简单

  的中断处理程序（interrupt handler）。中断处理程序是一小段操作系统代码，它会结束之前

  的请求（比如从设备读取到了数据或者错误码）并且唤醒等待 I/O 的进程继续执行。

  因此，中断允许计算与 I/O 重叠（overlap），这是提高 CPU 利用率的关键。

  注意，使用中断并非总是最佳方案。假如有一个非常高性能的设备，它处理请求很快：

  通常在 CPU 第一次轮询时就可以返回结果。此时如果使用中断，反而会使系统变慢：切换到

  其他进程，处理中断，再切换回之前的进程代价不小。因此，如果设备非常快，那么最好的

  办法反而是轮询。如果设备比较慢，那么采用允许发生重叠的中断更好。如果设备的速度未

  知，或者时快时慢，可以考虑使用混合（hybrid）策略，先尝试轮询一小段时间，如果设备没

  有完成操作，此时再使用中断。这种两阶段（two-phased）的办法可以实现两种方法的好处。

  另一个最好不要使用中断的场景是网络。网络端收到大量数据包，如果每一个包都发

  生一次中断，那么有可能导致操作系统发生活锁（livelock），即不断处理中断而无法处理用

  户层的请求。例如，假设一个 Web 服务器因为“点杠效应”而突然承受很重的负载。这种

  情况下，偶尔使用轮询的方式可以更好地控制系统的行为，并允许 Web 服务器先服务一些

  用户请求，再回去检查网卡设备是否有更多数据包到达。

  另一个基于中断的优化就是合并（coalescing）。设备在抛出中断之前往往会等待一小段

  时间，在此期间，其他请求可能很快完成，因此多次中断可以合并为一次中断抛出，从而

  降低处理中断的代价。当然，等待太长会增加请求的延迟，这是系统中常见的折中。

* 中断并非总是比 **PIO** 好

  尽管中断可以做到计算与 I/O 的重叠，但这仅在慢速设备上有意义。否则，额外的中断处理和上下

  文切换的代价反而会超过其收益。另外，如果短时间内出现大量的中断，可能会使得系统过载并且引发

  活锁[MR96]。这种情况下，轮询的方式可以在操作系统自身的调度上提供更多的控制，反而更有效。

* 利用 DMA 进行更高效的数据传送

  DMA 工作过程如下。为了能够将数据传送给设备，操作系统会通过编程告诉 DMA 引

  擎数据在内存的位置，要拷贝的大小以及要拷贝到哪个设备。在此之后，操作系统就可以

  处理其他请求了。当 DMA 的任务完成后，DMA 控制器会抛出一个中断来告诉操作系统自

  己已经完成数据传输。数据的拷贝工作都是由 DMA 控制器来完成的。

* 设备交互的方法 

  现在，我们了解了执行 I/O 涉及的效率问题后，还有其他一些问题需要解决，以便将设

  备合并到系统中。你可能已经注意到了一个问题：我们还没有真正讨论过操作系统究竟如

  何与设备进行通信！所以问题如下。

  随着技术的不断发展，主要有两种方式来实现与设备的交互。第一种办法相对老一些

  （在 IBM 主机中使用了多年），就是用明确的 I/O 指令。这些指令规定了操作系统将数据发

  送到特定设备寄存器的方法，从而允许构造上文提到的协议。

  例如在 x86 上，in 和 out 指令可以用来与设备进行交互。当需要发送数据给设备时，调

  用者指定一个存入数据的特定寄存器及一个代表设备的特定端口。执行这个指令就可以实

  现期望的行为。

  这些指令通常是特权指令（privileged）。操作系统是唯一可以直接与设备交互的实体。

  例如，设想如果任意程序都可以直接读写磁盘：完全混乱（总是会这样），因为任何用户程

  序都可以利用这个漏洞来取得计算机的全部控制权。

  第二种方法是内存映射 I/O（memory- mapped I/O）。通过这种方式，硬件将设备寄存器

  作为内存地址提供。当需要访问设备寄存器时，操作系统装载（读取）或者存入（写入）

  到该内存地址；然后硬件会将装载/存入转移到设备上，而不是物理内存。

  两种方法没有一种具备极大的优势。内存映射 I/O 的好处是不需要引入新指令来实现设

  备交互，但两种方法今天都在使用。

* 纳入操作系统：设备驱动程序 

  每个设备都有非常具体的接口，如何将它们纳入操作系统，而我们希望操作系统尽可能通用。例如文件系统，我们希望开发一个文件系统可以工作在

  SCSI 硬盘、IDE 硬盘、USB 钥匙串设备等设备之上，并且希望这个文件系统不那么清楚对

  这些不同设备发出读写请求的全部细节。

  这个问题可以通过古老的抽象（abstraction）技术来解决。在最底层，操作系统的一部

  分软件清楚地知道设备如何工作，我们将这部分软件称为设备驱动程序（device driver），所

  有设备交互的细节都封装在其中。我们来看看 Linux 文件系统栈，理解抽象技术如何应用于操作系统的设计和实现。图

  36.3 粗略地展示了 Linux 软件的组织方式。可以看出，文件系统（当然也包括在其之上的应

  用程序）完全不清楚它使用的是什么类型的磁盘。它只需要简单地向通用块设备层发送读

  写请求即可，块设备层会将这些请求路由给对应的设备驱动，然后设备驱动来完成真正的

  底层操作。

  [!image](./images/43.png)

  注意，这种封装也有不足的地方。例如，如果有一个设备可以提供很多特殊的功能，

  但为了兼容大多数操作系统它不得不提供一个通用的接口，这样就使得自身的特殊功能无

  法使用。这种情况在使用 SCSI 设备的 Linux 中就发生了。SCSI 设备提供非常丰富的报告错

  误信息，但其他的块设备（比如 ATA/IDE）只提供非常简单的报错处理，这样上层的所有

  软件只能在出错时收到一个通用的 EIO 错误码（一般 IO 错误），SCSI 可能提供的所有附加

  信息都不能报告给文件系统。

#### 磁盘驱动器

* 接口 

  我们先来了解一个现代磁盘驱动器的接口。所有现代驱动器的基本接口都很简单。驱

  动器由大量扇区（512 字节块）组成，每个扇区都可以读取或写入。在具有 *n* 个扇区的磁盘

  上，扇区从 0 到 *n*−1 编号。因此，我们可以将磁盘视为一组扇区，0 到 *n*−1 是驱动器的地址

  空间（address space）。

  多扇区操作是可能的。实际上，许多文件系统一次读取或写入 4KB（或更多）。但是，

  在更新磁盘时，驱动器制造商唯一保证的是单个 512 字节的写入是原子的（atomic，即它将

  完整地完成或者根本不会完成）。因此，如果发生不合时宜的掉电，则只能完成较大写入的

  一部分 [有时称为不完整写入（torn write）]。

  大多数磁盘驱动器的客户端都会做出一些假设，但这些假设并未直接在接口中指定。具体来说，通常可以假

  设访问驱动器地址空间内两个彼此靠近的块将比访问两个相隔很远的块更快。人们通常也

  可以假设访问连续块（即顺序读取或写入）是最快的访问模式，并且通常比任何更随机的

  访问模式快得多。

* 基本几何形状 

  让我们开始了解现代磁盘的一些组件。我们从一个盘片（platter）开始，它是一个圆形

  坚硬的表面，通过引入磁性变化来永久存储数据。磁盘可能有一个或多个盘片。每个盘片

  有两面，每面都称为表面。这些盘片通常由一些硬质材料（如铝）制成，然后涂上薄薄的

  磁性层，即使驱动器断电，驱动器也能持久存储数据位。

  所有盘片都围绕主轴（spindle）连接在一起，主轴连接到一个电机，以一个恒定（固定）

  的速度旋转盘片（当驱动器接通电源时）。旋转速率通常以每分钟转数（Rotations Per Minute，

  RPM）来测量，典型的现代数值在 7200～15000 RPM 范围内。请注意，我们经常会对单次

  旋转的时间感兴趣，例如，以 10000 RPM 旋转的驱动器意味着一次旋转需要大约 6ms。

  数据在扇区的同心圆中的每个表面上被编码。我们称这样的同心圆为一个磁道（track）。

  一个表面包含数以千计的磁道，紧密地排在一起，数百个磁道只有头发的宽度。

  要从表面进行读写操作，我们需要一种机制，使我们能够感应（即读取）磁盘上的磁

  性图案，或者让它们发生变化（即写入）。读写过程由磁头（disk head）完成；驱动器的每

  个表面有一个这样的磁头。磁头连接到单个磁盘臂（disk arm）上，磁盘臂在表面上移动，

  将磁头定位在期望的磁道上。

* 磁头必须等待期望的扇区旋转

  到磁头下。这种等待在现代驱动器中经常发生，并且是 I/O 服务时间的重要组成部分，它有

  一个特殊的名称：旋转延迟

  驱动器必须首先将磁盘臂移动到正确的磁道（在

  这种情况下，是最外面的磁道），通过一个所谓的寻道（seek）过程。寻道，以及旋转，是

  最昂贵的磁盘操作之一。

  I/O 的最后阶段将发生，称为传输（transfer），数据从表面

  读取或写入表面。因此，我们得到了完整的 I/O 时间图：首先寻道，然后等待转动延迟，最

  后传输。

* 一些其他细节 

  扇区往往会偏斜，因为从一个磁道切换到另一个磁道

  时，磁盘需要时间来重新定位磁头（即便移到相邻磁道）。

  如果没有这种偏斜，磁头将移动到下一个磁道，但所需的

  下一个块已经旋转到磁头下，因此驱动器将不得不等待整

  个旋转延迟，才能访问下一个块。

  外圈磁道通常比内圈磁道具有更多扇

  区，这是几何结构的结果。那里空间更多。这些磁道通常

  被称为多区域（multi-zoned）磁盘驱动器，其中磁盘被组

  织成多个区域，区域是表面上连续的一组磁道。每个区域

  每个磁道具有相同的扇区数量，并且外圈区域具有比内圈

  区域更多的扇区。

  最后，任何现代磁盘驱动器都有一个重要组成部分，即它的缓存（cache），由于历史原

  因有时称为磁道缓冲区（track buffer）。该缓存只是少量的内存（通常大约 8MB 或 16MB），

  驱动器可以使用这些内存来保存从磁盘读取或写入磁盘的数据。例如，当从磁盘读取扇区

  时，驱动器可能决定读取该磁道上的所有扇区并将其缓存在其存储器中。这样做可以让驱

  动器快速响应所有后续对同一磁道的请求。

  在写入时，驱动器面临一个选择：它应该在将数据放入其内存之后，还是写入实际写

  入磁盘之后，回报写入完成？前者被称为后写（write back）缓存（有时称为立即报告，immediate 

  reporting），后者则称为直写（write through）。后写缓存有时会使驱动器看起来“更快”，但

  可能有危险。如果文件系统或应用程序要求将数据按特定顺序写入磁盘以保证正确性，后

  写缓存可能会导致问题

* I/O 时间：用数学 

  既然我们有了一个抽象的磁盘模型，就可以通过一些分析来更好地理解磁盘性能。具

  体来说，现在可以将 I/O 时间表示为 3 个主要部分之和：

  *T*I/O = *T* 寻道 + *T* 旋转 + *T* 传输 

  请注意，通常比较驱动器用 I/O 速率（*R*I/O）更容易（如下所示），它很容易从时间计算

  出来。只要将传输的大小除以所花的时间：

  RI/O = 	传输大小/TI/O

  为了更好地感受 I/O 时间，我们执行以下计算。假设有两个我们感兴趣的工作负载。第

  一个工作负载称为随机（random）工作负载，它向磁盘上的随机位置发出小的（例如 4KB）

  读取请求。随机工作负载在许多重要的应用程序中很常见，包括数据库管理系统。第二种

  称为顺序（sequential）工作负载，只是从磁盘连续读取大量的扇区，不会跳过。顺序访问

  模式很常见，因此也很重要。

* 顺序地使用磁盘

  尽可能以顺序方式将数据传输到磁盘，并从磁盘传输数据。如果顺序不可行，至少应考虑以大块传

  输数据：越大越好。如果 I/O 是以小而随机方式完成的，则 I/O 性能将受到显著影响。

* 磁盘调度

  由于 I/O 的高成本，操作系统在决定发送给磁盘的 I/O 顺序方面历来发挥作用。更具体

  地说，给定一组 I/O 请求，磁盘调度程序检查请求并决定下一个要调度的请求。

  与任务调度不同，每个任务的长度通常是不知道的，对于磁盘调度，我们可以很好地

  猜测“任务”（即磁盘请求）需要多长时间。通过估计请求的查找和可能的旋转延迟，磁盘

  调度程序可以知道每个请求将花费多长时间，因此（贪婪地）选择先服务花费最少时间的

  请求。因此，磁盘调度程序将尝试在其操作中遵循 SJF（最短任务优先）的原则（principle of 

  SJF，shortest job first）。

  SSTF：最短寻道时间优先  SSTF 按磁道对 I/O 请求队列排序，选择在最近磁道上的请求先完成。 

  SSTF 不是万能的，原因如下。第

  一个问题，主机操作系统无法利用驱动器的几何结构，而

  是只会看到一系列的块。幸运的是，这个问题很容易解决。

  操作系统可以简单地实现最近块优先（Nearest-Block-First，NBF），而不是 SSTF，然后用最

  近的块地址来调度请求。

  第二个问题更为根本：饥饿（starvation）。想象一下，在我们上面的例子中，是否有对

  磁头当前所在位置的内圈磁道有稳定的请求。然后，纯粹的 SSTF 方法将完全忽略对其他磁

  道的请求。

  电梯（又称 SCAN 或 C-SCAN）  

  如何实现类 SSTF 调度，但避免饥饿？这个问题的答案是很久以前得到的，并且相对比较简单。该

  算法最初称为 SCAN，简单地以跨越磁道的顺序来服务磁盘请求。我们将一次跨越磁盘称为

  扫一遍。因此，如果请求的块所属的磁道在这次扫一遍中已经服务过了，它就不会立即处

  理，而是排队等待下次扫一遍。

  SCAN 有许多变种，所有这些变种都是一样的。例如，Coffman 等人引入了 F-SCAN，

  它在扫一遍时冻结队列以进行维护[CKR72]。这个操作会将扫一遍期间进入的请求放入队列

  中，以便稍后处理。这样做可以避免远距离请求饥饿，延迟了迟到（但更近）请求的服务。

  C-SCAN 是另一种常见的变体，即循环 SCAN（Circular SCAN）的缩写。不是在一个

  方向扫过磁盘，该算法从外圈扫到内圈，然后从内圈扫到外圈，如此下去。然而，SCAN 及其变种并不是最好的调度技术。特别是，SCAN（甚至 SSTF）实际上

  并没有严格遵守 SJF 的原则。具体来说，它们忽视了旋转。

  SPTF：最短定位时间优先 

* 其他调度问题 

  在这个基本磁盘操作，调度和相关主题的简要描述中，还有很多问题我们没有讨论。

  其中一个问题是：在现代系统上执行磁盘调度的地方在哪里？在较早的系统中，操作系统

  完成了所有的调度。在查看一系列挂起的请求之后，操作系统会选择最好的一个，并将其

  发送到磁盘。当该请求完成时，将选择下一个，如此下去。磁盘当年比较简单，生活也是。

  在现代系统中，磁盘可以接受多个分离的请求，它们本身具有复杂的内部调度程序（它

  们可以准确地实现 SPTF。在磁盘控制器内部，所有相关细节都可以得到，包括精确的磁头

  位置）。因此，操作系统调度程序通常会选择它认为最好的几个请求（如 16），并将它们全

  部发送到磁盘。磁盘然后利用其磁头位置和详细的磁道布局信息等内部知识，以最佳可能

  （SPTF）顺序服务于这些请求。

  磁盘调度程序执行的另一个重要相关任务是 I/O 合并（I/O merging）。调度程序执行的所有请求都基于合并后的请求。合并在操作系统级别尤其重要，因为它减少了发送到磁盘的请求数量，从而降低了开销。

  现代调度程序关注的最后一个问题是：在向磁盘发出 I/O 之前，系统应该等待多久？有

  人可能天真地认为，即使有一个磁盘 I/O，也应立即向驱动器发出请求。这种方法被称为工

  作保全（work-conserving），因为如果有请求就要服务，磁盘将永远不会闲下来。然而，对预

  期磁盘调度的研究表明，有时最好等待一段时间，即所谓的非工作保全

  （non-work-conserving）方法。通过等待，新的和“更好”的请求可能会到达磁盘，从而整

  体效率提高。当然，决定何时等待以及多久可能会非常棘手。

#### 廉价冗余磁盘阵列（Redundant Array of Inexpensive Disks）

* 这种技术使用多个磁盘一起构建更快、更大、更可靠的磁盘系统。从外部看，RAID 看起来像一个磁盘：一组可以读取或写入的块。在内部，RAID 是一

  个复杂的庞然大物，由多个磁盘、内存（包括易失性和非易失性）以及一个或多个处理器

  来管理系统。硬件 RAID 非常像一个计算机系统，专门用于管理一组磁盘。

  与单个磁盘相比，RAID 具有许多优点。一个好处就是性能。并行使用多个磁盘可以大

  大加快 I/O 时间。另一个好处是容量。大型数据集需要大型磁盘。最后，RAID 可以提高可

  靠性。在多个磁盘上传输数据（无 RAID 技术）会使数据容易受到单个磁盘丢失的影响。通

  过某种形式的冗余（redundancy），RAID 可以容许损失一个磁盘并保持运行，就像没有错误

  一样。	

* 透明支持部署

  在考虑如何向系统添加新功能时，应该始终考虑是否可以透明地（transparently）添加这样的功能，

  而不需要对系统其余部分进行更改。要求彻底重写现有软件（或激进的硬件更改）会减少创意产生影响

  的机会。RAID 就是一个很好的例子，它的透明肯定有助于它的成功。RAID 为使用它们的系统透明地（transparently）提供了这些优势，即

  RAID 对于主机系统看起来就像一个大磁盘。当然，透明的好处在于它可以简单地用 RAID

  替换磁盘，而不需要更换一行软件。操作系统和客户端应用程序无须修改，就可以继续运

  行。通过这种方式，透明极大地提高了 RAID 的可部署性（deployability），使用户和管理员

  可以使用 RAID，而不必担心软件兼容性问题。

* 当文件系统向 RAID 发出逻辑 I/O 请求时，RAID 内部必须计算要访问的磁盘（或多个

  磁盘）以完成请求，然后发出一个或多个物理 I/O 来执行此操作。这些物理 I/O 的确切性质

  取决于 RAID 级别，我们将在下面详细讨论。但是，举一个简单的例子，考虑一个 RAID，

  它保留每个块的两个副本（每个都在一个单独的磁盘上）。当写入这种镜像（mirrored）RAID

  系统时，RAID 必须为它发出的每一个逻辑 I/O 执行两个物理 I/O。

  RAID 系统通常构建为单独的硬件盒，并通过标准连接（例如，SCSI 或 SATA）接入主

  机。然而，在内部，RAID 相当复杂。它包括一个微控制器，运行固件以指导 RAID 的操作。

  它还包括 DRAM 这样的易失性存储器，在读取和写入时缓冲数据块。在某些情况下，还包

  括非易失性存储器，安全地缓冲写入。它甚至可能包含专用的逻辑电路，来执行奇偶校验

  计算（在某些 RAID 级别中非常有用，下面会提到）。在很高的层面上，RAID 是一个非常

  专业的计算机系统：它有一个处理器，内存和磁盘。然而，它不是运行应用程序，而是运

  行专门用于操作 RAID 的软件。

#### 文文件件和和目目录

* 永久存储设备永久地（或至少长时间地）存储信息，如传统硬盘驱动器（hard disk drive）或

  更现代的固态存储设备（solid-state storage device）。持久存储设备与内存不同。内存在断电

  时，其内容会丢失，而持久存储设备会保持这些数据不变。因此，操作系统必须特别注意

  这样的设备：用户用它们保存真正关心的数据。

* 文件和目录 

  随着时间的推移，存储虚拟化形成了两个关键的抽象。第一个是文件（file）。文件就是

  一个线性字节数组，每个字节都可以读取或写入。每个文件都有某种低级名称（low-level 

  name），通常是某种数字。用户通常不知道这个名字（我们稍后会看到）。由于历史原因，

  文件的低级名称通常称为 inode 号（inode number）。

  在大多数系统中，操作系统不太了解文件的结构（例如，它是图片、文本文件还是 C

  代码）。相反，文件系统的责任仅仅是将这些数据永久存储在磁盘上，并确保当你再次请求

  数据时，得到你原来放在那里的内容。

  第二个抽象是目录（directory）。一个目录，像一个文件一样，也有一个低级名字（即

  inode 号），但是它的内容非常具体：它包含一个（用户可读名字，低级名字）对的列表。例

  如，假设存在一个低级别名称为“10”的文件，它的用户可读的名称为“foo”。“foo”所在

  的目录因此会有条目（“foo”，“10”），将用户可读名称映射到低级名称。目录中的每个条目

  都指向文件或其他目录。通过将目录放入其他目录中，用户可以构建任意的目录树（directory 

  tree，或目录层次结构，directory hierarchy），在该目录树下存储所有文件和目录。

  目录层次结构从根目录（root directory）开始（在基于 UNIX 的系统中，根目录就记为

  “/”），并使用某种分隔符（separator）来命名后续子目录

  （sub-directories），直到命名所需的文件或目录。

  目录和文件可以具有相

  同的名称，只要它们位于文件系统树的不同位置

  名称在系统中很重要，因为访问任何资源的第一步是能够命名它。在 UNIX

  系统中，文件系统提供了一种统一的方式来访问磁盘、U 盘、CD-ROM、许多其他设备上的

  文件，事实上还有很多其他的东西，都位于单一目录树下。

* 文件系统接口

  创建一个文件。这可以通过 open 系统调用完成。open()的一个重要方面是它的返回值：文件描述符（file descriptor）。文件描述符只是一

  个整数，是每个进程私有的，在 UNIX 系统中用于访问文件。因此，一旦文件被打开，你

  就可以使用文件描述符来读取或写入文件，假定你有权这样做。这样，一个文件描述符就

  是一种权限（capability），即一个不透明的句柄，它可以让你执行某些操作。另一种

  看待文件描述符的方法，是将它作为指向文件类型对象的指针。一旦你有这样的对象，就

  可以调用其他“方法”来访问文件，如 read()和 write()。

  strace 的作用就是跟踪程序在运行时所做的每个系统调

  用，然后将跟踪结果显示在屏幕上供你查看。

  调用 **lseek()**不会执行磁盘寻道

  调用 lseek()与移动磁盘臂的磁盘的寻道（seek）操作无关。对 lseek()的调用只

  是改变内核中变量的值。执行 I/O 时，根据磁盘头的位置，磁盘可能会也可能不会执行实际

  的寻道来完成请求。命名糟糕的系统调用 lseek()让很多学生困惑，试图去理解磁盘以及其上的文件系统如何工作。不要混淆二者！lseek()调用只是在 OS 内存中更改一个变量，该变量跟踪特定进程的下一个读取或写入开始

  的偏移量。如果发送到磁盘的读取或写入与最后一次读取或写入不在同一磁道上，就会发生磁盘寻道，

  因此需要磁头移动。更令人困惑的是，调用 lseek()从文件的随机位置读取或写入文件，然后读取/写入这

  些随机位置，确实会导致更多的磁盘寻道。因此，调用 lseek()肯定会导致在即将进行的读取或写入中进

  行搜索，但绝对不会导致任何磁盘 I/O 自动发生。

  大多数情况下，当程序调用 write()时，它只是告诉文件系统：请在将来的某个时刻，将此数据写入持久存储。出于性能的原因，文件系统会将这些写入在内存中缓冲（buffer）一

  段时间（例如 5s 或 30s）。在稍后的时间点，写入将实际发送到存储设备。从调用应用程序

  的角度来看，写入似乎很快完成，并且只有在极少数情况下（例如，在 write()调用之后但写

  入磁盘之前，机器崩溃）数据会丢失。	为了支持这些类型的应用程序，大多数文件系统都提供了一些额外的控制 API。在 UNIX

  中，提供给应用程序的接口被称为 fsync(int fd)。当进程针对特定文件描述符调用 fsync()时，

  文件系统通过强制将所有脏（dirty）数据（即尚未写入的）写入磁盘来响应，针对指定文件

  描述符引用的文件。一旦所有这些写入完成，fsync()例程就会返回。

  rename()调用提供了一个有趣的保证：它（通常）是一个原子（atomic）调用，不论系

  统是否崩溃。如果系统在重命名期间崩溃，文件将被命名为旧名称或新名称，不会出现奇

  怪的中间状态。因此，对于支持某些需要对文件状态进行原子更新的应用程序，rename()非

  常重要。

  文件系统能够保存关于它正在存储的每个文件的大量

  信息。我们通常将这些数据称为文件元数据（metadata）事实表明，每个文件系统通常将这种类型的信息保存在一个名为 inode①的结构中。

  unlink()只需要待删除文件的名称，并在成功时返回零。	

  除了文件外，还可以使用一组与目录相关的系统调用来创建、读取和删除目录。请注

  意，你永远不能直接写入目录。因为目录的格式被视为文件系统元数据，所以你只能间接

  更新目录，例如，通过在其中创建文件、目录或其他对象类型。通过这种方式，文件系统

  可以确保目录的内容始终符合预期。

  要创建目录，可以用系统调用 mkdir()。

  opendir()、readdir()和 closedir()这 3 个调用来读取目录。调用 rmdir()来删除目录

  ink()系统调用有两个参数：一个旧路径名和一个新

  路径名。当你将一个新的文件名“链接”到一个旧的文件名时，你实际上创建了另一种引

  用同一个文件的方法。	link 只是在要创建链接的目录中创建了另一个名称，并将其指向原有文件的相同 inode

  号（即低级别名称）。该文件不以任何方式复制。相反，你现在就有了两个人类可读的名称，都指向同一个文件。通过打印每个文件的 inode 号。创建一个文件时，实际上做了两件事。

  首先，要构建一个结构（inode），它将跟踪几乎所有关于文件的信息，包括其大小、文件块

  在磁盘上的位置等等。其次，将人类可读的名称链接到该文件，并将该链接放入目录中。

  在创建文件的硬链接之后，在文件系统中，原有文件名（file）和新创建的文件名（file2）

  之间没有区别。实际上，它们都只是指向文件底层元数据的链接。当文件系统取消链接文件时，它检查 inode 号中的引用计数（reference 

  count）。该引用计数（有时称为链接计数，link count）允许文件系统跟踪有多少不同的文件

  名已链接到这个 inode。调用 unlink()时，会删除人类可读的名称（正在删除的文件）与给定

  inode 号之间的“链接”，并减少引用计数。只有当引用计数达到零时，文件系统才会释放

  inode 和相关数据块，从而真正“删除”该文件。

  符号链接（symbolic link），有时称为软链接（soft 

  link）。事实表明，硬链接有点局限：你不能创建目录的硬链接（因为担心会在目录树中创

  建一个环）。你不能硬链接到其他磁盘分区中的文件（因为 inode 号在特定文件系统中是唯

  一的，而不是跨文件系统），等等。因此，人们创建了一种称为符号链接的新型链接。符号链接实际上与硬链接完全不同。第一个区别是符号链

  接本身实际上是一个不同类型的文件。我们已经讨论过常规文件和目录。符号链接是文件

  系统知道的第三种类型。由于创建符号链接的方式，有可能造成所谓的悬空引用（dangling reference）。

  如何从许多底层文件系统组建完整的目录树。这项任务的实现是先制作文

  件系统，然后挂载它们，使其内容可以访问。为了创建一个文件系统，大多数文件系统提供了一个工具，通常名为 mkfs（发音为“make 

  fs”），它就是完成这个任务的。思路如下：作为输入，为该工具提供一个设备（例如磁盘分

  区，例如/dev/sda1），一种文件系统类型（例如 ext3），它就在该磁盘分区上写入一个空文件

  系统，从根目录开始。mkfs 说，要有文件系统！ 

  但是，一旦创建了这样的文件系统，就需要在统一的文件系统树中进行访问。这个任

  务是通过 mount 程序实现的（它使底层系统调用 mount()完成实际工作）。mount 的作用很简

  单：以现有目录作为目标挂载点（mount point），本质上是将新的文件系统粘贴到目录树的

  这个点上。

#### 文件件系系统统实实现

* 文件系统是纯软件。与 CPU 和内存虚拟化的开发不同，我们不会添加硬件功能来使文

  件系统的某些方面更好地工作（但我们需要注意设备特性，以确保文件系统运行良好）。

* 第一个方面是文件系统的数据结构（data structure）。换言之，文件系统在磁盘上使用哪

  些类型的结构来组织其数据和元数据？我们即将看到的第一个文件系统（包括下面的

  VSFS）使用简单的结构，如块或其他对象的数组，而更复杂的文件系统（如 SGI 的 XFS）

  使用更复杂的基于树的结构。

  文件系统的第二个方面是访问方法（access method）。如何将进程发出的调用，如 open()、

  read()、write()等，映射到它的结构上？在执行特定系统调用期间读取哪些结构？改写哪些

  结构？所有这些步骤的执行效率如何？

  对于文件系统，你

  的心智模型最终应该包含以下问题的答案：磁盘上的哪些结构存储文件系统的数据和元数据？当一个进

  程打开一个文件时会发生什么？在读取或写入期间访问哪些磁盘结构？

* 整体组织

  我们需要做的第一件

  事是将磁盘分成块（block）。简单的文件系统只使用一种块大小。我们对构建文件系统的磁盘分区的看法很简单：一系列块，每块大小为 4KB。

  在大小为 *N* 个 4KB 块的分区中，这些块的地址为从 0 到 *N*−1。

  将用于存放用户数据的磁盘区域称为数据区域（data region），文件系统必须记录每个文件的信息。该信息是元数据

  （metadata）的关键部分，并且记录诸如文件包含哪些数据块（在数据区域中）、文件的大小，

  其所有者和访问权限、访问和修改时间以及其他类似信息的事情。为了存储这些信息，文

  件系统通常有一个名为 inode 的结构。为了存放 inode，我们还需要在磁盘上留出一些空间。我们将这部分磁盘称为 inode 表 

  （inode table），它只是保存了一个磁盘上 inode 的数组。到目前为止，我们的文件系统有了数据块（D）和 inode（I），但还缺一些东西。你可

  能已经猜到，还需要某种方法来记录 inode 或数据块是空闲还是已分配。因此，这种分配结

  构（allocation structure）是所有文件系统中必需的部分。

  当然，可能有许多分配记录方法。例如，我们可以用一个空闲列表（free list），指向第

  一个空闲块，然后它又指向下一个空闲块，依此类推。我们选择一种简单而流行的结构，

  称为位图（bitmap），一种用于数据区域（数据位图，data bitmap），另一种用于 inode 表（inode

  位图，inode bitmap）。位图是一种简单的结构：每个位用于指示相应的对象/块是空闲（0）

  还是正在使用。

  超级块包含关于该特定文件系统的信息，

  包括例如文件系统中有多少个 inode 和数据块、inode 表的

  开始位置等等。它可能还包括一些幻数，来标识文件系统类型。因此，在挂载文件系统时，操作系统将首先读取超级块，初始化各种参数，然后将该

  卷添加到文件系统树中。当卷中的文件被访问时，系统就会知道在哪里查找所需的磁盘上

  的结构。

* 文件组织：inode 

  文件系统最重要的磁盘结构之一是 inode，几乎所有的文件系统都有类似的结构。名

  称 inode 是 index node（索引节点）的缩写，因为这些节点最初放在一个数组中，在访问特定 inode 时会用到该数

  组的索引。

  每个 inode 都由一个数字（称为 inumber）隐式引用，我们之前称之为文件的低级名称

  （low-level name）。在 VSFS（和其他简单的文件系统）中，给定一个 inumber，你应该能够

  直接计算磁盘上相应节点的位置。

  在每个 inode 中，实际上是所有关于文件的信息：文件类型（例如，常规文件、目录等）、

  大小、分配给它的块数、保护信息（如谁拥有该文件以及谁可以访问它）、一些时间信息（包

  括文件创建、修改或上次访问的时间文件下），以及有关其数据块驻留在磁盘上的位置的信

  息（如某种类型的指针）。我们将所有关于文件的信息称为元数据（metadata）。实际上，文

  件系统中除了纯粹的用户数据外，其他任何信息通常都称为元数据。

  设计 inode 时，最重要的决定之一是它如何引用数据块的位置。一种简单的方法是在

  inode 中有一个或多个直接指针（磁盘地址）。每个指针指向属于该文件的一个磁盘块。这种

  方法有局限：例如，如果你想要一个非常大的文件（例如，大于块的大小乘以直接指针数），

  那就不走运了。

  [!image](./images/44.png)