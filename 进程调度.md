确定工作负载是构建调度策略的关键部分。工作
负载了解得越多，你的策略就越优化。
一个完全可操作的调度准则（a fully-operational scheduling discipline）①。
我们对操作系统中运行的进程（有时也叫工作任务）做出如下的假设：
1．每一个工作运行相同的时间。
2．所有的工作同时到达。
3．一旦开始，每个工作保持运行直到完成。
4．所有的工作只是用 CPU（即它们不执行 IO 操作）。
5．每个工作的运行时间是已知的。
我们说这些假设中许多是不现实的
除了做出工作负载假设之外，还需要一个东西能让我们比较不同的调度策略：调度指
标。指标是我们用来衡量某些东西的东西，在进程调度中，有一些不同的指标是有意义的。
现在，让我们简化一下生活，只用一个指标：周转时间（turnaround time）。任务的周转
时间定义为任务完成时间减去任务到达系统的时间。
你应该注意到，周转时间是一个性能（performance）指标，这将是本章的首要关注点。
另一个有趣的指标是公平（fairness），比如 Jian's Fairness Index。性能和公平在调度系
统中往往是矛盾的。例如，调度程序可以优化性能，但代价是以阻止一些任务运行，这就
降低了公平。
先进先出（FIFO）
我们可以实现的最基本的算法，被称为先进先出（First In First Out 或 FIFO）调度，有
时候也称为先到先服务（First Come First Served 或 FCFS）。
FIFO 有一些积极的特性：它很简单，而且易于实现。而且，对于我们的假设，它的效
果很好。
因此不再认为每个任务的运行时
间相同。FIFO 表现如何？
这个问题通常被称为护航效应（convoy effect），一些耗时较少的潜在资源消费
者被排在重量级的资源消费者之后。这个调度方案可能让你想起在杂货店只有一个排队队
伍的时候，如果看到前面的人装满 3 辆购物车食品并且掏出了支票本，你感觉如何？这会
等很长时间①。
提示：SJF 原则
最短任务优先代表一个总体调度原则，可以应用于所有系统，只要其中平均客户（或在我们案例中
的任务）周转时间很重要。想想你等待的任何队伍：如果有关的机构关心客户满意度，他们可能会考虑
到 SJF。例如，大超市通常都有一个“零散购物”的通道，以确保仅购买几件东西的购物者，不会堵在
为即将到来的冬天而大量购物以做准备的家庭后面。
最短任务优先（SJF） 先运行最短的任务，然后是次短的任务，如此下去。
在考虑平均周转时间的情况下，SJF 调度策略更好。
事实上，考虑到所有工作同时到达的假设，我们可以证明 SJF 确实是一个最优（optimal）
调度算法。但是，你是在上操作系统课，而不是研究理论，所以，这里允许没有证明。
补充：抢占式调度程序
在过去的批处理计算中，开发了一些非抢占式（non-preemptive）调度程序。这样的系统会将每项
工作做完，再考虑是否运行新工作。几乎所有现代化的调度程序都是抢占式的（preemptive），非常愿意
停止一个进程以运行另一个进程。这意味着调度程序采用了我们之前学习的机制。特别是调度程序可以
进行上下文切换，临时停止一个运行进程，并恢复（或启动）另一个进程。
在这里我们可以再次用一个例子来说明问题。现在，假设 A 在 t = 0 时到达，且需要运
行 100s。而 B 和 C 在 t = 10 到达，且各需要运行 10s。用纯 SJF，
最短完成时间优先（STCF）
为了解决这个问题，需要放宽假设条件（工作必须保持运行直到完成）。我们还需要调
度程序本身的一些机制。你可能已经猜到，鉴于我们先前关于时钟中断和上下文切换的讨
论，当 B 和 C 到达时，调度程序当然可以做其他事情：它可以抢占（preempt）工作 A，并
决定运行另一个工作，或许稍后继续工作 A。根据我们的定义，SJF 是一种非抢占式
（non-preemptive）调度程序，因此存在上述问题。
幸运的是，有一个调度程序完全就是这样做的：向 SJF 添加抢占，称为最短完成时间优
先（Shortest Time-to-Completion First，STCF）或抢占式最短作业优先（Preemptive Shortest Job
First ，PSJF）调度程序。每当新工作进入系统时，它就会确定剩余工作和新工作中，
谁的剩余时间最少，然后调度该工作。因此，在我
们的例子中，STCF 将抢占 A 并运行 B 和 C 以完
成。只有在它们完成后，才能调度 A 的剩余时间。
考虑到我们的新假设，STCF 可证明
是最优的。考虑到如果所有工作同时到达，SJF 是
最优的，那么你应该能够看到 STCF 的最优性是符合直觉的。
新度量指标：响应时间
因此，如果我们知道任务长度，而且任务只使用 CPU，而我们唯一的衡量是周转时间，
STCF 将是一个很好的策略。事实上，对于许多早期批处理系统，这些类型的调度算法有一
定的意义。然而，引入分时系统改变了这一切。现在，用户将会坐在终端前面，同时也要
求系统的交互性好。因此，一个新的度量标准诞生了：响应时间（response time）。
响应时间定义为从任务到达系统到首次运行的时间。
你可能会想，STCF 和相关方法在响应时间上并不是很好。例如，如果 3 个工作同时到
达，第三个工作必须等待前两个工作全部运行后才能运行。这种方法虽然有很好的周转时
间，但对于响应时间和交互性是相当糟糕的。假设你在终端前输入，不得不等待 10s 才能看
到系统的回应，只是因为其他一些工作已经在你之前被调度：你肯定不太开心。
因此，我们还有另一个问题：如何构建对响应时间敏感的调度程序？
轮转
为了解决这个问题，我们将介绍一种新的调度算法，通常被称为轮转（Round-Robin，
RR）调度。基本思想很简单：RR 在一个时间片（time slice，有时称为调度量子，scheduling
quantum）内运行一个工作，然后切换到运行队列中的下一个任务，而不是运行一个任务直
到结束。它反复执行，直到所有任务完成。因此，RR 有时被称为时间切片（time-slicing）。
请注意，时间片长度必须是时钟中断周期的倍数。因此，如果时钟中断是每 10ms 中断一次，
则时间片可以是 10ms、20ms 或 10ms 的任何其他倍数。
为了更详细地理解 RR，我们来看一个例子。假设 3 个任务 A、B 和 C 在系统中同时到达，
并且它们都希望运行 5s。SJF 调度程序必须运行完当前任务才可运行下一个任务（见图 7.6）。相
比之下，1s 时间片的 RR 可以快要地循环工作
RR 的平均响应时间是：（0 + 1 + 2）/3 = 1; SJF 算法平均响应时间是：（0 + 5 + 10）/ 3 = 5。
如你所见，时间片长度对于 RR 是至关重要的。越短，RR 在响应时间上表现越好。然
而，时间片太短是有问题的：突然上下文切换的成本将影响整体性能。因此，系统设计者
需要权衡时间片的长度，使其足够长，以便摊销（amortize）上下文切换成本，而又不会使
系统不及时响应。
摊销可以减少成本
当系统某些操作有固定成本时，通常会使用摊销技术（amortization）。通过减少成本的频度（即执
行较少次的操作），系统的总成本就会降低。例如，如果时间片设置为 10ms，并且上下文切换时间为 1ms，
那么浪费大约 10%的时间用于上下文切换。如果要摊销这个成本，可以把时间片增加到 100ms。在这种
情况下，不到 1%的时间用于上下文切换，因此时间片带来的成本就被摊销了。
请注意，上下文切换的成本不仅仅来自保存和恢复少量寄存器的操作系统操作。程序
运行时，它们在 CPU 高要缓存、TLB、分支预测器和其他片上硬件中建立了大量的状态。
切换到另一个工作会导致此状态被刷新，且与当前运行的作业相关的新状态被引入，这可
能导致显著的性能成本。
如果响应时间是我们的唯一指标，那么带有合理时间片的 RR，就会是非常好的调度程
序。但是我们老朋友的周转时间呢？再来看看我们的例子。A、B 和 C，每个运行时间为 5s，
同时到达，RR 是具有（长）1s 时间片的调度程序。从图 7.7 可以看出，A 在 13 完成，B 在
14，C 在 15，平均 14。相当可怕！
这并不奇怪，如果周转时间是我们的指标，那么 RR 确实是最糟糕的策略之一。直观地
说，这应该是有意义的：RR 所做的正是延伸每个工作，只运行每个工作一小段时间，就转
向下一个工作。因为周转时间只关心作业何时完成，RR 几乎是最差的，在很多情况下甚至
比简单的 FIFO 更差。
更一般地说，任何公平（fair）的政策（如 RR），即在小规模的时间内将 CPU 均匀分配
到活动进程之间，在周转时间这类指标上表现不佳。事实上，这是固有的权衡：如果你愿
意不公平，你可以运行较短的工作直到完成，但是要以响应时间为代价。如果你重视公平
性，则响应时间会较短，但会以周转时间为代价。这种权衡在系统中很常见。你不能既拥
有你的蛋糕，又吃它。
我们开发了两种调度程序。第一种类型（SJF、STCF）优化周转时间，但对响应时间不
利。第二种类型（RR）优化响应时间，但对周转时间不利。我们还有两个假设需要放宽：
假设 4（作业没有 I/O）和假设 5（每个作业的运行时间是已知的）。
结合 I/O
首先，我们将放宽假设 4：当然所有程序都执行 I/O。想象一下没有任何输入的程序：
每次都会产生相同的输出。设想一个没有输出的程序：它就像谚语所说的森林里倒下的树，
没有人看到它。它的运行并不重要。
调度程序显然要在工作发起 I/O 请求时做出决定，因为当前正在运行的作业在 I/O 期间
不会使用 CPU，它被阻塞等待 I/O 完成。如果将 I/O 发送到硬盘驱动器，则进程可能会被阻
塞几毫秒或更长时间，具体取决于驱动器当前的 I/O 负载。因此，这时调度程序应该在 CPU
上安排另一项工作。
调度程序还必须在 I/O 完成时做出决定。发生这种情况时，会产生中断，操作系统运行
并将发出 I/O 的进程从阻塞状态移回就绪状态。当然，它甚至可以决定在那个时候运行该项
工作。操作系统应该如何处理每项工作？
为了更好地理解这个问题，让我们假设有两项工作 A 和 B，每项工作需要 50ms 的 CPU
时间。但是，有一个明显的区别：A 运行 10ms，然后发出 I/O 请求（假设 I/O 每个都需要
10ms），而 B 只是使用 CPU 50ms，不执行 I/O。调度程序先运行 A，然后运行 B（见图 7.8）。
假设我们正在尝试构建 STCF 调度程序。这样的调度程序应该如何考虑到这样的事实，
即 A 分解成 5 个 10ms 子工作，而 B 仅仅是单个 50ms CPU 需求？显然，仅仅运行一个工作，
然后运行另一个工作，而不考虑如何考虑 I/O 是没有意义的。
一种常见的方法是将 A 的每个 10ms 的子工作视为一项独立的工作。因此，当系统启动
时，它的选择是调度 10ms 的 A，还是 50ms 的 B。对于 STCF，选择是明确的：选择较短的
一个，在这种情况下是 A。然后，A 的工作已完成，只剩下 B，并开始运行。然后提交 A
的一个新子工作，它抢占 B 并运行 10ms。这样做可以实现重叠（overlap），一个进程在等
待另一个进程的 I/O 完成时使用 CPU，系统因此得到更好的利用
当这些交互式作业正在执行 I/O 时，其他 CPU 密
集型作业将运行，从而更好地利用处理器。
无法预知
有了应对 I/O 的基本方法，我们来到最后的假设：调度程序知道每个工作的长度。如前
所述，这可能是可以做出的最糟糕的假设。事实上，在一个通用的操作系统中（比如我们
所关心的操作系统），操作系统通常对每个作业的长度知之甚少。因此，我们如何建立一个
没有这种先验知识的 SJF/STCF？更进一步，我们如何能够将已经看到的一些想法与 RR 调
度程序结合起来，以便响应时间也变得相当不没？
我们介绍了调度的基本思想，并开发了两类方法。第一类是运行最短的工作，从而优
化周转时间。第二类是交替运行所有工作，从而优化响应时间。但很难做到“鱼与熊掌兼
得”，这是系统中常见的、固有的折中。我们也看到了如何将 I/O 结合到场景中，但仍未解
决操作系统根本无法看到未来的问题。稍后，我们将看到如何通过构建一个调度程序，利
用最近的历史预测未来，从而解决这个问题。这个调度程序称为多级反馈队列，
多级反馈队列需要解决两方面的问题。首先，它要优化周转时间。在第 7 章中我们看
到，这通过先执行短工作来实现。然而，操作系统通常不知道工作要运行多久，而这又是
SJF（或 STCF）等算法所必需的。其次，MLFQ 希望给交互用户（如用户坐在屏幕前，等
着进程结束）很好的交互体验，因此需要降低响应时间。然而，像轮转这样的算法虽然降
低了响应时间，周转时间却很差。所以这里的问题是：通常我们对进程一无所知，应该如
何构建调度程序来实现这些目标？调度程序如何在运行过程中学习进程的特征，从而做出
更好的调度决策？
关键问题：没有完备的知识如何调度？
没有工作长度的先验（priori）知识，如何设计一个能同时减少响应时间和周转时间的调度程序？
提示：从历史中学习
多级反馈队列是用历史经验预测未来的一个典型的例子，操作系统中有很多地方采用了这种技术
（同样存在于计算机科学领域的很多其他地方，比如硬件的分支预测及缓存算法）。如果工作有明显的阶
段性行为，因此可以预测，那么这种方式会很有效。当然，必须十分小心地使用这种技术，因为它可能
出错，让系统做出比一无所知的时候更糟的决定。
MLFQ：基本规则
为了构建这样的调度程序，本章将介绍多级消息队列背后的基本算法。虽然它有许多
不同的实现，但大多数方法是类似的。
MLFQ 中有许多独立的队列（queue），每个队列有不同的优先级（priority level）。任何
时刻，一个工作只能存在于一个队列中。MLFQ 总是优先执行较高优先级的工作（即在较
高级队列中的工作）。
当然，每个队列中可能会有多个工作，因此具有同样的优先级。在这种情况下，我们
就对这些工作采用轮转调度。
因此，MLFQ 调度策略的关键在于如何设置优先级。MLFQ 没有为每个工作指定不变
的优先情绪而已，而是根据观察到的行为调整它的优先级。例如，如果一个工作不断放弃
CPU 去等待键盘输入，这是交互型进程的可能行为，MLFQ 因此会让它保持高优先级。相
反，如果一个工作长时间地占用 CPU，MLFQ 会降低其优先级。通过这种方式，MLFQ 在
进程运行过程中学习其行为，从而利用工作的历史来预测它未来的行为。
至此，我们得到了 MLFQ 的两条基本规则。
 规则 1：如果 A 的优先级 > B 的优先级，运行 A（不运行 B）。
 规则 2：如果 A 的优先级 = B 的优先级，轮转运行
A 和 B。
尝试 1：如何改变优先级
我们必须决定，在一个工作的生命周期中，MLFQ 如何改变其优先级（在哪个队列中）。
要做到这一点，我们必须记得工作负载：既有运行时间很短、频繁放弃 CPU 的交互型工作，
也有需要很多 CPU 时间、响应时间却不重要的长时间计算密集型工作。下面是我们第一次
尝试优先级调整算法。
 规则 3：工作进入系统时，放在最高优先级（最上层队列）。
 规则 4a：工作用完整个时间片后，降低其优先级（移入下一个队列）。
 规则 4b：如果工作在其时间片以内主动释放 CPU，
则优先级不变。
这个算法的一个主要目标：如果不知道工作是短工
作还是长工作，那么就在开始的时候假设其是短工作，并赋予最高优先级。如果确实是短
工作，则很快会执行完毕，否则将被慢慢移入低优先级队列，而这时该工作也被认为是长
工作了。通过这种方式，MLFQ 近似于 SJF。
如果有 I/O 呢
看一个有 I/O 的例子。根据上述规则 4b，如果进程在时间片用完之前主动放弃 CPU，
则保持它的优先级不变。这条规则的意图很简单：假设交互型工作中有大量的 I/O 操作（比
如等待用户的键盘或鼠标输入），它会在时间片用完之前放弃 CPU。在这种情况下，我们不
想处罚它，只是保持它的优先级不变。
交互型工作 B（用灰色表示）每执行 1ms 便需要进行 I/O
操作，它与长时间运行的工作 A（用黑色表示）竞争 CPU。MLFQ 算法保持 B 在最高优先
级，因为 B 总是让出 CPU。如果 B 是交互型工作，MLFQ 就进一步实现了它的目标，让交
互型工作快速运行。
当前 MLFQ 的一些问题
至此，我们有了基本的 MLFQ。它看起来似乎相当不错，长工作之间可以公平地分享
CPU，又能给短工作或交互型工作很好的响应时间。然而，这种算法有一些非常严重的缺点。
首先，会有饥饿（starvation）问题。如果系统有“太多”交互型工作，就会不断占用
CPU，导致长工作永远无法得到 CPU（它们饿死了）。即使在这种情况下，我们希望这些长
工作也能有所进展。
其次，聪明的用户会重写程序，愚弄调度程序（game the scheduler）。愚弄调度程序指
的是用一些卑鄙的手段欺骗调度程序，让它给你远超公平的资源。上述算法对如下的攻击
束手无策：进程在时间片用完之前，调用一个 I/O 操作（比如访问一个无关的文件），从而
主动释放 CPU。如此便可以保持在高优先级，占用更多的 CPU 时间。做得好时（比如，每
运行 99%的时间片时间就主动放弃一次 CPU），工作可以几乎独占 CPU。
最后，一个程序可能在不同时间表现不同。一个计算密集的进程可能在某段时间表现为
一个交互型的进程。用我们目前的方法，它不会享受系统中其他交互型工作的待遇。