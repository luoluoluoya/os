确定工作负载是构建调度策略的关键部分。工作
负载了解得越多，你的策略就越优化。
一个完全可操作的调度准则（a fully-operational scheduling discipline）①。
我们对操作系统中运行的进程（有时也叫工作任务）做出如下的假设：
1．每一个工作运行相同的时间。
2．所有的工作同时到达。
3．一旦开始，每个工作保持运行直到完成。
4．所有的工作只是用 CPU（即它们不执行 IO 操作）。
5．每个工作的运行时间是已知的。
我们说这些假设中许多是不现实的
除了做出工作负载假设之外，还需要一个东西能让我们比较不同的调度策略：调度指
标。指标是我们用来衡量某些东西的东西，在进程调度中，有一些不同的指标是有意义的。
现在，让我们简化一下生活，只用一个指标：周转时间（turnaround time）。任务的周转
时间定义为任务完成时间减去任务到达系统的时间。
你应该注意到，周转时间是一个性能（performance）指标，这将是本章的首要关注点。
另一个有趣的指标是公平（fairness），比如 Jian's Fairness Index。性能和公平在调度系
统中往往是矛盾的。例如，调度程序可以优化性能，但代价是以阻止一些任务运行，这就
降低了公平。
先进先出（FIFO）
我们可以实现的最基本的算法，被称为先进先出（First In First Out 或 FIFO）调度，有
时候也称为先到先服务（First Come First Served 或 FCFS）。
FIFO 有一些积极的特性：它很简单，而且易于实现。而且，对于我们的假设，它的效
果很好。
因此不再认为每个任务的运行时
间相同。FIFO 表现如何？
这个问题通常被称为护航效应（convoy effect），一些耗时较少的潜在资源消费
者被排在重量级的资源消费者之后。这个调度方案可能让你想起在杂货店只有一个排队队
伍的时候，如果看到前面的人装满 3 辆购物车食品并且掏出了支票本，你感觉如何？这会
等很长时间①。
提示：SJF 原则
最短任务优先代表一个总体调度原则，可以应用于所有系统，只要其中平均客户（或在我们案例中
的任务）周转时间很重要。想想你等待的任何队伍：如果有关的机构关心客户满意度，他们可能会考虑
到 SJF。例如，大超市通常都有一个“零散购物”的通道，以确保仅购买几件东西的购物者，不会堵在
为即将到来的冬天而大量购物以做准备的家庭后面。
最短任务优先（SJF） 先运行最短的任务，然后是次短的任务，如此下去。
在考虑平均周转时间的情况下，SJF 调度策略更好。
事实上，考虑到所有工作同时到达的假设，我们可以证明 SJF 确实是一个最优（optimal）
调度算法。但是，你是在上操作系统课，而不是研究理论，所以，这里允许没有证明。
补充：抢占式调度程序
在过去的批处理计算中，开发了一些非抢占式（non-preemptive）调度程序。这样的系统会将每项
工作做完，再考虑是否运行新工作。几乎所有现代化的调度程序都是抢占式的（preemptive），非常愿意
停止一个进程以运行另一个进程。这意味着调度程序采用了我们之前学习的机制。特别是调度程序可以
进行上下文切换，临时停止一个运行进程，并恢复（或启动）另一个进程。
在这里我们可以再次用一个例子来说明问题。现在，假设 A 在 t = 0 时到达，且需要运
行 100s。而 B 和 C 在 t = 10 到达，且各需要运行 10s。用纯 SJF，
最短完成时间优先（STCF）
为了解决这个问题，需要放宽假设条件（工作必须保持运行直到完成）。我们还需要调
度程序本身的一些机制。你可能已经猜到，鉴于我们先前关于时钟中断和上下文切换的讨
论，当 B 和 C 到达时，调度程序当然可以做其他事情：它可以抢占（preempt）工作 A，并
决定运行另一个工作，或许稍后继续工作 A。根据我们的定义，SJF 是一种非抢占式
（non-preemptive）调度程序，因此存在上述问题。
幸运的是，有一个调度程序完全就是这样做的：向 SJF 添加抢占，称为最短完成时间优
先（Shortest Time-to-Completion First，STCF）或抢占式最短作业优先（Preemptive Shortest Job
First ，PSJF）调度程序。每当新工作进入系统时，它就会确定剩余工作和新工作中，
谁的剩余时间最少，然后调度该工作。因此，在我
们的例子中，STCF 将抢占 A 并运行 B 和 C 以完
成。只有在它们完成后，才能调度 A 的剩余时间。
考虑到我们的新假设，STCF 可证明
是最优的。考虑到如果所有工作同时到达，SJF 是
最优的，那么你应该能够看到 STCF 的最优性是符合直觉的。
新度量指标：响应时间
因此，如果我们知道任务长度，而且任务只使用 CPU，而我们唯一的衡量是周转时间，
STCF 将是一个很好的策略。事实上，对于许多早期批处理系统，这些类型的调度算法有一
定的意义。然而，引入分时系统改变了这一切。现在，用户将会坐在终端前面，同时也要
求系统的交互性好。因此，一个新的度量标准诞生了：响应时间（response time）。
响应时间定义为从任务到达系统到首次运行的时间。
你可能会想，STCF 和相关方法在响应时间上并不是很好。例如，如果 3 个工作同时到
达，第三个工作必须等待前两个工作全部运行后才能运行。这种方法虽然有很好的周转时
间，但对于响应时间和交互性是相当糟糕的。假设你在终端前输入，不得不等待 10s 才能看
到系统的回应，只是因为其他一些工作已经在你之前被调度：你肯定不太开心。
因此，我们还有另一个问题：如何构建对响应时间敏感的调度程序？
轮转
为了解决这个问题，我们将介绍一种新的调度算法，通常被称为轮转（Round-Robin，
RR）调度。基本思想很简单：RR 在一个时间片（time slice，有时称为调度量子，scheduling
quantum）内运行一个工作，然后切换到运行队列中的下一个任务，而不是运行一个任务直
到结束。它反复执行，直到所有任务完成。因此，RR 有时被称为时间切片（time-slicing）。
请注意，时间片长度必须是时钟中断周期的倍数。因此，如果时钟中断是每 10ms 中断一次，
则时间片可以是 10ms、20ms 或 10ms 的任何其他倍数。
为了更详细地理解 RR，我们来看一个例子。假设 3 个任务 A、B 和 C 在系统中同时到达，
并且它们都希望运行 5s。SJF 调度程序必须运行完当前任务才可运行下一个任务（见图 7.6）。相
比之下，1s 时间片的 RR 可以快要地循环工作
RR 的平均响应时间是：（0 + 1 + 2）/3 = 1; SJF 算法平均响应时间是：（0 + 5 + 10）/ 3 = 5。
如你所见，时间片长度对于 RR 是至关重要的。越短，RR 在响应时间上表现越好。然
而，时间片太短是有问题的：突然上下文切换的成本将影响整体性能。因此，系统设计者
需要权衡时间片的长度，使其足够长，以便摊销（amortize）上下文切换成本，而又不会使
系统不及时响应。
摊销可以减少成本
当系统某些操作有固定成本时，通常会使用摊销技术（amortization）。通过减少成本的频度（即执
行较少次的操作），系统的总成本就会降低。例如，如果时间片设置为 10ms，并且上下文切换时间为 1ms，
那么浪费大约 10%的时间用于上下文切换。如果要摊销这个成本，可以把时间片增加到 100ms。在这种
情况下，不到 1%的时间用于上下文切换，因此时间片带来的成本就被摊销了。
请注意，上下文切换的成本不仅仅来自保存和恢复少量寄存器的操作系统操作。程序
运行时，它们在 CPU 高要缓存、TLB、分支预测器和其他片上硬件中建立了大量的状态。
切换到另一个工作会导致此状态被刷新，且与当前运行的作业相关的新状态被引入，这可
能导致显著的性能成本。
如果响应时间是我们的唯一指标，那么带有合理时间片的 RR，就会是非常好的调度程
序。但是我们老朋友的周转时间呢？再来看看我们的例子。A、B 和 C，每个运行时间为 5s，
同时到达，RR 是具有（长）1s 时间片的调度程序。从图 7.7 可以看出，A 在 13 完成，B 在
14，C 在 15，平均 14。相当可怕！
这并不奇怪，如果周转时间是我们的指标，那么 RR 确实是最糟糕的策略之一。直观地
说，这应该是有意义的：RR 所做的正是延伸每个工作，只运行每个工作一小段时间，就转
向下一个工作。因为周转时间只关心作业何时完成，RR 几乎是最差的，在很多情况下甚至
比简单的 FIFO 更差。
更一般地说，任何公平（fair）的政策（如 RR），即在小规模的时间内将 CPU 均匀分配
到活动进程之间，在周转时间这类指标上表现不佳。事实上，这是固有的权衡：如果你愿
意不公平，你可以运行较短的工作直到完成，但是要以响应时间为代价。如果你重视公平
性，则响应时间会较短，但会以周转时间为代价。这种权衡在系统中很常见。你不能既拥
有你的蛋糕，又吃它。
我们开发了两种调度程序。第一种类型（SJF、STCF）优化周转时间，但对响应时间不
利。第二种类型（RR）优化响应时间，但对周转时间不利。我们还有两个假设需要放宽：
假设 4（作业没有 I/O）和假设 5（每个作业的运行时间是已知的）。
结合 I/O
首先，我们将放宽假设 4：当然所有程序都执行 I/O。想象一下没有任何输入的程序：
每次都会产生相同的输出。设想一个没有输出的程序：它就像谚语所说的森林里倒下的树，
没有人看到它。它的运行并不重要。
调度程序显然要在工作发起 I/O 请求时做出决定，因为当前正在运行的作业在 I/O 期间
不会使用 CPU，它被阻塞等待 I/O 完成。如果将 I/O 发送到硬盘驱动器，则进程可能会被阻
塞几毫秒或更长时间，具体取决于驱动器当前的 I/O 负载。因此，这时调度程序应该在 CPU
上安排另一项工作。
调度程序还必须在 I/O 完成时做出决定。发生这种情况时，会产生中断，操作系统运行
并将发出 I/O 的进程从阻塞状态移回就绪状态。当然，它甚至可以决定在那个时候运行该项
工作。操作系统应该如何处理每项工作？
为了更好地理解这个问题，让我们假设有两项工作 A 和 B，每项工作需要 50ms 的 CPU
时间。但是，有一个明显的区别：A 运行 10ms，然后发出 I/O 请求（假设 I/O 每个都需要
10ms），而 B 只是使用 CPU 50ms，不执行 I/O。调度程序先运行 A，然后运行 B（见图 7.8）。
假设我们正在尝试构建 STCF 调度程序。这样的调度程序应该如何考虑到这样的事实，
即 A 分解成 5 个 10ms 子工作，而 B 仅仅是单个 50ms CPU 需求？显然，仅仅运行一个工作，
然后运行另一个工作，而不考虑如何考虑 I/O 是没有意义的。
一种常见的方法是将 A 的每个 10ms 的子工作视为一项独立的工作。因此，当系统启动
时，它的选择是调度 10ms 的 A，还是 50ms 的 B。对于 STCF，选择是明确的：选择较短的
一个，在这种情况下是 A。然后，A 的工作已完成，只剩下 B，并开始运行。然后提交 A
的一个新子工作，它抢占 B 并运行 10ms。这样做可以实现重叠（overlap），一个进程在等
待另一个进程的 I/O 完成时使用 CPU，系统因此得到更好的利用
当这些交互式作业正在执行 I/O 时，其他 CPU 密
集型作业将运行，从而更好地利用处理器。
无法预知
有了应对 I/O 的基本方法，我们来到最后的假设：调度程序知道每个工作的长度。如前
所述，这可能是可以做出的最糟糕的假设。事实上，在一个通用的操作系统中（比如我们
所关心的操作系统），操作系统通常对每个作业的长度知之甚少。因此，我们如何建立一个
没有这种先验知识的 SJF/STCF？更进一步，我们如何能够将已经看到的一些想法与 RR 调
度程序结合起来，以便响应时间也变得相当不没？
我们介绍了调度的基本思想，并开发了两类方法。第一类是运行最短的工作，从而优
化周转时间。第二类是交替运行所有工作，从而优化响应时间。但很难做到“鱼与熊掌兼
得”，这是系统中常见的、固有的折中。我们也看到了如何将 I/O 结合到场景中，但仍未解
决操作系统根本无法看到未来的问题。稍后，我们将看到如何通过构建一个调度程序，利
用最近的历史预测未来，从而解决这个问题。这个调度程序称为多级反馈队列，
多级反馈队列需要解决两方面的问题。首先，它要优化周转时间。在第 7 章中我们看
到，这通过先执行短工作来实现。然而，操作系统通常不知道工作要运行多久，而这又是
SJF（或 STCF）等算法所必需的。其次，MLFQ 希望给交互用户（如用户坐在屏幕前，等
着进程结束）很好的交互体验，因此需要降低响应时间。然而，像轮转这样的算法虽然降
低了响应时间，周转时间却很差。所以这里的问题是：通常我们对进程一无所知，应该如
何构建调度程序来实现这些目标？调度程序如何在运行过程中学习进程的特征，从而做出
更好的调度决策？
关键问题：没有完备的知识如何调度？
没有工作长度的先验（priori）知识，如何设计一个能同时减少响应时间和周转时间的调度程序？
提示：从历史中学习
多级反馈队列是用历史经验预测未来的一个典型的例子，操作系统中有很多地方采用了这种技术
（同样存在于计算机科学领域的很多其他地方，比如硬件的分支预测及缓存算法）。如果工作有明显的阶
段性行为，因此可以预测，那么这种方式会很有效。当然，必须十分小心地使用这种技术，因为它可能
出错，让系统做出比一无所知的时候更糟的决定。
MLFQ：基本规则
为了构建这样的调度程序，本章将介绍多级消息队列背后的基本算法。虽然它有许多
不同的实现，但大多数方法是类似的。
MLFQ 中有许多独立的队列（queue），每个队列有不同的优先级（priority level）。任何
时刻，一个工作只能存在于一个队列中。MLFQ 总是优先执行较高优先级的工作（即在较
高级队列中的工作）。
当然，每个队列中可能会有多个工作，因此具有同样的优先级。在这种情况下，我们
就对这些工作采用轮转调度。
因此，MLFQ 调度策略的关键在于如何设置优先级。MLFQ 没有为每个工作指定不变
的优先情绪而已，而是根据观察到的行为调整它的优先级。例如，如果一个工作不断放弃
CPU 去等待键盘输入，这是交互型进程的可能行为，MLFQ 因此会让它保持高优先级。相
反，如果一个工作长时间地占用 CPU，MLFQ 会降低其优先级。通过这种方式，MLFQ 在
进程运行过程中学习其行为，从而利用工作的历史来预测它未来的行为。
至此，我们得到了 MLFQ 的两条基本规则。
 规则 1：如果 A 的优先级 > B 的优先级，运行 A（不运行 B）。
 规则 2：如果 A 的优先级 = B 的优先级，轮转运行
A 和 B。
尝试 1：如何改变优先级
我们必须决定，在一个工作的生命周期中，MLFQ 如何改变其优先级（在哪个队列中）。
要做到这一点，我们必须记得工作负载：既有运行时间很短、频繁放弃 CPU 的交互型工作，
也有需要很多 CPU 时间、响应时间却不重要的长时间计算密集型工作。下面是我们第一次
尝试优先级调整算法。
 规则 3：工作进入系统时，放在最高优先级（最上层队列）。
 规则 4a：工作用完整个时间片后，降低其优先级（移入下一个队列）。
 规则 4b：如果工作在其时间片以内主动释放 CPU，
则优先级不变。
这个算法的一个主要目标：如果不知道工作是短工
作还是长工作，那么就在开始的时候假设其是短工作，并赋予最高优先级。如果确实是短
工作，则很快会执行完毕，否则将被慢慢移入低优先级队列，而这时该工作也被认为是长
工作了。通过这种方式，MLFQ 近似于 SJF。
如果有 I/O 呢
看一个有 I/O 的例子。根据上述规则 4b，如果进程在时间片用完之前主动放弃 CPU，
则保持它的优先级不变。这条规则的意图很简单：假设交互型工作中有大量的 I/O 操作（比
如等待用户的键盘或鼠标输入），它会在时间片用完之前放弃 CPU。在这种情况下，我们不
想处罚它，只是保持它的优先级不变。
交互型工作 B（用灰色表示）每执行 1ms 便需要进行 I/O
操作，它与长时间运行的工作 A（用黑色表示）竞争 CPU。MLFQ 算法保持 B 在最高优先
级，因为 B 总是让出 CPU。如果 B 是交互型工作，MLFQ 就进一步实现了它的目标，让交
互型工作快速运行。
当前 MLFQ 的一些问题
至此，我们有了基本的 MLFQ。它看起来似乎相当不错，长工作之间可以公平地分享
CPU，又能给短工作或交互型工作很好的响应时间。然而，这种算法有一些非常严重的缺点。
首先，会有饥饿（starvation）问题。如果系统有“太多”交互型工作，就会不断占用
CPU，导致长工作永远无法得到 CPU（它们饿死了）。即使在这种情况下，我们希望这些长
工作也能有所进展。
其次，聪明的用户会重写程序，愚弄调度程序（game the scheduler）。愚弄调度程序指
的是用一些卑鄙的手段欺骗调度程序，让它给你远超公平的资源。上述算法对如下的攻击
束手无策：进程在时间片用完之前，调用一个 I/O 操作（比如访问一个无关的文件），从而
主动释放 CPU。如此便可以保持在高优先级，占用更多的 CPU 时间。做得好时（比如，每
运行 99%的时间片时间就主动放弃一次 CPU），工作可以几乎独占 CPU。
最后，一个程序可能在不同时间表现不同。一个计算密集的进程可能在某段时间表现为
一个交互型的进程。用我们目前的方法，它不会享受系统中其他交互型工作的待遇。

尝试 2：提升优先级 

让我们试着改变之前的规则，看能否避免饥饿问题。要让 CPU 密集型工作也能取得一

些进展（即使不多），我们能做些什么？

一个简单的思路是周期性地提升（boost）所有工作的优先级。可以有很多方法做到，

但我们就用最简单的：将所有工作扔到最高优先级队列。于是有了如下的新规则。

 规则 **5**：经过一段时间 *S*，就将系统中所有工作重新加入最高优先级队列。

新规则一下解决了两个问题。首先，进程不会饿死——在最高优先级队列中，它会以轮

转的方式，与其他高优先级工作分享 CPU，从而最终获得执行。其次，如果一个 CPU 密集

型工作变成了交互型，当它优先级提升时，调度程序会正确对待它。

当然，添加时间段 *S* 导致了明显的问题：*S* 的值应该如何设置？德高望重的系统研究员8.5 MLFQ 调优及其他问题 

John Ousterhout[O11]曾将这种值称为“巫毒常量（voo-doo constant）”，因为似乎需要一些黑

魔法才能正确设置。如果 *S* 设置得太高，长工作会饥饿；如果设置得太低，交互型工作又

得不到合适的 CPU 时间比例。

8.4 尝试 3：更好的计时方式 

现在还有一个问题要解决：如何阻止调度程序被愚弄？可以看出，这里的元凶是规则

4a 和 4b，导致工作在时间片以内释放 CPU，就保留它的优先级。那么应该怎么做？

这里的解决方案，是为 MLFQ 的每层队列提供更完善的 CPU 计时方式（accounting）。

调度程序应该记录一个进程在某一层中消耗的总时间，而不是在调度时重新计时。只要进

程用完了自己的配额，就将它降到低一优先级的队列中去。不论它是一次用完的，还是拆

成很多次用完。因此，我们重写规则 4a 和 4b。

 规则 **4**：一旦工作用完了其在某一层中的时间配额（无论中间主动放弃了多少次

CPU），就降低其优先级（移入低一级队列）。

在规则 4a、4b 的策略下（左图），以及在新的规则 4（右

图）的策略下，同样试图愚弄调度程序的进程的表现。没有规则 4 的保护时，进程可以在

每个时间片结束前发起一次 I/O 操作，从而垄断 CPU 时间。有了这样的保护后，不论进程

的 I/O 行为如何，都会慢慢地降低优先级，因而无法获得超过公平的 CPU 时间比例。

 MLFQ 调优及其他问题 

关于 MLFQ 调度算法还有一些问题。其中一个大问题是如何配置一个调度程序，例如，

配置多少队列？每一层队列的时间片配置多大？为了避免饥饿问题以及进程行为改变，应

该多久提升一次进程的优先级？这些问题都没有显而易见的答案，因此只有利用对工作负

载的经验，以及后续对调度程序的调优，才会导致令人满意的平衡。

例如，大多数的 MLFQ 变体都支持不同队列可变的时间片长度。高优先级队列通常只

有较短的时间片（比如 10ms 或者更少），因而这一层的交互工作可以更快地切换。相反，62 

第 8 章 调度：多级反馈队列 

低优先级队列中更多的是 CPU 密集型工作，配置更长的时间片会取得更好的效果。图 8.7

展示了一个例子，两个长工作在高优先级队列执行 10ms，中间队列执行 20ms，最后在最低

优先级队列执行 40ms。

提示：避免巫毒常量（**Ousterhout** 定律）

尽可能避免巫毒常量是个好主意。然而，从上面的例子可以看出，这通常很难。当然，我们也可以

让系统自己去学习一个很优化的值，但这同样也不容易。因此，通常我们会有一个写满各种参数值默认

值的配置文件，使得系统管理员可以方便地进行修改调整。然而，大多数使用者并不会去修改这些默认

值，这时就寄希望于默认值合适了。这个提示是由资深的 OS 教授 John Ousterhout 提出的，因此称为

Ousterhout 定律（Ousterhout’s Law）。

Solaris 的 MLFQ 实现（时分调度类 TS）很容易配置。它提供了一组表来决定进程在其

生命周期中如何调整优先级，每层的时间片多大，以及多

久提升一个工作的优先级[AD00]。管理员可以通过这些

表，让调度程序的行为方式不同。该表默认有 60 层队列，

时间片长度从 20ms（最高优先级），到几百 ms（最低优

先级），每一秒左右提升一次进程的优先级。

其他一些 MLFQ 调度程序没用表，甚至没用本章中

讲到的规则，有些采用数学公式来调整优先级。例如，

FreeBSD 调度程序（4.3 版本），会基于当前进程使用了多

少 CPU，通过公式计算某个工作的当前优先级[LM+89]。

另外，使用量会随时间衰减，这提供了期望的优先级提升，但与这里描述方式不同。阅读

Epema 的论文，他漂亮地概括了这种使用量衰减（decay-usage）算法及其特征[E95]。

最后，许多调度程序有一些我们没有提到的特征。例如，有些调度程序将最高优先级

队列留给操作系统使用，因此通常的用户工作是无法得到系统的最高优先级的。有些系统

允许用户给出优先级设置的建议（advice），比如通过命令行工具 nice，可以增加或降低工

作的优先级（稍微），从而增加或降低它在某个时刻运行的机会。更多信息请查看 man 手册。

MLFQ：小结 

本章介绍了一种调度方式，名为多级反馈队列（MLFQ）。你应该已经知道它为什么叫

这个名字——它有多级队列，并利用反馈信息决定某个工作的优先级。以史为鉴：关注进程

的一贯表现，然后区别对待。

提示：尽可能多地使用建议

操作系统很少知道什么策略对系统中的单个进程和每个进程算是好的，因此提供接口并允许用户或管理

员给操作系统一些提示（hint）常常很有用。我们通常称之为建议（advice），因为操作系统不一定要关注它，

但是可能会将建议考虑在内，以便做出更好的决定。这种用户建议的方式在操作系统中的各个领域经常十分

有用，包括调度程序（通过 nice）、内存管理（madvise），以及文件系统（通知预取和缓存[P+95]）。本章包含了一组优化的 MLFQ 规则。为了方便查阅，我们重新列在这里。

 规则 **1**：如果 A 的优先级 > B 的优先级，运行 A（不运行 B）。

 规则 **2**：如果 A 的优先级 = B 的优先级，轮转运行 A 和 B。

 规则 **3**：工作进入系统时，放在最高优先级（最上层队列）。

 规则 **4**：一旦工作用完了其在某一层中的时间配额（无论中间主动放弃了多少次

CPU），就降低其优先级（移入低一级队列）。

 规则 **5**：经过一段时间 *S*，就将系统中所有工作重新加入最高优先级队列。

MLFQ 有趣的原因是：它不需要对工作的运行方式有先验知识，而是通过观察工作的

运行来给出对应的优先级。通过这种方式，MLFQ 可以同时满足各种工作的需求：对于短

时间运行的交互型工作，获得类似于 SJF/STCF 的很好的全局性能，同时对长时间运行的

CPU 密集型负载也可以公平地、不断地稳步向前。因此，许多系统使用某种类型的 MLFQ

作为自己的基础调度程序，包括类 BSD UNIX 系统[LM+89，B86]、Solaris[M06]以及 Windows 

NT 和其后的 Window 系列操作系统。

在本章中，我们来看一个不同类型的调度程序——比例份额（proportional-share）调度

程序，有时也称为公平份额（fair-share）调度程序。比例份额算法基于一个简单的想法：调

度程序的最终目标，是确保每个工作获得一定比例的 CPU 时间，而不是优化周转时间和响

应时间。

比例份额调度程序有一个非常优秀的现代例子，由 Waldspurger 和 Weihl 发现，名为彩

票调度（lottery scheduling） [WW94]。但这个想法其实出现得更早[KL88]。基本思想很简

单：每隔一段时间，都会举行一次彩票抽奖，以确定接下来应该运行哪个进程。越是应该

频繁运行的进程，越是应该拥有更多地赢得彩票的机会。很简单吧？现在，谈谈细节！但

还是先看看下面的关键问题。

关键问题：如何按比例分配 **CPU**

如何设计调度程序来按比例分配 CPU？其关键的机制是什么？效率如何？



基本概念：彩票数表示份额 

彩票调度背后是一个非常基本的概念：彩票数（ticket）代表了进程（或用户或其他）占

有某个资源的份额。一个进程拥有的彩票数占总彩票数的百分比，就是它占有资源的份额。

下面来看一个例子。假设有两个进程 A 和 B，A 拥有 75 张彩票，B 拥有 25 张。因此

我们希望 A 占用 75%的 CPU 时间，而 B 占用 25%。

通过不断定时地（比如，每个时间片）抽取彩票，彩票调度从概率上（但不是确定的）

获得这种份额比例。抽取彩票的过程很简单：调度程序知道总共的彩票数（在我们的例子

中，有 100 张）。调度程序抽取中奖彩票，这是从 0 和 99①之间的一个数，拥有这个数对应

的彩票的进程中奖。假设进程 A 拥有 0 到 74 共 75 张彩票，进程 B 拥有 75 到 99 的 25 张，

中奖的彩票就决定了运行 A 或 B。调度程序然后加载中奖进程的状态，并运行它。

提示：利用随机性

彩票调度最精彩的地方在于利用了随机性（randomness）。当你需要做出决定时，采用随机的方式

常常是既可靠又简单的选择。

随机方法相对于传统的决策方式，至少有 3 点优势。第一，随机方法常常可以避免奇怪的边角情况，

第 9 章 调度：比例份额 

较传统的算法可能在处理这些情况时遇到麻烦。例如 LRU 替换策略（稍后会在虚拟内存的章节详

细介绍）。虽然 LRU 通常是很好的替换算法，但在有重复序列的负载时表现非常差。但随机方法就没有

这种最差情况。

第二，随机方法很轻量，几乎不需要记录任何状态。在传统的公平份额调度算法中，记录每个进程

已经获得了多少的 CPU 时间，需要对每个进程计时，这必须在每次运行结束后更新。而采用随机方式

后每个进程只需要非常少的状态（即每个进程拥有的彩票号码）。

第三，随机方法很快。只要能很快地产生随机数，做出决策就很快。因此，随机方式在对运行速度

要求高的场景非常适用。当然，越是需要快的计算速度，随机就会越倾向于伪随机

提示：用彩票来表示份额

彩票（步长）调度的设计中，最强大（且最基本）的机制是彩票。在这些例子中，彩票用于表示一

个进程占有 CPU 的份额，但也可以用在更多的地方。比如在虚拟机管理程序的虚存管理的最新研究工

作中，Waldspurger 提出了用彩票来表示用户占用操作系统内存份额的方法[W02]。因此，如果你需要通

过什么机制来表示所有权比例，这个概念可能就是彩票。

彩票机制 

彩票调度还提供了一些机制，以不同且有效的方式来调度彩票。一种方式是利用彩票

货币（ticket currency）的概念。这种方式允许拥有一组彩票的用户以他们喜欢的某种货币，

将彩票分给自己的不同工作。之后操作系统再自动将这种货币兑换为正确的全局彩票。

比如，假设用户 A 和用户 B 每人拥有 100 张彩票。用户 A 有两个工作 A1 和 A2，他以

自己的货币，给每个工作 500 张彩票（共 1000 张）。用户 B 只运行一个工作，给它 10 张彩

票（总共 10 张）。操作系统将进行兑换，将 A1 和 A2 拥有的 A 的货币 500 张，兑换成全局

货币 50 张。类似地，兑换给 B1 的 10 张彩票兑换成 100 张。然后会对全局彩票货币（共 200

张）举行抽奖，决定哪个工作运行。

另一个有用的机制是彩票转让（ticket transfer）。通过转让，一个进程可以临时将自己

的彩票交给另一个进程。这种机制在客户端/服务端交互的场景中尤其有用，在这种场景中，

客户端进程向服务端发送消息，请求其按自己的需求执行工作，为了加速服务端的执行，

客户端可以将自己的彩票转让给服务端，从而尽可能加速服务端执行自己请求的速度。服

务端执行结束后会将这部分彩票归还给客户端。

最后，彩票通胀（ticket inflation）有时也很有用。利用通胀，一个进程可以临时提升或

降低自己拥有的彩票数量。当然在竞争环境中，进程之间互相不信任，这种机制就没什么

意义。一个贪婪的进程可能给自己非常多的彩票，从而接管机器。但是，通胀可以用于进

程之间相互信任的环境。在这种情况下，如果一个进程知道它需要更多 CPU 时间，就可以

增加自己的彩票，从而将自己的需求告知操作系统，这一切不需要与任何其他进程通信。

9.4 一个例子 

为了更好地理解彩票调度的运行过程，我们现在简单研究一下两个互相竞争工作的完

成时间，每个工作都有相同数目的 100 张彩票，以及相同的运行时间 *R*（稍后会改变）。

这种情况下，我们希望两个工作在大约同时完

成，但由于彩票调度算法的随机性，有时一个工作

会先于另一个完成。为了量化这种区别，我们定义

了一个简单的不公平指标 *U*（unfairness metric），将

两个工作完成时刻相除得到 *U* 的值。比如，运行时

间 *R* 为 10，第一个工作在时刻 10 完成，另一个在

20，*U*=10/20=0.5。如果两个工作几乎同时完成，*U*

的值将很接近于 1。在这种情况下，我们的目标是：

完美的公平调度程序可以做到 *U*=1。 

图 9.2 展示了当两个工作的运行时间从 1 到

1000 变化时，30 次试验的平均 *U* 值（利用本章末

尾的模拟器产生的结果）。可以看出，当工作执行时

间很短时，平均不公平度非常糟糕。只有当工作执行非常多的时间片时，彩票调度算法才

能得到期望的结果。

如何分配彩票 

关于彩票调度，还有一个问题没有提到，那就是如何为工作分配彩票？这是一个非常

棘手的问题，系统的运行严重依赖于彩票的分配。假设用户自己知道如何分配，因此可以

给每个用户一定量的彩票，由用户按照需要自主分配给自己的工作。然而这种方案似乎什

么也没有解决——还是没有给出具体的分配策略。因此对于给定的一组工作，彩票分配的问

题依然没有最佳答案。

为什么不是确定的 

你可能还想知道，究竟为什么要利用随机性？从上面的内容可以看出，虽然随机方式

可以使得调度程序的实现简单（且大致正确），但偶尔并不能产生正确的比例，尤其在工作

运行时间很短的情况下。由于这个原因，Waldspurger 提出了步长调度（stride scheduling），

一个确定性的公平分配算法[W95]。

步长调度也很简单。系统中的每个工作都有自己的步长，这个值与票数值成反比。在

上面的例子中，A、B、C 这 3 个工作的票数分别是 100、50 和 250，我们通过用一个大数

分别除以他们的票数来获得每个进程的步长。比如用 10000 除以这些票数值，得到了 3 个

进程的步长分别为 100、200 和 40。我们称这个值为每个进程的步长（stride）。每次进程运

行后，我们会让它的计数器 [称为行程（pass）值] 增加它的步长，记录它的总体进展。

之后，调度程序使用进程的步长及行程值来确定调度哪个进程。基本思路很简单：当

需要进行调度时，选择目前拥有最小行程值的进程，并且在运行之后将该进程的行程值增

加一个步长。

在我们的例子中，3 个进程（A、B、C）的步长值分别为 100、200 和 40，初始行程值

都为 0。因此，最初，所有进程都可能被选择执行。假设选择 A（任意的，所有具有同样低

的行程值的进程，都可能被选中）。A 执行一个时间片后，更新它的行程值为 100。然后运

行 B，并更新其行程值为 200。最后执行 C，C 的行程值变为 40。这时，算法选择最小的行

程值，是 C，执行并增加为 80（C 的步长是 40）。然后 C 再次运行（依然行程值最小），行

程值增加到 120。现在运行 A，更新它的行程值为 200（现在与 B 相同）。然后 C 再次连续

运行两次，行程值也变为 200。此时，所有行程值再次相等，这个过程会无限地重复下去。

表 9.1 展示了一段时间内调度程序的行为。

可以看出，C 运行了 5 次、A 运行了 2 次，B 一次，正好是票数的比例——200、100 和 50。

彩票调度算法只能一段时间后，在概率上实现比例，而步长调度算法可以在每个调度周期

后做到完全正确。

你可能想知道，既然有了可以精确控制的步长调度算法，为什么还要彩票调度算法

呢？好吧，彩票调度有一个步长调度没有的优势——不需要全局状态。假如一个新的进

程在上面的步长调度执行过程中加入系统，应该怎么设置它的行程值呢？设置成 0 吗？

这样的话，它就独占 CPU 了。而彩票调度算法不需要对每个进程记录全局状态，只需要

用新进程的票数更新全局的总票数就可以了。因此彩票调度算法能够更合理地处理新加

入的进程。

小结 

本章介绍了比例份额调度的概念，并简单讨论了两种实现：彩票调度和步长调度。

彩票调度通过随机值，聪明地做到了按比例分配。步长调度算法能够确定的获得需要的

比例。虽然两者都很有趣，但由于一些原因，并没有作为 CPU 调度程序被广泛使用。一

个原因是这两种方式都不能很好地适合 I/O[AC97]；另一个原因是其中最难的票数分配

问题并没有确定的解决方式，例如，如何知道浏览器进程应该拥有多少票数？通用调度

程序（像前面讨论的 MLFQ 及其他类似的 Linux 调度程序）做得更好，因此得到了广泛

的应用。

结果，比例份额调度程序只有在这些问题可以相对容易解决的领域更有用（例如容易

确定份额比例）。例如在虚拟（virtualized）数据中心中，你可能会希望分配 1/4 的 CPU 周

期给 Windows 虚拟机，剩余的给 Linux 系统，比例分配的方式可以更简单高效。详细信息

请参考 Waldspurger [W02]，该文介绍了 VMWare 的 ESX 系统如何用比例分配的方式来共

享内存。

